{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  benign_0__mal_1  \n",
       "0          0.4601                  0.11890                0  \n",
       "1          0.2750                  0.08902                0  \n",
       "2          0.3613                  0.08758                0  \n",
       "3          0.6638                  0.17300                0  \n",
       "4          0.2364                  0.07678                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>28.11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>188.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>2501.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.16340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.34540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.20120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.30400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>2.87300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>4.88500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>21.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>542.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.13540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.05279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.07895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal dimension error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.02984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>36.04000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>49.54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>251.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>4254.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.22260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>1.05800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>1.25200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.66380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign_0__mal_1</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.627417</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean         std         min  \\\n",
       "mean radius              569.0   14.127292    3.524049    6.981000   \n",
       "mean texture             569.0   19.289649    4.301036    9.710000   \n",
       "mean perimeter           569.0   91.969033   24.298981   43.790000   \n",
       "mean area                569.0  654.889104  351.914129  143.500000   \n",
       "mean smoothness          569.0    0.096360    0.014064    0.052630   \n",
       "mean compactness         569.0    0.104341    0.052813    0.019380   \n",
       "mean concavity           569.0    0.088799    0.079720    0.000000   \n",
       "mean concave points      569.0    0.048919    0.038803    0.000000   \n",
       "mean symmetry            569.0    0.181162    0.027414    0.106000   \n",
       "mean fractal dimension   569.0    0.062798    0.007060    0.049960   \n",
       "radius error             569.0    0.405172    0.277313    0.111500   \n",
       "texture error            569.0    1.216853    0.551648    0.360200   \n",
       "perimeter error          569.0    2.866059    2.021855    0.757000   \n",
       "area error               569.0   40.337079   45.491006    6.802000   \n",
       "smoothness error         569.0    0.007041    0.003003    0.001713   \n",
       "compactness error        569.0    0.025478    0.017908    0.002252   \n",
       "concavity error          569.0    0.031894    0.030186    0.000000   \n",
       "concave points error     569.0    0.011796    0.006170    0.000000   \n",
       "symmetry error           569.0    0.020542    0.008266    0.007882   \n",
       "fractal dimension error  569.0    0.003795    0.002646    0.000895   \n",
       "worst radius             569.0   16.269190    4.833242    7.930000   \n",
       "worst texture            569.0   25.677223    6.146258   12.020000   \n",
       "worst perimeter          569.0  107.261213   33.602542   50.410000   \n",
       "worst area               569.0  880.583128  569.356993  185.200000   \n",
       "worst smoothness         569.0    0.132369    0.022832    0.071170   \n",
       "worst compactness        569.0    0.254265    0.157336    0.027290   \n",
       "worst concavity          569.0    0.272188    0.208624    0.000000   \n",
       "worst concave points     569.0    0.114606    0.065732    0.000000   \n",
       "worst symmetry           569.0    0.290076    0.061867    0.156500   \n",
       "worst fractal dimension  569.0    0.083946    0.018061    0.055040   \n",
       "benign_0__mal_1          569.0    0.627417    0.483918    0.000000   \n",
       "\n",
       "                                25%         50%          75%         max  \n",
       "mean radius               11.700000   13.370000    15.780000    28.11000  \n",
       "mean texture              16.170000   18.840000    21.800000    39.28000  \n",
       "mean perimeter            75.170000   86.240000   104.100000   188.50000  \n",
       "mean area                420.300000  551.100000   782.700000  2501.00000  \n",
       "mean smoothness            0.086370    0.095870     0.105300     0.16340  \n",
       "mean compactness           0.064920    0.092630     0.130400     0.34540  \n",
       "mean concavity             0.029560    0.061540     0.130700     0.42680  \n",
       "mean concave points        0.020310    0.033500     0.074000     0.20120  \n",
       "mean symmetry              0.161900    0.179200     0.195700     0.30400  \n",
       "mean fractal dimension     0.057700    0.061540     0.066120     0.09744  \n",
       "radius error               0.232400    0.324200     0.478900     2.87300  \n",
       "texture error              0.833900    1.108000     1.474000     4.88500  \n",
       "perimeter error            1.606000    2.287000     3.357000    21.98000  \n",
       "area error                17.850000   24.530000    45.190000   542.20000  \n",
       "smoothness error           0.005169    0.006380     0.008146     0.03113  \n",
       "compactness error          0.013080    0.020450     0.032450     0.13540  \n",
       "concavity error            0.015090    0.025890     0.042050     0.39600  \n",
       "concave points error       0.007638    0.010930     0.014710     0.05279  \n",
       "symmetry error             0.015160    0.018730     0.023480     0.07895  \n",
       "fractal dimension error    0.002248    0.003187     0.004558     0.02984  \n",
       "worst radius              13.010000   14.970000    18.790000    36.04000  \n",
       "worst texture             21.080000   25.410000    29.720000    49.54000  \n",
       "worst perimeter           84.110000   97.660000   125.400000   251.20000  \n",
       "worst area               515.300000  686.500000  1084.000000  4254.00000  \n",
       "worst smoothness           0.116600    0.131300     0.146000     0.22260  \n",
       "worst compactness          0.147200    0.211900     0.339100     1.05800  \n",
       "worst concavity            0.114500    0.226700     0.382900     1.25200  \n",
       "worst concave points       0.064930    0.099930     0.161400     0.29100  \n",
       "worst symmetry             0.250400    0.282200     0.317900     0.66380  \n",
       "worst fractal dimension    0.071460    0.080040     0.092080     0.20750  \n",
       "benign_0__mal_1            0.000000    1.000000     1.000000     1.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc67a468c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='benign_0__mal_1', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1', axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 30)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 30)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tiny = Sequential()\n",
    "\n",
    "model_tiny.add(Dense(30, activation='relu'))\n",
    "\n",
    "model_tiny.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_tiny.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/600\n",
      "364/364 [==============================] - 2s 4ms/sample - loss: 0.6790 - val_loss: 0.6654\n",
      "Epoch 2/600\n",
      "364/364 [==============================] - 0s 283us/sample - loss: 0.6589 - val_loss: 0.6481\n",
      "Epoch 3/600\n",
      "364/364 [==============================] - 0s 194us/sample - loss: 0.6392 - val_loss: 0.6310\n",
      "Epoch 4/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.6210 - val_loss: 0.6129\n",
      "Epoch 5/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.6012 - val_loss: 0.5939\n",
      "Epoch 6/600\n",
      "364/364 [==============================] - 0s 171us/sample - loss: 0.5813 - val_loss: 0.5740\n",
      "Epoch 7/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.5603 - val_loss: 0.5539\n",
      "Epoch 8/600\n",
      "364/364 [==============================] - 0s 165us/sample - loss: 0.5392 - val_loss: 0.5338\n",
      "Epoch 9/600\n",
      "364/364 [==============================] - 0s 177us/sample - loss: 0.5178 - val_loss: 0.5135\n",
      "Epoch 10/600\n",
      "364/364 [==============================] - 0s 163us/sample - loss: 0.4964 - val_loss: 0.4934\n",
      "Epoch 11/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.4755 - val_loss: 0.4739\n",
      "Epoch 12/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.4552 - val_loss: 0.4555\n",
      "Epoch 13/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.4355 - val_loss: 0.4375\n",
      "Epoch 14/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.4163 - val_loss: 0.4200\n",
      "Epoch 15/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.3956 - val_loss: 0.4016\n",
      "Epoch 16/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.3766 - val_loss: 0.3851\n",
      "Epoch 17/600\n",
      "364/364 [==============================] - 0s 161us/sample - loss: 0.3592 - val_loss: 0.3698\n",
      "Epoch 18/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.3416 - val_loss: 0.3561\n",
      "Epoch 19/600\n",
      "364/364 [==============================] - 0s 164us/sample - loss: 0.3271 - val_loss: 0.3435\n",
      "Epoch 20/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.3137 - val_loss: 0.3326\n",
      "Epoch 21/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.3013 - val_loss: 0.3261\n",
      "Epoch 22/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.2911 - val_loss: 0.3136\n",
      "Epoch 23/600\n",
      "364/364 [==============================] - 0s 188us/sample - loss: 0.2796 - val_loss: 0.3073\n",
      "Epoch 24/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.2706 - val_loss: 0.2983\n",
      "Epoch 25/600\n",
      "364/364 [==============================] - 0s 172us/sample - loss: 0.2617 - val_loss: 0.2919\n",
      "Epoch 26/600\n",
      "364/364 [==============================] - 0s 166us/sample - loss: 0.2529 - val_loss: 0.2881\n",
      "Epoch 27/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.2459 - val_loss: 0.2832\n",
      "Epoch 28/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.2392 - val_loss: 0.2763\n",
      "Epoch 29/600\n",
      "364/364 [==============================] - 0s 107us/sample - loss: 0.2330 - val_loss: 0.2752\n",
      "Epoch 30/600\n",
      "364/364 [==============================] - 0s 112us/sample - loss: 0.2271 - val_loss: 0.2696\n",
      "Epoch 31/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.2210 - val_loss: 0.2631\n",
      "Epoch 32/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.2159 - val_loss: 0.2620\n",
      "Epoch 33/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.2121 - val_loss: 0.2571\n",
      "Epoch 34/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.2066 - val_loss: 0.2557\n",
      "Epoch 35/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.2023 - val_loss: 0.2502\n",
      "Epoch 36/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.1975 - val_loss: 0.2496\n",
      "Epoch 37/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.1938 - val_loss: 0.2470\n",
      "Epoch 38/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.1898 - val_loss: 0.2410\n",
      "Epoch 39/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.1879 - val_loss: 0.2383\n",
      "Epoch 40/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1835 - val_loss: 0.2396\n",
      "Epoch 41/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.1796 - val_loss: 0.2337\n",
      "Epoch 42/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.1762 - val_loss: 0.2314\n",
      "Epoch 43/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1732 - val_loss: 0.2312\n",
      "Epoch 44/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1707 - val_loss: 0.2257\n",
      "Epoch 45/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.1671 - val_loss: 0.2238\n",
      "Epoch 46/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1644 - val_loss: 0.2181\n",
      "Epoch 47/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1618 - val_loss: 0.2178\n",
      "Epoch 48/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1592 - val_loss: 0.2179\n",
      "Epoch 49/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.1558 - val_loss: 0.2134\n",
      "Epoch 50/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.1533 - val_loss: 0.2099\n",
      "Epoch 51/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1508 - val_loss: 0.2078\n",
      "Epoch 52/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.1489 - val_loss: 0.2056\n",
      "Epoch 53/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.1464 - val_loss: 0.2075\n",
      "Epoch 54/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1447 - val_loss: 0.2088\n",
      "Epoch 55/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.1420 - val_loss: 0.2009\n",
      "Epoch 56/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.1408 - val_loss: 0.2036\n",
      "Epoch 57/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.1393 - val_loss: 0.1965\n",
      "Epoch 58/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.1361 - val_loss: 0.2003\n",
      "Epoch 59/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.1355 - val_loss: 0.1922\n",
      "Epoch 60/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.1315 - val_loss: 0.1947\n",
      "Epoch 61/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.1302 - val_loss: 0.1917\n",
      "Epoch 62/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1281 - val_loss: 0.1914\n",
      "Epoch 63/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1273 - val_loss: 0.1952\n",
      "Epoch 64/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.1263 - val_loss: 0.1862\n",
      "Epoch 65/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.1237 - val_loss: 0.1838\n",
      "Epoch 66/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1217 - val_loss: 0.1853\n",
      "Epoch 67/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.1202 - val_loss: 0.1829\n",
      "Epoch 68/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.1195 - val_loss: 0.1871\n",
      "Epoch 69/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.1170 - val_loss: 0.1766\n",
      "Epoch 70/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.1167 - val_loss: 0.1751\n",
      "Epoch 71/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.1146 - val_loss: 0.1804\n",
      "Epoch 72/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1134 - val_loss: 0.1771\n",
      "Epoch 73/600\n",
      "364/364 [==============================] - 0s 102us/sample - loss: 0.1124 - val_loss: 0.1786\n",
      "Epoch 74/600\n",
      "364/364 [==============================] - 0s 103us/sample - loss: 0.1103 - val_loss: 0.1748\n",
      "Epoch 75/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.1100 - val_loss: 0.1699\n",
      "Epoch 76/600\n",
      "364/364 [==============================] - 0s 115us/sample - loss: 0.1087 - val_loss: 0.1765\n",
      "Epoch 77/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1070 - val_loss: 0.1717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1056 - val_loss: 0.1678\n",
      "Epoch 79/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1045 - val_loss: 0.1681\n",
      "Epoch 80/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.1037 - val_loss: 0.1681\n",
      "Epoch 81/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1024 - val_loss: 0.1637\n",
      "Epoch 82/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.1015 - val_loss: 0.1700\n",
      "Epoch 83/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1007 - val_loss: 0.1619\n",
      "Epoch 84/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0989 - val_loss: 0.1645\n",
      "Epoch 85/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0981 - val_loss: 0.1648\n",
      "Epoch 86/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0968 - val_loss: 0.1611\n",
      "Epoch 87/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0966 - val_loss: 0.1600\n",
      "Epoch 88/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0949 - val_loss: 0.1641\n",
      "Epoch 89/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0943 - val_loss: 0.1573\n",
      "Epoch 90/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0935 - val_loss: 0.1579\n",
      "Epoch 91/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0926 - val_loss: 0.1551\n",
      "Epoch 92/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0913 - val_loss: 0.1563\n",
      "Epoch 93/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0910 - val_loss: 0.1576\n",
      "Epoch 94/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0908 - val_loss: 0.1492\n",
      "Epoch 95/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0890 - val_loss: 0.1534\n",
      "Epoch 96/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0879 - val_loss: 0.1545\n",
      "Epoch 97/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0872 - val_loss: 0.1492\n",
      "Epoch 98/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0863 - val_loss: 0.1497\n",
      "Epoch 99/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0860 - val_loss: 0.1486\n",
      "Epoch 100/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0861 - val_loss: 0.1535\n",
      "Epoch 101/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0839 - val_loss: 0.1491\n",
      "Epoch 102/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0830 - val_loss: 0.1455\n",
      "Epoch 103/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0824 - val_loss: 0.1439\n",
      "Epoch 104/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0815 - val_loss: 0.1471\n",
      "Epoch 105/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0812 - val_loss: 0.1444\n",
      "Epoch 106/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0810 - val_loss: 0.1525\n",
      "Epoch 107/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0797 - val_loss: 0.1436\n",
      "Epoch 108/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0787 - val_loss: 0.1439\n",
      "Epoch 109/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0779 - val_loss: 0.1437\n",
      "Epoch 110/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0785 - val_loss: 0.1444\n",
      "Epoch 111/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0772 - val_loss: 0.1393\n",
      "Epoch 112/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0760 - val_loss: 0.1470\n",
      "Epoch 113/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0754 - val_loss: 0.1414\n",
      "Epoch 114/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0760 - val_loss: 0.1370\n",
      "Epoch 115/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0745 - val_loss: 0.1409\n",
      "Epoch 116/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0743 - val_loss: 0.1452\n",
      "Epoch 117/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0730 - val_loss: 0.1355\n",
      "Epoch 118/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0737 - val_loss: 0.1423\n",
      "Epoch 119/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0724 - val_loss: 0.1359\n",
      "Epoch 120/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0711 - val_loss: 0.1400\n",
      "Epoch 121/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0711 - val_loss: 0.1381\n",
      "Epoch 122/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0711 - val_loss: 0.1325\n",
      "Epoch 123/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0696 - val_loss: 0.1388\n",
      "Epoch 124/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0694 - val_loss: 0.1387\n",
      "Epoch 125/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0692 - val_loss: 0.1361\n",
      "Epoch 126/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0682 - val_loss: 0.1315\n",
      "Epoch 127/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0683 - val_loss: 0.1339\n",
      "Epoch 128/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0671 - val_loss: 0.1327\n",
      "Epoch 129/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0673 - val_loss: 0.1314\n",
      "Epoch 130/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0662 - val_loss: 0.1349\n",
      "Epoch 131/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0660 - val_loss: 0.1339\n",
      "Epoch 132/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0650 - val_loss: 0.1300\n",
      "Epoch 133/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0649 - val_loss: 0.1310\n",
      "Epoch 134/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0645 - val_loss: 0.1316\n",
      "Epoch 135/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0640 - val_loss: 0.1306\n",
      "Epoch 136/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0636 - val_loss: 0.1322\n",
      "Epoch 137/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0633 - val_loss: 0.1311\n",
      "Epoch 138/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0628 - val_loss: 0.1311\n",
      "Epoch 139/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0633 - val_loss: 0.1285\n",
      "Epoch 140/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0619 - val_loss: 0.1356\n",
      "Epoch 141/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0617 - val_loss: 0.1299\n",
      "Epoch 142/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0615 - val_loss: 0.1268\n",
      "Epoch 143/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0612 - val_loss: 0.1313\n",
      "Epoch 144/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0605 - val_loss: 0.1304\n",
      "Epoch 145/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0609 - val_loss: 0.1260\n",
      "Epoch 146/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0610 - val_loss: 0.1353\n",
      "Epoch 147/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0603 - val_loss: 0.1248\n",
      "Epoch 148/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0593 - val_loss: 0.1289\n",
      "Epoch 149/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0599 - val_loss: 0.1247\n",
      "Epoch 150/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0591 - val_loss: 0.1301\n",
      "Epoch 151/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0586 - val_loss: 0.1287\n",
      "Epoch 152/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0576 - val_loss: 0.1256\n",
      "Epoch 153/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0572 - val_loss: 0.1267\n",
      "Epoch 154/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0571 - val_loss: 0.1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0564 - val_loss: 0.1270\n",
      "Epoch 156/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0566 - val_loss: 0.1258\n",
      "Epoch 157/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0558 - val_loss: 0.1291\n",
      "Epoch 158/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0556 - val_loss: 0.1254\n",
      "Epoch 159/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0556 - val_loss: 0.1248\n",
      "Epoch 160/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0546 - val_loss: 0.1293\n",
      "Epoch 161/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0554 - val_loss: 0.1307\n",
      "Epoch 162/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0548 - val_loss: 0.1237\n",
      "Epoch 163/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0543 - val_loss: 0.1249\n",
      "Epoch 164/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0538 - val_loss: 0.1262\n",
      "Epoch 165/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0533 - val_loss: 0.1231\n",
      "Epoch 166/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0538 - val_loss: 0.1284\n",
      "Epoch 167/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0531 - val_loss: 0.1258\n",
      "Epoch 168/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0527 - val_loss: 0.1260\n",
      "Epoch 169/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0526 - val_loss: 0.1267\n",
      "Epoch 170/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0519 - val_loss: 0.1246\n",
      "Epoch 171/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0525 - val_loss: 0.1266\n",
      "Epoch 172/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0514 - val_loss: 0.1230\n",
      "Epoch 173/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0514 - val_loss: 0.1248\n",
      "Epoch 174/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0510 - val_loss: 0.1240\n",
      "Epoch 175/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0507 - val_loss: 0.1245\n",
      "Epoch 176/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0506 - val_loss: 0.1257\n",
      "Epoch 177/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0506 - val_loss: 0.1236\n",
      "Epoch 178/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0500 - val_loss: 0.1236\n",
      "Epoch 179/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0497 - val_loss: 0.1242\n",
      "Epoch 180/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0494 - val_loss: 0.1237\n",
      "Epoch 181/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0493 - val_loss: 0.1236\n",
      "Epoch 182/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0490 - val_loss: 0.1210\n",
      "Epoch 183/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0496 - val_loss: 0.1233\n",
      "Epoch 184/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0489 - val_loss: 0.1222\n",
      "Epoch 185/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0483 - val_loss: 0.1234\n",
      "Epoch 186/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0481 - val_loss: 0.1262\n",
      "Epoch 187/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0482 - val_loss: 0.1226\n",
      "Epoch 188/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0478 - val_loss: 0.1227\n",
      "Epoch 189/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0475 - val_loss: 0.1243\n",
      "Epoch 190/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0473 - val_loss: 0.1229\n",
      "Epoch 191/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0469 - val_loss: 0.1240\n",
      "Epoch 192/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0468 - val_loss: 0.1271\n",
      "Epoch 193/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0475 - val_loss: 0.1268\n",
      "Epoch 194/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0464 - val_loss: 0.1207\n",
      "Epoch 195/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0465 - val_loss: 0.1224\n",
      "Epoch 196/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0468 - val_loss: 0.1230\n",
      "Epoch 197/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0462 - val_loss: 0.1288\n",
      "Epoch 198/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0458 - val_loss: 0.1224\n",
      "Epoch 199/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0458 - val_loss: 0.1233\n",
      "Epoch 200/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0454 - val_loss: 0.1262\n",
      "Epoch 201/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0451 - val_loss: 0.1234\n",
      "Epoch 202/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0448 - val_loss: 0.1234\n",
      "Epoch 203/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0451 - val_loss: 0.1220\n",
      "Epoch 204/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0443 - val_loss: 0.1241\n",
      "Epoch 205/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0450 - val_loss: 0.1289\n",
      "Epoch 206/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0445 - val_loss: 0.1220\n",
      "Epoch 207/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0443 - val_loss: 0.1215\n",
      "Epoch 208/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0439 - val_loss: 0.1232\n",
      "Epoch 209/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0444 - val_loss: 0.1306\n",
      "Epoch 210/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0435 - val_loss: 0.1223\n",
      "Epoch 211/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0434 - val_loss: 0.1228\n",
      "Epoch 212/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0428 - val_loss: 0.1250\n",
      "Epoch 213/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0429 - val_loss: 0.1247\n",
      "Epoch 214/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0428 - val_loss: 0.1236\n",
      "Epoch 215/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0427 - val_loss: 0.1230\n",
      "Epoch 216/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0424 - val_loss: 0.1243\n",
      "Epoch 217/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0425 - val_loss: 0.1247\n",
      "Epoch 218/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0420 - val_loss: 0.1229\n",
      "Epoch 219/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0420 - val_loss: 0.1209\n",
      "Epoch 220/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0418 - val_loss: 0.1259\n",
      "Epoch 221/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0417 - val_loss: 0.1227\n",
      "Epoch 222/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0414 - val_loss: 0.1231\n",
      "Epoch 223/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0411 - val_loss: 0.1224\n",
      "Epoch 224/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0409 - val_loss: 0.1233\n",
      "Epoch 225/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0409 - val_loss: 0.1248\n",
      "Epoch 226/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0408 - val_loss: 0.1233\n",
      "Epoch 227/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0406 - val_loss: 0.1253\n",
      "Epoch 228/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0412 - val_loss: 0.1231\n",
      "Epoch 229/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0404 - val_loss: 0.1252\n",
      "Epoch 230/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0405 - val_loss: 0.1222\n",
      "Epoch 231/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0400 - val_loss: 0.1239\n",
      "Epoch 232/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0399 - val_loss: 0.1248\n",
      "Epoch 233/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0399 - val_loss: 0.1228\n",
      "Epoch 234/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0397 - val_loss: 0.1249\n",
      "Epoch 235/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0398 - val_loss: 0.1249\n",
      "Epoch 236/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0393 - val_loss: 0.1227\n",
      "Epoch 237/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0396 - val_loss: 0.1262\n",
      "Epoch 238/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0393 - val_loss: 0.1231\n",
      "Epoch 239/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0390 - val_loss: 0.1234\n",
      "Epoch 240/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0388 - val_loss: 0.1244\n",
      "Epoch 241/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0396 - val_loss: 0.1218\n",
      "Epoch 242/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0387 - val_loss: 0.1243\n",
      "Epoch 243/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0382 - val_loss: 0.1248\n",
      "Epoch 244/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0391 - val_loss: 0.1259\n",
      "Epoch 245/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0386 - val_loss: 0.1212\n",
      "Epoch 246/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0387 - val_loss: 0.1252\n",
      "Epoch 247/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0380 - val_loss: 0.1253\n",
      "Epoch 248/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0382 - val_loss: 0.1230\n",
      "Epoch 249/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0379 - val_loss: 0.1281\n",
      "Epoch 250/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0376 - val_loss: 0.1246\n",
      "Epoch 251/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0377 - val_loss: 0.1229\n",
      "Epoch 252/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0374 - val_loss: 0.1257\n",
      "Epoch 253/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0377 - val_loss: 0.1237\n",
      "Epoch 254/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0375 - val_loss: 0.1244\n",
      "Epoch 255/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0376 - val_loss: 0.1280\n",
      "Epoch 256/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0365 - val_loss: 0.1243\n",
      "Epoch 257/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0368 - val_loss: 0.1232\n",
      "Epoch 258/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0367 - val_loss: 0.1252\n",
      "Epoch 259/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0363 - val_loss: 0.1259\n",
      "Epoch 260/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0365 - val_loss: 0.1249\n",
      "Epoch 261/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0363 - val_loss: 0.1256\n",
      "Epoch 262/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0362 - val_loss: 0.1265\n",
      "Epoch 263/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0366 - val_loss: 0.1246\n",
      "Epoch 264/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0357 - val_loss: 0.1290\n",
      "Epoch 265/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0361 - val_loss: 0.1274\n",
      "Epoch 266/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0355 - val_loss: 0.1263\n",
      "Epoch 267/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0362 - val_loss: 0.1245\n",
      "Epoch 268/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0356 - val_loss: 0.1289\n",
      "Epoch 269/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0355 - val_loss: 0.1266\n",
      "Epoch 270/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0356 - val_loss: 0.1261\n",
      "Epoch 271/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0351 - val_loss: 0.1257\n",
      "Epoch 272/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0358 - val_loss: 0.1260\n",
      "Epoch 273/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0348 - val_loss: 0.1282\n",
      "Epoch 274/600\n",
      "364/364 [==============================] - 0s 168us/sample - loss: 0.0351 - val_loss: 0.1288\n",
      "Epoch 275/600\n",
      "364/364 [==============================] - 0s 118us/sample - loss: 0.0352 - val_loss: 0.1277\n",
      "Epoch 276/600\n",
      "364/364 [==============================] - 0s 91us/sample - loss: 0.0354 - val_loss: 0.1245\n",
      "Epoch 277/600\n",
      "364/364 [==============================] - 0s 94us/sample - loss: 0.0343 - val_loss: 0.1276\n",
      "Epoch 278/600\n",
      "364/364 [==============================] - 0s 104us/sample - loss: 0.0346 - val_loss: 0.1315\n",
      "Epoch 279/600\n",
      "364/364 [==============================] - 0s 95us/sample - loss: 0.0349 - val_loss: 0.1270\n",
      "Epoch 280/600\n",
      "364/364 [==============================] - 0s 99us/sample - loss: 0.0355 - val_loss: 0.1262\n",
      "Epoch 281/600\n",
      "364/364 [==============================] - 0s 96us/sample - loss: 0.0338 - val_loss: 0.1322\n",
      "Epoch 282/600\n",
      "364/364 [==============================] - 0s 92us/sample - loss: 0.0343 - val_loss: 0.1281\n",
      "Epoch 283/600\n",
      "364/364 [==============================] - 0s 107us/sample - loss: 0.0338 - val_loss: 0.1266\n",
      "Epoch 284/600\n",
      "364/364 [==============================] - 0s 110us/sample - loss: 0.0339 - val_loss: 0.1297\n",
      "Epoch 285/600\n",
      "364/364 [==============================] - 0s 116us/sample - loss: 0.0338 - val_loss: 0.1294\n",
      "Epoch 286/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0338 - val_loss: 0.1291\n",
      "Epoch 287/600\n",
      "364/364 [==============================] - 0s 104us/sample - loss: 0.0338 - val_loss: 0.1290\n",
      "Epoch 288/600\n",
      "364/364 [==============================] - 0s 104us/sample - loss: 0.0333 - val_loss: 0.1269\n",
      "Epoch 289/600\n",
      "364/364 [==============================] - 0s 99us/sample - loss: 0.0337 - val_loss: 0.1268\n",
      "Epoch 290/600\n",
      "364/364 [==============================] - 0s 96us/sample - loss: 0.0334 - val_loss: 0.1298\n",
      "Epoch 291/600\n",
      "364/364 [==============================] - 0s 95us/sample - loss: 0.0331 - val_loss: 0.1278\n",
      "Epoch 292/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0336 - val_loss: 0.1299\n",
      "Epoch 293/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0327 - val_loss: 0.1261\n",
      "Epoch 294/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0334 - val_loss: 0.1273\n",
      "Epoch 295/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0332 - val_loss: 0.1286\n",
      "Epoch 296/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0325 - val_loss: 0.1272\n",
      "Epoch 297/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0331 - val_loss: 0.1274\n",
      "Epoch 298/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0331 - val_loss: 0.1272\n",
      "Epoch 299/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0323 - val_loss: 0.1290\n",
      "Epoch 300/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0326 - val_loss: 0.1329\n",
      "Epoch 301/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0331 - val_loss: 0.1306\n",
      "Epoch 302/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0321 - val_loss: 0.1276\n",
      "Epoch 303/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0324 - val_loss: 0.1284\n",
      "Epoch 304/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0324 - val_loss: 0.1287\n",
      "Epoch 305/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0327 - val_loss: 0.1321\n",
      "Epoch 306/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0320 - val_loss: 0.1296\n",
      "Epoch 307/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0324 - val_loss: 0.1283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0318 - val_loss: 0.1308\n",
      "Epoch 309/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0317 - val_loss: 0.1293\n",
      "Epoch 310/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0315 - val_loss: 0.1300\n",
      "Epoch 311/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0315 - val_loss: 0.1288\n",
      "Epoch 312/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0318 - val_loss: 0.1316\n",
      "Epoch 313/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0313 - val_loss: 0.1283\n",
      "Epoch 314/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0315 - val_loss: 0.1284\n",
      "Epoch 315/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0313 - val_loss: 0.1304\n",
      "Epoch 316/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0310 - val_loss: 0.1295\n",
      "Epoch 317/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0309 - val_loss: 0.1292\n",
      "Epoch 318/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0320 - val_loss: 0.1284\n",
      "Epoch 319/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0307 - val_loss: 0.1309\n",
      "Epoch 320/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0312 - val_loss: 0.1304\n",
      "Epoch 321/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0307 - val_loss: 0.1312\n",
      "Epoch 322/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0306 - val_loss: 0.1305\n",
      "Epoch 323/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0305 - val_loss: 0.1307\n",
      "Epoch 324/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0307 - val_loss: 0.1320\n",
      "Epoch 325/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0331 - val_loss: 0.1283\n",
      "Epoch 326/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0322 - val_loss: 0.1334\n",
      "Epoch 327/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0304 - val_loss: 0.1309\n",
      "Epoch 328/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0300 - val_loss: 0.1299\n",
      "Epoch 329/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0314 - val_loss: 0.1325\n",
      "Epoch 330/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0299 - val_loss: 0.1289\n",
      "Epoch 331/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0306 - val_loss: 0.1297\n",
      "Epoch 332/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0300 - val_loss: 0.1322\n",
      "Epoch 333/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0302 - val_loss: 0.1309\n",
      "Epoch 334/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0299 - val_loss: 0.1315\n",
      "Epoch 335/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0298 - val_loss: 0.1316\n",
      "Epoch 336/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0296 - val_loss: 0.1320\n",
      "Epoch 337/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0299 - val_loss: 0.1315\n",
      "Epoch 338/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0297 - val_loss: 0.1317\n",
      "Epoch 339/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0293 - val_loss: 0.1311\n",
      "Epoch 340/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0294 - val_loss: 0.1312\n",
      "Epoch 341/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0297 - val_loss: 0.1315\n",
      "Epoch 342/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0295 - val_loss: 0.1320\n",
      "Epoch 343/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0292 - val_loss: 0.1316\n",
      "Epoch 344/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0290 - val_loss: 0.1340\n",
      "Epoch 345/600\n",
      "364/364 [==============================] - 0s 102us/sample - loss: 0.0291 - val_loss: 0.1324\n",
      "Epoch 346/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0290 - val_loss: 0.1322\n",
      "Epoch 347/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0290 - val_loss: 0.1319\n",
      "Epoch 348/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0289 - val_loss: 0.1328\n",
      "Epoch 349/600\n",
      "364/364 [==============================] - 0s 172us/sample - loss: 0.0293 - val_loss: 0.1316\n",
      "Epoch 350/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0287 - val_loss: 0.1320\n",
      "Epoch 351/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0286 - val_loss: 0.1332\n",
      "Epoch 352/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0285 - val_loss: 0.1335\n",
      "Epoch 353/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0297 - val_loss: 0.1321\n",
      "Epoch 354/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0322 - val_loss: 0.1373\n",
      "Epoch 355/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0288 - val_loss: 0.1340\n",
      "Epoch 356/600\n",
      "364/364 [==============================] - 0s 164us/sample - loss: 0.0307 - val_loss: 0.1320\n",
      "Epoch 357/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0287 - val_loss: 0.1355\n",
      "Epoch 358/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.0285 - val_loss: 0.1339\n",
      "Epoch 359/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0282 - val_loss: 0.1331\n",
      "Epoch 360/600\n",
      "364/364 [==============================] - 0s 111us/sample - loss: 0.0283 - val_loss: 0.1340\n",
      "Epoch 361/600\n",
      "364/364 [==============================] - 0s 116us/sample - loss: 0.0282 - val_loss: 0.1325\n",
      "Epoch 362/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0282 - val_loss: 0.1341\n",
      "Epoch 363/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0291 - val_loss: 0.1353\n",
      "Epoch 364/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0289 - val_loss: 0.1325\n",
      "Epoch 365/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0306 - val_loss: 0.1344\n",
      "Epoch 366/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0276 - val_loss: 0.1339\n",
      "Epoch 367/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0276 - val_loss: 0.1338\n",
      "Epoch 368/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0279 - val_loss: 0.1334\n",
      "Epoch 369/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0280 - val_loss: 0.1340\n",
      "Epoch 370/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0277 - val_loss: 0.1341\n",
      "Epoch 371/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0276 - val_loss: 0.1352\n",
      "Epoch 372/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0277 - val_loss: 0.1347\n",
      "Epoch 373/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0274 - val_loss: 0.1342\n",
      "Epoch 374/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0280 - val_loss: 0.1337\n",
      "Epoch 375/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0282 - val_loss: 0.1363\n",
      "Epoch 376/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0272 - val_loss: 0.1349\n",
      "Epoch 377/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0272 - val_loss: 0.1344\n",
      "Epoch 378/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0278 - val_loss: 0.1352\n",
      "Epoch 379/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0269 - val_loss: 0.1361\n",
      "Epoch 380/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0274 - val_loss: 0.1365\n",
      "Epoch 381/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0281 - val_loss: 0.1341\n",
      "Epoch 382/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0275 - val_loss: 0.1370\n",
      "Epoch 383/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0268 - val_loss: 0.1362\n",
      "Epoch 384/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0273 - val_loss: 0.1353\n",
      "Epoch 385/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0271 - val_loss: 0.1355\n",
      "Epoch 386/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0270 - val_loss: 0.1365\n",
      "Epoch 387/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0266 - val_loss: 0.1372\n",
      "Epoch 388/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0269 - val_loss: 0.1363\n",
      "Epoch 389/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0266 - val_loss: 0.1356\n",
      "Epoch 390/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0266 - val_loss: 0.1363\n",
      "Epoch 391/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0269 - val_loss: 0.1368\n",
      "Epoch 392/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0269 - val_loss: 0.1352\n",
      "Epoch 393/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0284 - val_loss: 0.1351\n",
      "Epoch 394/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0283 - val_loss: 0.1454\n",
      "Epoch 395/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0280 - val_loss: 0.1378\n",
      "Epoch 396/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0259 - val_loss: 0.1361\n",
      "Epoch 397/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0265 - val_loss: 0.1364\n",
      "Epoch 398/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0261 - val_loss: 0.1386\n",
      "Epoch 399/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0260 - val_loss: 0.1376\n",
      "Epoch 400/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0283 - val_loss: 0.1367\n",
      "Epoch 401/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0269 - val_loss: 0.1392\n",
      "Epoch 402/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0264 - val_loss: 0.1373\n",
      "Epoch 403/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0255 - val_loss: 0.1385\n",
      "Epoch 404/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0261 - val_loss: 0.1390\n",
      "Epoch 405/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0259 - val_loss: 0.1374\n",
      "Epoch 406/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0258 - val_loss: 0.1386\n",
      "Epoch 407/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0274 - val_loss: 0.1403\n",
      "Epoch 408/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0267 - val_loss: 0.1372\n",
      "Epoch 409/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0258 - val_loss: 0.1383\n",
      "Epoch 410/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0252 - val_loss: 0.1412\n",
      "Epoch 411/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0262 - val_loss: 0.1395\n",
      "Epoch 412/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0258 - val_loss: 0.1385\n",
      "Epoch 413/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0257 - val_loss: 0.1391\n",
      "Epoch 414/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0266 - val_loss: 0.1403\n",
      "Epoch 415/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0254 - val_loss: 0.1385\n",
      "Epoch 416/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0282 - val_loss: 0.1376\n",
      "Epoch 417/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0256 - val_loss: 0.1430\n",
      "Epoch 418/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0259 - val_loss: 0.1399\n",
      "Epoch 419/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0248 - val_loss: 0.1384\n",
      "Epoch 420/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0257 - val_loss: 0.1384\n",
      "Epoch 421/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0251 - val_loss: 0.1407\n",
      "Epoch 422/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0259 - val_loss: 0.1392\n",
      "Epoch 423/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0248 - val_loss: 0.1405\n",
      "Epoch 424/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0253 - val_loss: 0.1393\n",
      "Epoch 425/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0262 - val_loss: 0.1389\n",
      "Epoch 426/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0253 - val_loss: 0.1420\n",
      "Epoch 427/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0258 - val_loss: 0.1411\n",
      "Epoch 428/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0261 - val_loss: 0.1387\n",
      "Epoch 429/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0257 - val_loss: 0.1391\n",
      "Epoch 430/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0252 - val_loss: 0.1401\n",
      "Epoch 431/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0248 - val_loss: 0.1395\n",
      "Epoch 432/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0248 - val_loss: 0.1393\n",
      "Epoch 433/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0249 - val_loss: 0.1392\n",
      "Epoch 434/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0247 - val_loss: 0.1400\n",
      "Epoch 435/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0250 - val_loss: 0.1396\n",
      "Epoch 436/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0246 - val_loss: 0.1389\n",
      "Epoch 437/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0247 - val_loss: 0.1397\n",
      "Epoch 438/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0244 - val_loss: 0.1392\n",
      "Epoch 439/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0252 - val_loss: 0.1402\n",
      "Epoch 440/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0241 - val_loss: 0.1389\n",
      "Epoch 441/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0245 - val_loss: 0.1391\n",
      "Epoch 442/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0242 - val_loss: 0.1390\n",
      "Epoch 443/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0244 - val_loss: 0.1388\n",
      "Epoch 444/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0245 - val_loss: 0.1391\n",
      "Epoch 445/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0240 - val_loss: 0.1401\n",
      "Epoch 446/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0241 - val_loss: 0.1399\n",
      "Epoch 447/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0244 - val_loss: 0.1395\n",
      "Epoch 448/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0241 - val_loss: 0.1402\n",
      "Epoch 449/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0241 - val_loss: 0.1401\n",
      "Epoch 450/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0244 - val_loss: 0.1396\n",
      "Epoch 451/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0241 - val_loss: 0.1406\n",
      "Epoch 452/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0248 - val_loss: 0.1410\n",
      "Epoch 453/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0240 - val_loss: 0.1395\n",
      "Epoch 454/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0245 - val_loss: 0.1398\n",
      "Epoch 455/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0237 - val_loss: 0.1415\n",
      "Epoch 456/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0243 - val_loss: 0.1413\n",
      "Epoch 457/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0239 - val_loss: 0.1401\n",
      "Epoch 458/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0237 - val_loss: 0.1406\n",
      "Epoch 459/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0237 - val_loss: 0.1417\n",
      "Epoch 460/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0243 - val_loss: 0.1408\n",
      "Epoch 461/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0242 - val_loss: 0.1428\n",
      "Epoch 462/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0239 - val_loss: 0.1414\n",
      "Epoch 463/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0235 - val_loss: 0.1412\n",
      "Epoch 464/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0234 - val_loss: 0.1414\n",
      "Epoch 465/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0243 - val_loss: 0.1426\n",
      "Epoch 466/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0234 - val_loss: 0.1411\n",
      "Epoch 467/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0235 - val_loss: 0.1419\n",
      "Epoch 468/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0237 - val_loss: 0.1419\n",
      "Epoch 469/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0233 - val_loss: 0.1411\n",
      "Epoch 470/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0239 - val_loss: 0.1412\n",
      "Epoch 471/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0229 - val_loss: 0.1424\n",
      "Epoch 472/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0236 - val_loss: 0.1426\n",
      "Epoch 473/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0235 - val_loss: 0.1425\n",
      "Epoch 474/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0235 - val_loss: 0.1423\n",
      "Epoch 475/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0240 - val_loss: 0.1420\n",
      "Epoch 476/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0229 - val_loss: 0.1426\n",
      "Epoch 477/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0234 - val_loss: 0.1435\n",
      "Epoch 478/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0231 - val_loss: 0.1426\n",
      "Epoch 479/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0231 - val_loss: 0.1422\n",
      "Epoch 480/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0234 - val_loss: 0.1427\n",
      "Epoch 481/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0243 - val_loss: 0.1428\n",
      "Epoch 482/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0228 - val_loss: 0.1440\n",
      "Epoch 483/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0231 - val_loss: 0.1441\n",
      "Epoch 484/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0229 - val_loss: 0.1444\n",
      "Epoch 485/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0232 - val_loss: 0.1442\n",
      "Epoch 486/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0262 - val_loss: 0.1439\n",
      "Epoch 487/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0244 - val_loss: 0.1444\n",
      "Epoch 488/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0231 - val_loss: 0.1435\n",
      "Epoch 489/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0229 - val_loss: 0.1438\n",
      "Epoch 490/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0226 - val_loss: 0.1447\n",
      "Epoch 491/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0227 - val_loss: 0.1441\n",
      "Epoch 492/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0231 - val_loss: 0.1439\n",
      "Epoch 493/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0228 - val_loss: 0.1455\n",
      "Epoch 494/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0230 - val_loss: 0.1443\n",
      "Epoch 495/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0226 - val_loss: 0.1436\n",
      "Epoch 496/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0229 - val_loss: 0.1439\n",
      "Epoch 497/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0226 - val_loss: 0.1456\n",
      "Epoch 498/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0225 - val_loss: 0.1447\n",
      "Epoch 499/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0222 - val_loss: 0.1442\n",
      "Epoch 500/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0241 - val_loss: 0.1442\n",
      "Epoch 501/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0230 - val_loss: 0.1460\n",
      "Epoch 502/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0224 - val_loss: 0.1447\n",
      "Epoch 503/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0222 - val_loss: 0.1445\n",
      "Epoch 504/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0226 - val_loss: 0.1447\n",
      "Epoch 505/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0236 - val_loss: 0.1443\n",
      "Epoch 506/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0242 - val_loss: 0.1467\n",
      "Epoch 507/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0228 - val_loss: 0.1450\n",
      "Epoch 508/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0222 - val_loss: 0.1452\n",
      "Epoch 509/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0220 - val_loss: 0.1453\n",
      "Epoch 510/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0222 - val_loss: 0.1453\n",
      "Epoch 511/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0219 - val_loss: 0.1448\n",
      "Epoch 512/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0219 - val_loss: 0.1451\n",
      "Epoch 513/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0219 - val_loss: 0.1452\n",
      "Epoch 514/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0224 - val_loss: 0.1451\n",
      "Epoch 515/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0221 - val_loss: 0.1458\n",
      "Epoch 516/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0228 - val_loss: 0.1448\n",
      "Epoch 517/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0217 - val_loss: 0.1455\n",
      "Epoch 518/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0219 - val_loss: 0.1455\n",
      "Epoch 519/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0231 - val_loss: 0.1460\n",
      "Epoch 520/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0225 - val_loss: 0.1454\n",
      "Epoch 521/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0225 - val_loss: 0.1459\n",
      "Epoch 522/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0220 - val_loss: 0.1465\n",
      "Epoch 523/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0219 - val_loss: 0.1457\n",
      "Epoch 524/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0241 - val_loss: 0.1456\n",
      "Epoch 525/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0224 - val_loss: 0.1480\n",
      "Epoch 526/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0223 - val_loss: 0.1468\n",
      "Epoch 527/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0218 - val_loss: 0.1462\n",
      "Epoch 528/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0222 - val_loss: 0.1475\n",
      "Epoch 529/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0218 - val_loss: 0.1481\n",
      "Epoch 530/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0219 - val_loss: 0.1480\n",
      "Epoch 531/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0209 - val_loss: 0.1472\n",
      "Epoch 532/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0218 - val_loss: 0.1473\n",
      "Epoch 533/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0213 - val_loss: 0.1475\n",
      "Epoch 534/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0215 - val_loss: 0.1476\n",
      "Epoch 535/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0219 - val_loss: 0.1480\n",
      "Epoch 536/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0214 - val_loss: 0.1472\n",
      "Epoch 537/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0232 - val_loss: 0.1487\n",
      "Epoch 538/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0223 - val_loss: 0.1471\n",
      "Epoch 539/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0214 - val_loss: 0.1471\n",
      "Epoch 540/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0213 - val_loss: 0.1472\n",
      "Epoch 541/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0220 - val_loss: 0.1485\n",
      "Epoch 542/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0213 - val_loss: 0.1477\n",
      "Epoch 543/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0211 - val_loss: 0.1475\n",
      "Epoch 544/600\n",
      "364/364 [==============================] - 0s 118us/sample - loss: 0.0211 - val_loss: 0.1473\n",
      "Epoch 545/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0215 - val_loss: 0.1482\n",
      "Epoch 546/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0230 - val_loss: 0.1475\n",
      "Epoch 547/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0210 - val_loss: 0.1477\n",
      "Epoch 548/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0208 - val_loss: 0.1486\n",
      "Epoch 549/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0212 - val_loss: 0.1477\n",
      "Epoch 550/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0210 - val_loss: 0.1481\n",
      "Epoch 551/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0212 - val_loss: 0.1479\n",
      "Epoch 552/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0212 - val_loss: 0.1485\n",
      "Epoch 553/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0210 - val_loss: 0.1483\n",
      "Epoch 554/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0214 - val_loss: 0.1485\n",
      "Epoch 555/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0214 - val_loss: 0.1479\n",
      "Epoch 556/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0207 - val_loss: 0.1488\n",
      "Epoch 557/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0211 - val_loss: 0.1483\n",
      "Epoch 558/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0208 - val_loss: 0.1479\n",
      "Epoch 559/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0209 - val_loss: 0.1483\n",
      "Epoch 560/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0207 - val_loss: 0.1483\n",
      "Epoch 561/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0210 - val_loss: 0.1489\n",
      "Epoch 562/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0215 - val_loss: 0.1484\n",
      "Epoch 563/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0217 - val_loss: 0.1491\n",
      "Epoch 564/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0208 - val_loss: 0.1485\n",
      "Epoch 565/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0206 - val_loss: 0.1488\n",
      "Epoch 566/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0207 - val_loss: 0.1484\n",
      "Epoch 567/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0229 - val_loss: 0.1487\n",
      "Epoch 568/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0205 - val_loss: 0.1489\n",
      "Epoch 569/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0214 - val_loss: 0.1487\n",
      "Epoch 570/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0210 - val_loss: 0.1500\n",
      "Epoch 571/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0207 - val_loss: 0.1491\n",
      "Epoch 572/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0211 - val_loss: 0.1485\n",
      "Epoch 573/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0205 - val_loss: 0.1511\n",
      "Epoch 574/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0212 - val_loss: 0.1494\n",
      "Epoch 575/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0201 - val_loss: 0.1486\n",
      "Epoch 576/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0206 - val_loss: 0.1487\n",
      "Epoch 577/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0205 - val_loss: 0.1490\n",
      "Epoch 578/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0200 - val_loss: 0.1493\n",
      "Epoch 579/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0203 - val_loss: 0.1499\n",
      "Epoch 580/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0200 - val_loss: 0.1495\n",
      "Epoch 581/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0208 - val_loss: 0.1496\n",
      "Epoch 582/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0227 - val_loss: 0.1509\n",
      "Epoch 583/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0222 - val_loss: 0.1498\n",
      "Epoch 584/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0201 - val_loss: 0.1502\n",
      "Epoch 585/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0201 - val_loss: 0.1508\n",
      "Epoch 586/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0204 - val_loss: 0.1498\n",
      "Epoch 587/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0201 - val_loss: 0.1497\n",
      "Epoch 588/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0199 - val_loss: 0.1496\n",
      "Epoch 589/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0202 - val_loss: 0.1497\n",
      "Epoch 590/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0206 - val_loss: 0.1499\n",
      "Epoch 591/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0197 - val_loss: 0.1507\n",
      "Epoch 592/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0206 - val_loss: 0.1509\n",
      "Epoch 593/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0200 - val_loss: 0.1502\n",
      "Epoch 594/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0198 - val_loss: 0.1506\n",
      "Epoch 595/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0200 - val_loss: 0.1512\n",
      "Epoch 596/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0200 - val_loss: 0.1508\n",
      "Epoch 597/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0198 - val_loss: 0.1508\n",
      "Epoch 598/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0207 - val_loss: 0.1506\n",
      "Epoch 599/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0197 - val_loss: 0.1511\n",
      "Epoch 600/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0199 - val_loss: 0.1512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc701adbc8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tiny.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model_tiny_df = pd.DataFrame(model_tiny.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc704b08c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_model_tiny_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  With early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tiny_es = Sequential()\n",
    "\n",
    "model_tiny_es.add(Dense(30, activation='relu'))\n",
    "\n",
    "model_tiny_es.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_tiny_es.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/600\n",
      "364/364 [==============================] - 1s 2ms/sample - loss: 0.6511 - val_loss: 0.6280\n",
      "Epoch 2/600\n",
      "364/364 [==============================] - 0s 115us/sample - loss: 0.6101 - val_loss: 0.5946\n",
      "Epoch 3/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.5772 - val_loss: 0.5647\n",
      "Epoch 4/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.5471 - val_loss: 0.5360\n",
      "Epoch 5/600\n",
      "364/364 [==============================] - 0s 110us/sample - loss: 0.5175 - val_loss: 0.5087\n",
      "Epoch 6/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.4893 - val_loss: 0.4831\n",
      "Epoch 7/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.4638 - val_loss: 0.4592\n",
      "Epoch 8/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.4380 - val_loss: 0.4362\n",
      "Epoch 9/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.4129 - val_loss: 0.4142\n",
      "Epoch 10/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.3905 - val_loss: 0.3952\n",
      "Epoch 11/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.3694 - val_loss: 0.3781\n",
      "Epoch 12/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.3506 - val_loss: 0.3634\n",
      "Epoch 13/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.3344 - val_loss: 0.3504\n",
      "Epoch 14/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.3184 - val_loss: 0.3398\n",
      "Epoch 15/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.3041 - val_loss: 0.3290\n",
      "Epoch 16/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.2913 - val_loss: 0.3190\n",
      "Epoch 17/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.2800 - val_loss: 0.3089\n",
      "Epoch 18/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.2690 - val_loss: 0.3031\n",
      "Epoch 19/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.2593 - val_loss: 0.2971\n",
      "Epoch 20/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.2505 - val_loss: 0.2901\n",
      "Epoch 21/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.2425 - val_loss: 0.2853\n",
      "Epoch 22/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.2341 - val_loss: 0.2781\n",
      "Epoch 23/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.2292 - val_loss: 0.2715\n",
      "Epoch 24/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.2195 - val_loss: 0.2728\n",
      "Epoch 25/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.2167 - val_loss: 0.2697\n",
      "Epoch 26/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.2093 - val_loss: 0.2624\n",
      "Epoch 27/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.2047 - val_loss: 0.2565\n",
      "Epoch 28/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.1991 - val_loss: 0.2556\n",
      "Epoch 29/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.1940 - val_loss: 0.2540\n",
      "Epoch 30/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.1901 - val_loss: 0.2482\n",
      "Epoch 31/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.1856 - val_loss: 0.2467\n",
      "Epoch 32/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.1812 - val_loss: 0.2420\n",
      "Epoch 33/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1775 - val_loss: 0.2372\n",
      "Epoch 34/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1743 - val_loss: 0.2375\n",
      "Epoch 35/600\n",
      "364/364 [==============================] - 0s 162us/sample - loss: 0.1715 - val_loss: 0.2313\n",
      "Epoch 36/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.1671 - val_loss: 0.2328\n",
      "Epoch 37/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.1645 - val_loss: 0.2290\n",
      "Epoch 38/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.1605 - val_loss: 0.2262\n",
      "Epoch 39/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.1577 - val_loss: 0.2220\n",
      "Epoch 40/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.1553 - val_loss: 0.2202\n",
      "Epoch 41/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1525 - val_loss: 0.2199\n",
      "Epoch 42/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.1497 - val_loss: 0.2148\n",
      "Epoch 43/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.1469 - val_loss: 0.2165\n",
      "Epoch 44/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1442 - val_loss: 0.2112\n",
      "Epoch 45/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1427 - val_loss: 0.2124\n",
      "Epoch 46/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.1395 - val_loss: 0.2065\n",
      "Epoch 47/600\n",
      "364/364 [==============================] - 0s 178us/sample - loss: 0.1376 - val_loss: 0.2049\n",
      "Epoch 48/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.1351 - val_loss: 0.2052\n",
      "Epoch 49/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.1338 - val_loss: 0.2058\n",
      "Epoch 50/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.1311 - val_loss: 0.2004\n",
      "Epoch 51/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1288 - val_loss: 0.1996\n",
      "Epoch 52/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1289 - val_loss: 0.2000\n",
      "Epoch 53/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1258 - val_loss: 0.1927\n",
      "Epoch 54/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1243 - val_loss: 0.1975\n",
      "Epoch 55/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1211 - val_loss: 0.1903\n",
      "Epoch 56/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.1199 - val_loss: 0.1892\n",
      "Epoch 57/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.1182 - val_loss: 0.1886\n",
      "Epoch 58/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1184 - val_loss: 0.1928\n",
      "Epoch 59/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1147 - val_loss: 0.1820\n",
      "Epoch 60/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1145 - val_loss: 0.1825\n",
      "Epoch 61/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.1117 - val_loss: 0.1891\n",
      "Epoch 62/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.1106 - val_loss: 0.1841\n",
      "Epoch 63/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1085 - val_loss: 0.1787\n",
      "Epoch 64/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1081 - val_loss: 0.1782\n",
      "Epoch 65/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.1070 - val_loss: 0.1832\n",
      "Epoch 66/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.1058 - val_loss: 0.1769\n",
      "Epoch 67/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1033 - val_loss: 0.1771\n",
      "Epoch 68/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1022 - val_loss: 0.1766\n",
      "Epoch 69/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1007 - val_loss: 0.1713\n",
      "Epoch 70/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1008 - val_loss: 0.1720\n",
      "Epoch 71/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0992 - val_loss: 0.1736\n",
      "Epoch 72/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0974 - val_loss: 0.1732\n",
      "Epoch 73/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0961 - val_loss: 0.1695\n",
      "Epoch 74/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0957 - val_loss: 0.1656\n",
      "Epoch 75/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0951 - val_loss: 0.1708\n",
      "Epoch 76/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0936 - val_loss: 0.1669\n",
      "Epoch 77/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0923 - val_loss: 0.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0912 - val_loss: 0.1659\n",
      "Epoch 79/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0903 - val_loss: 0.1643\n",
      "Epoch 80/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0895 - val_loss: 0.1692\n",
      "Epoch 81/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0883 - val_loss: 0.1645\n",
      "Epoch 82/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0882 - val_loss: 0.1637\n",
      "Epoch 83/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0867 - val_loss: 0.1602\n",
      "Epoch 84/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0864 - val_loss: 0.1642\n",
      "Epoch 85/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0847 - val_loss: 0.1587\n",
      "Epoch 86/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0840 - val_loss: 0.1603\n",
      "Epoch 87/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0839 - val_loss: 0.1640\n",
      "Epoch 88/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0834 - val_loss: 0.1549\n",
      "Epoch 89/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0811 - val_loss: 0.1615\n",
      "Epoch 90/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0815 - val_loss: 0.1618\n",
      "Epoch 91/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0798 - val_loss: 0.1548\n",
      "Epoch 92/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0793 - val_loss: 0.1538\n",
      "Epoch 93/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0785 - val_loss: 0.1548\n",
      "Epoch 94/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0778 - val_loss: 0.1562\n",
      "Epoch 95/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0772 - val_loss: 0.1536\n",
      "Epoch 96/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0765 - val_loss: 0.1536\n",
      "Epoch 97/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0758 - val_loss: 0.1535\n",
      "Epoch 98/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0751 - val_loss: 0.1518\n",
      "Epoch 99/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0745 - val_loss: 0.1507\n",
      "Epoch 100/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0740 - val_loss: 0.1518\n",
      "Epoch 101/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0731 - val_loss: 0.1472\n",
      "Epoch 102/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0730 - val_loss: 0.1456\n",
      "Epoch 103/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0721 - val_loss: 0.1495\n",
      "Epoch 104/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0714 - val_loss: 0.1492\n",
      "Epoch 105/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0712 - val_loss: 0.1465\n",
      "Epoch 106/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0702 - val_loss: 0.1479\n",
      "Epoch 107/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0711 - val_loss: 0.1524\n",
      "Epoch 108/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0695 - val_loss: 0.1440\n",
      "Epoch 109/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0689 - val_loss: 0.1456\n",
      "Epoch 110/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0690 - val_loss: 0.1516\n",
      "Epoch 111/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0676 - val_loss: 0.1419\n",
      "Epoch 112/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0679 - val_loss: 0.1452\n",
      "Epoch 113/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0670 - val_loss: 0.1445\n",
      "Epoch 114/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0664 - val_loss: 0.1477\n",
      "Epoch 115/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0654 - val_loss: 0.1430\n",
      "Epoch 116/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0659 - val_loss: 0.1402\n",
      "Epoch 117/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0648 - val_loss: 0.1493\n",
      "Epoch 118/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0651 - val_loss: 0.1412\n",
      "Epoch 119/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0639 - val_loss: 0.1446\n",
      "Epoch 120/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0634 - val_loss: 0.1440\n",
      "Epoch 121/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0637 - val_loss: 0.1403\n",
      "Epoch 122/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0629 - val_loss: 0.1401\n",
      "Epoch 123/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0615 - val_loss: 0.1495\n",
      "Epoch 124/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0619 - val_loss: 0.1421\n",
      "Epoch 125/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0637 - val_loss: 0.1507\n",
      "Epoch 126/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0605 - val_loss: 0.1409\n",
      "Epoch 127/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0607 - val_loss: 0.1386\n",
      "Epoch 128/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0597 - val_loss: 0.1426\n",
      "Epoch 129/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0611 - val_loss: 0.1466\n",
      "Epoch 130/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0595 - val_loss: 0.1422\n",
      "Epoch 131/600\n",
      "364/364 [==============================] - 0s 116us/sample - loss: 0.0587 - val_loss: 0.1447\n",
      "Epoch 132/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0602 - val_loss: 0.1396\n",
      "Epoch 133/600\n",
      "364/364 [==============================] - 0s 116us/sample - loss: 0.0593 - val_loss: 0.1487\n",
      "Epoch 134/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0580 - val_loss: 0.1383\n",
      "Epoch 135/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0574 - val_loss: 0.1391\n",
      "Epoch 136/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0568 - val_loss: 0.1437\n",
      "Epoch 137/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0571 - val_loss: 0.1397\n",
      "Epoch 138/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0566 - val_loss: 0.1406\n",
      "Epoch 139/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0572 - val_loss: 0.1462\n",
      "Epoch 140/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0557 - val_loss: 0.1359\n",
      "Epoch 141/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0561 - val_loss: 0.1408\n",
      "Epoch 142/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0559 - val_loss: 0.1364\n",
      "Epoch 143/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0554 - val_loss: 0.1465\n",
      "Epoch 144/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0545 - val_loss: 0.1387\n",
      "Epoch 145/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0569 - val_loss: 0.1350\n",
      "Epoch 146/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0546 - val_loss: 0.1504\n",
      "Epoch 147/600\n",
      "364/364 [==============================] - 0s 118us/sample - loss: 0.0549 - val_loss: 0.1368\n",
      "Epoch 148/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0530 - val_loss: 0.1389\n",
      "Epoch 149/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0535 - val_loss: 0.1418\n",
      "Epoch 150/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0525 - val_loss: 0.1357\n",
      "Epoch 151/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0522 - val_loss: 0.1375\n",
      "Epoch 152/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0520 - val_loss: 0.1382\n",
      "Epoch 153/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0529 - val_loss: 0.1418\n",
      "Epoch 154/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0543 - val_loss: 0.1333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0521 - val_loss: 0.1467\n",
      "Epoch 156/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0514 - val_loss: 0.1373\n",
      "Epoch 157/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0505 - val_loss: 0.1338\n",
      "Epoch 158/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0510 - val_loss: 0.1367\n",
      "Epoch 159/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0503 - val_loss: 0.1359\n",
      "Epoch 160/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0497 - val_loss: 0.1377\n",
      "Epoch 161/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0497 - val_loss: 0.1378\n",
      "Epoch 162/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0496 - val_loss: 0.1368\n",
      "Epoch 163/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0493 - val_loss: 0.1361\n",
      "Epoch 164/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0491 - val_loss: 0.1360\n",
      "Epoch 165/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0496 - val_loss: 0.1322\n",
      "Epoch 166/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0493 - val_loss: 0.1404\n",
      "Epoch 167/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0485 - val_loss: 0.1398\n",
      "Epoch 168/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0483 - val_loss: 0.1361\n",
      "Epoch 169/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0483 - val_loss: 0.1330\n",
      "Epoch 170/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0475 - val_loss: 0.1379\n",
      "Epoch 171/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0472 - val_loss: 0.1387\n",
      "Epoch 172/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0474 - val_loss: 0.1358\n",
      "Epoch 173/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0477 - val_loss: 0.1389\n",
      "Epoch 174/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0473 - val_loss: 0.1332\n",
      "Epoch 175/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0468 - val_loss: 0.1406\n",
      "Epoch 176/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0465 - val_loss: 0.1356\n",
      "Epoch 177/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0460 - val_loss: 0.1379\n",
      "Epoch 178/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0464 - val_loss: 0.1354\n",
      "Epoch 179/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0459 - val_loss: 0.1387\n",
      "Epoch 180/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0456 - val_loss: 0.1369\n",
      "Epoch 181/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0453 - val_loss: 0.1343\n",
      "Epoch 182/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0451 - val_loss: 0.1361\n",
      "Epoch 183/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0449 - val_loss: 0.1366\n",
      "Epoch 184/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0446 - val_loss: 0.1318\n",
      "Epoch 185/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0447 - val_loss: 0.1356\n",
      "Epoch 186/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0449 - val_loss: 0.1393\n",
      "Epoch 187/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0440 - val_loss: 0.1345\n",
      "Epoch 188/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0443 - val_loss: 0.1360\n",
      "Epoch 189/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0439 - val_loss: 0.1366\n",
      "Epoch 190/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0435 - val_loss: 0.1360\n",
      "Epoch 191/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0435 - val_loss: 0.1357\n",
      "Epoch 192/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0433 - val_loss: 0.1350\n",
      "Epoch 193/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0432 - val_loss: 0.1322\n",
      "Epoch 194/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0430 - val_loss: 0.1367\n",
      "Epoch 195/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0435 - val_loss: 0.1327\n",
      "Epoch 196/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0428 - val_loss: 0.1378\n",
      "Epoch 197/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0443 - val_loss: 0.1330\n",
      "Epoch 198/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0427 - val_loss: 0.1429\n",
      "Epoch 199/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0425 - val_loss: 0.1364\n",
      "Epoch 200/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0417 - val_loss: 0.1361\n",
      "Epoch 201/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0423 - val_loss: 0.1384\n",
      "Epoch 202/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0416 - val_loss: 0.1361\n",
      "Epoch 203/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0421 - val_loss: 0.1314\n",
      "Epoch 204/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0416 - val_loss: 0.1374\n",
      "Epoch 205/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0414 - val_loss: 0.1346\n",
      "Epoch 206/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0408 - val_loss: 0.1370\n",
      "Epoch 207/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0410 - val_loss: 0.1350\n",
      "Epoch 208/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0412 - val_loss: 0.1399\n",
      "Epoch 209/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0406 - val_loss: 0.1331\n",
      "Epoch 210/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0411 - val_loss: 0.1325\n",
      "Epoch 211/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0405 - val_loss: 0.1387\n",
      "Epoch 212/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0415 - val_loss: 0.1412\n",
      "Epoch 213/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0425 - val_loss: 0.1327\n",
      "Epoch 214/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0397 - val_loss: 0.1378\n",
      "Epoch 215/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0401 - val_loss: 0.1396\n",
      "Epoch 216/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0402 - val_loss: 0.1327\n",
      "Epoch 217/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0412 - val_loss: 0.1418\n",
      "Epoch 218/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0396 - val_loss: 0.1333\n",
      "Epoch 219/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0394 - val_loss: 0.1355\n",
      "Epoch 220/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0389 - val_loss: 0.1348\n",
      "Epoch 221/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0388 - val_loss: 0.1344\n",
      "Epoch 222/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0387 - val_loss: 0.1363\n",
      "Epoch 223/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0383 - val_loss: 0.1374\n",
      "Epoch 224/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0387 - val_loss: 0.1379\n",
      "Epoch 225/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0382 - val_loss: 0.1361\n",
      "Epoch 226/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0388 - val_loss: 0.1336\n",
      "Epoch 227/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0380 - val_loss: 0.1385\n",
      "Epoch 228/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0381 - val_loss: 0.1364\n",
      "Epoch 00228: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc719fb388>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tiny_es.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_val, y_val), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model_tiny_es_df = pd.DataFrame(model_tiny_es.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc71f33548>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_model_tiny_es_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## medium size neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_med_es = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model_med_es.add(Dense(30, activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "model_med_es.add(Dense(15, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model_med_es.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_med_es.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/600\n",
      "364/364 [==============================] - 1s 3ms/sample - loss: 0.6859 - val_loss: 0.6739\n",
      "Epoch 2/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.6640 - val_loss: 0.6531\n",
      "Epoch 3/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.6411 - val_loss: 0.6307\n",
      "Epoch 4/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.6180 - val_loss: 0.6062\n",
      "Epoch 5/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.5897 - val_loss: 0.5779\n",
      "Epoch 6/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.5581 - val_loss: 0.5477\n",
      "Epoch 7/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.5238 - val_loss: 0.5184\n",
      "Epoch 8/600\n",
      "364/364 [==============================] - 0s 173us/sample - loss: 0.4880 - val_loss: 0.4855\n",
      "Epoch 9/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.4518 - val_loss: 0.4538\n",
      "Epoch 10/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.4149 - val_loss: 0.4218\n",
      "Epoch 11/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.3800 - val_loss: 0.3921\n",
      "Epoch 12/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.3454 - val_loss: 0.3611\n",
      "Epoch 13/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.3117 - val_loss: 0.3356\n",
      "Epoch 14/600\n",
      "364/364 [==============================] - 0s 162us/sample - loss: 0.2830 - val_loss: 0.3106\n",
      "Epoch 15/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.2575 - val_loss: 0.2930\n",
      "Epoch 16/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.2376 - val_loss: 0.2735\n",
      "Epoch 17/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.2192 - val_loss: 0.2626\n",
      "Epoch 18/600\n",
      "364/364 [==============================] - 0s 166us/sample - loss: 0.2022 - val_loss: 0.2497\n",
      "Epoch 19/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1908 - val_loss: 0.2409\n",
      "Epoch 20/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.1821 - val_loss: 0.2279\n",
      "Epoch 21/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1671 - val_loss: 0.2193\n",
      "Epoch 22/600\n",
      "364/364 [==============================] - 0s 163us/sample - loss: 0.1615 - val_loss: 0.2154\n",
      "Epoch 23/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1527 - val_loss: 0.2092\n",
      "Epoch 24/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.1455 - val_loss: 0.2036\n",
      "Epoch 25/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.1370 - val_loss: 0.1977\n",
      "Epoch 26/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.1320 - val_loss: 0.1907\n",
      "Epoch 27/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.1257 - val_loss: 0.1924\n",
      "Epoch 28/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.1235 - val_loss: 0.1793\n",
      "Epoch 29/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.1200 - val_loss: 0.1792\n",
      "Epoch 30/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.1214 - val_loss: 0.1772\n",
      "Epoch 31/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.1093 - val_loss: 0.1705\n",
      "Epoch 32/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1120 - val_loss: 0.1754\n",
      "Epoch 33/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.1052 - val_loss: 0.1645\n",
      "Epoch 34/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0966 - val_loss: 0.1765\n",
      "Epoch 35/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0959 - val_loss: 0.1634\n",
      "Epoch 36/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0926 - val_loss: 0.1584\n",
      "Epoch 37/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0910 - val_loss: 0.1647\n",
      "Epoch 38/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0881 - val_loss: 0.1567\n",
      "Epoch 39/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0847 - val_loss: 0.1596\n",
      "Epoch 40/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0866 - val_loss: 0.1557\n",
      "Epoch 41/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0793 - val_loss: 0.1485\n",
      "Epoch 42/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0779 - val_loss: 0.1525\n",
      "Epoch 43/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0808 - val_loss: 0.1450\n",
      "Epoch 44/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0758 - val_loss: 0.1451\n",
      "Epoch 45/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0759 - val_loss: 0.1512\n",
      "Epoch 46/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.0694 - val_loss: 0.1395\n",
      "Epoch 47/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0694 - val_loss: 0.1484\n",
      "Epoch 48/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0684 - val_loss: 0.1420\n",
      "Epoch 49/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0679 - val_loss: 0.1469\n",
      "Epoch 50/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.0658 - val_loss: 0.1388\n",
      "Epoch 51/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0632 - val_loss: 0.1413\n",
      "Epoch 52/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0615 - val_loss: 0.1391\n",
      "Epoch 53/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0604 - val_loss: 0.1415\n",
      "Epoch 54/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.0611 - val_loss: 0.1430\n",
      "Epoch 55/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0594 - val_loss: 0.1376\n",
      "Epoch 56/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0572 - val_loss: 0.1369\n",
      "Epoch 57/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0560 - val_loss: 0.1396\n",
      "Epoch 58/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0558 - val_loss: 0.1389\n",
      "Epoch 59/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0551 - val_loss: 0.1338\n",
      "Epoch 60/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0546 - val_loss: 0.1362\n",
      "Epoch 61/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0527 - val_loss: 0.1363\n",
      "Epoch 62/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0516 - val_loss: 0.1343\n",
      "Epoch 63/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0530 - val_loss: 0.1349\n",
      "Epoch 64/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0514 - val_loss: 0.1398\n",
      "Epoch 65/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0566 - val_loss: 0.1318\n",
      "Epoch 66/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0478 - val_loss: 0.1395\n",
      "Epoch 67/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0479 - val_loss: 0.1318\n",
      "Epoch 68/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0470 - val_loss: 0.1319\n",
      "Epoch 69/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0476 - val_loss: 0.1361\n",
      "Epoch 70/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0477 - val_loss: 0.1286\n",
      "Epoch 71/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0481 - val_loss: 0.1352\n",
      "Epoch 72/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0472 - val_loss: 0.1314\n",
      "Epoch 73/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0446 - val_loss: 0.1327\n",
      "Epoch 74/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0430 - val_loss: 0.1358\n",
      "Epoch 75/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0440 - val_loss: 0.1357\n",
      "Epoch 76/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0429 - val_loss: 0.1321\n",
      "Epoch 77/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0420 - val_loss: 0.1349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0408 - val_loss: 0.1313\n",
      "Epoch 79/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0413 - val_loss: 0.1317\n",
      "Epoch 80/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0408 - val_loss: 0.1360\n",
      "Epoch 81/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0433 - val_loss: 0.1328\n",
      "Epoch 82/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0422 - val_loss: 0.1320\n",
      "Epoch 83/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0397 - val_loss: 0.1361\n",
      "Epoch 84/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0378 - val_loss: 0.1322\n",
      "Epoch 85/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0380 - val_loss: 0.1351\n",
      "Epoch 86/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0378 - val_loss: 0.1325\n",
      "Epoch 87/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0379 - val_loss: 0.1330\n",
      "Epoch 88/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0381 - val_loss: 0.1355\n",
      "Epoch 89/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0382 - val_loss: 0.1323\n",
      "Epoch 90/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0377 - val_loss: 0.1339\n",
      "Epoch 91/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.0355 - val_loss: 0.1359\n",
      "Epoch 92/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0360 - val_loss: 0.1356\n",
      "Epoch 93/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0354 - val_loss: 0.1345\n",
      "Epoch 94/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0344 - val_loss: 0.1385\n",
      "Epoch 95/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0360 - val_loss: 0.1362\n",
      "Epoch 00095: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc74205388>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_med_es.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_val, y_val), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model_med_es_df = pd.DataFrame(model_med_es.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc75be1588>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9b3/8ddnZrLvCQlkISQge8IiYVEUd0VFcEEFxYW6tLVqr7da7a+t12q9ttq69JZ7W9uqWFGgiIpW3FFcAAkQ9i2GJRuQjZB9kpnv748TIGACAyScZPJ5Ph551DnnzJnPnA7v+c73fM/3iDEGpZRSXZ/D7gKUUkq1Dw10pZTyExroSinlJzTQlVLKT2igK6WUn3DZ9cI9evQwaWlpdr28Ukp1SatWrSo1xsS3ts62QE9LSyM7O9uul1dKqS5JRHa1tU67XJRSyk/4FOgiMlFEtopIrog80sr650Qkp/lvm4jsb/9SlVJKHctxu1xExAnMAi4BCoCVIrLIGLPp4DbGmAdabH8fMLIDalVKKXUMvvShjwFyjTF5ACIyF5gCbGpj++nAf7VPeUopf9PY2EhBQQH19fV2l9KpBQcHk5KSQkBAgM/P8SXQk4H8Fo8LgLGtbSgifYB04LM21t8N3A2Qmprqc5FKKf9RUFBAREQEaWlpiIjd5XRKxhjKysooKCggPT3d5+f50ofe2hFva0avacACY4yntZXGmBeNMVnGmKz4+FZH3Sil/Fx9fT1xcXEa5scgIsTFxZ3wrxhfAr0A6N3icQpQ1Ma204A3TqgCpVS3o2F+fCdzjHwJ9JVAfxFJF5FArNBe1MqLDwRigGW+vHBZjftE6lRKKXUcxw10Y0wTcC/wIbAZmG+M2Sgij4vI5BabTgfmGh8nWC/eX8eeSj0popQ6/cLDw+0uoUP4dKWoMeZ94P2jlj161OPHTvTFX/h0G09dO+xEn6aUUqoVtl0pGhcWyPzsAr4rqbarBKVUN2eM4aGHHiIjI4PMzEzmzZsHQHFxMRMmTGDEiBFkZGTw5Zdf4vF4uP322w9t+9xzz9lc/ffZNpdLL08R9S4Hf/hwK/83Y5RdZSilbPSbdzeyqehAu+5zSFIk/3XVUJ+2XbhwITk5Oaxdu5bS0lJGjx7NhAkTeP3117nsssv45S9/icfjoba2lpycHAoLC9mwYQMA+/d3vgvibWuhS8MBfpu5h8Ub9pCT3/kOjFLK/3311VdMnz4dp9NJz549Oe+881i5ciWjR4/m5Zdf5rHHHmP9+vVERETQt29f8vLyuO+++/jggw+IjIy0u/zvsa2FjiuIyXv/j6dCf8PvFm/mjbvG6VAmpboZX1vSHaWtMRwTJkxg6dKl/Pvf/+aWW27hoYce4tZbb2Xt2rV8+OGHzJo1i/nz5/PSSy+d5oqPzb7ZFiOTcZZu4YUB61ieV87S7aW2laKU6p4mTJjAvHnz8Hg8lJSUsHTpUsaMGcOuXbtISEjgrrvu4o477mD16tWUlpbi9Xq57rrreOKJJ1i9erXd5X+PfS304Cjo059xu//KwOjn+eNHW5nQv4e20pVSp80111zDsmXLGD58OCLC008/Ta9evZg9ezbPPPMMAQEBhIeH8+qrr1JYWMjMmTPxer0APPXUUzZX/33i47DxdpeVlWWyF/0NXjyfLX1/wMRNF/O3W7O4ZEhPW+pRSp0emzdvZvDgwXaX0SW0dqxEZJUxJqu17e29wUXSSBg+nYG7XmNcTBXPfrwNr9eeLxillOrq7L9j0YW/RsTB03Hvsbn4AB9s3GN3RUop1SXZH+hRyTDmbnoXvMfFcWU8+/E2PNpKV0qpE2Z/oAOc8wASFMFvI98md181765tazJHpZRSbekcgR4aC2ffT6/iT5nSo4jnP9lGk8drd1VKKdWldI5ABxj3IwjtwaOhb7KzrJa31hTaXZFSSnUpnSfQgyJgwoPE7VvGzQl5/Omz7TRqK10ppXzWeQIdYNRMiEzh56755JfX8uaqArsrUkp1c8eaO33nzp1kZGScxmqOrXMFekAwnPcQUeXruK3nDv7ns1zcTdpKV0opX9h36X9bhk+Hz3/PA0HvMHtvX+Zn5zNjXB+7q1JKdYTFj8Ce9e27z16ZcPnv2lz98MMP06dPH+655x4AHnvsMUSEpUuXUlFRQWNjI7/97W+ZMmXKCb1sfX09P/7xj8nOzsblcvHss89ywQUXsHHjRmbOnInb7cbr9fLmm2+SlJTEDTfcQEFBAR6Ph1//+tfceOONp/S2obO10AFcQTD+fqL3reTmxEJmLcmlvtFjd1VKKT8xbdq0QzeyAJg/fz4zZ87krbfeYvXq1SxZsoSf/exnbc7E2JZZs2YBsH79et544w1uu+026uvr+ctf/sJPf/pTcnJyyM7OJiUlhQ8++ICkpCTWrl3Lhg0bmDhxYru8t87XQgc48zZY+gw/C3mPOcU/5F/Z+dxyVprdVSml2tsxWtIdZeTIkezbt4+ioiJKSkqIiYkhMTGRBx54gKVLl+JwOCgsLGTv3r306tXL5/1+9dVX3HfffQAMGjSIPn36sG3bNs466yyefPJJCgoKuPbaa+nfvz+ZmZk8+OCDPPzww0yaNIlzzz23Xd5b52uhAwSGwrh7iC36gmt6lfLKNztP+NtSKaXaMnXqVBYsWMC8efOYNm0ac+bMoaSkhFWrVpGTk0PPnj2prz+xm9i3lVE33XQTixYtIiQkhMsuu4zPPvuMAQMGsGrVKjIzM/nFL37B448/3h5vq5MGOsCYuyAoip+FvMd3JTUs+67M7oqUUn5i2rRpzJ07lwULFjB16lQqKytJSEggICCAJUuWsGvXrhPe54QJE5gzZw4A27ZtY/fu3QwcOJC8vDz69u3L/fffz+TJk1m3bh1FRUWEhoYyY8YMHnzwwXabW92nQBeRiSKyVURyReSRNra5QUQ2ichGEXn9lCsLjoIxd5Fc/DEjQ/byz+UnfoCVUqo1Q4cOpaqqiuTkZBITE7n55pvJzs4mKyuLOXPmMGjQoBPe5z333IPH4yEzM5Mbb7yRV155haCgIObNm0dGRgYjRoxgy5Yt3Hrrraxfv54xY8YwYsQInnzySX71q1+1y/s67nzoIuIEtgGXAAXASmC6MWZTi236A/OBC40xFSKSYIzZd6z9ZmVlmezs7GNXV1MKz2WQE3MJ1xVO5+uHL6RXVLAv70sp1UnpfOi+64j50McAucaYPGOMG5gLHD2e5y5gljGmAuB4Ye6zsB6QOZVhFR8TZqp5/dvd7bJbpZTyR74EejKQ3+JxQfOylgYAA0TkaxFZLiKtjsERkbtFJFtEsktKSnyrcPSdOJrqeLjXGt74drdOB6CUOu3Wr1/PiBEjjvgbO3as3WV9jy/DFlu7yefR/TQuoD9wPpACfCkiGcaY/Uc8yZgXgRfB6nLxqcKkEZCcxdUHFvPLqvF8tHEvVw5L9OmpSqnOyRjTpe4fnJmZSU5Ozml9zZMZ2edLC70A6N3icQpw9ITlBcA7xphGY8wOYCtWwLeP0XcSVrWDKVG5vLpsZ7vtVil1+gUHB1NWVqZDkY/BGENZWRnBwSd2ztCXFvpKoL+IpAOFwDTgpqO2eRuYDrwiIj2wumDyTqiSYxl6DXz4C+4PW8pFO/rzXUk1/eLbnjBHKdV5paSkUFBQgM/drt1UcHAwKSkpJ/Sc4wa6MaZJRO4FPgScwEvGmI0i8jiQbYxZ1LzuUhHZBHiAh4wx7TdwPCAYRt5C32WzSJRrWLi6gIcuO/FhRUop+wUEBJCenm53GX7puMMWO4pPwxZbKs+DP53J21EzeLr+Gr56+EIcjq7TB6eUUu3hVIctdg6xfeGMi5nY8AH7KqtZlqdXjiqlVEtdJ9ABsn5AcH0JVwSv15tfKKXUUbpWoPe/FMJ78eOIr1m8YQ/VDU12V6SUUp1G1wp0pwtG3MSg6uVENpaweH2x3RUppVSn0bUCHWDkDMR4uTNiGW+u1m4XpZQ6qOsFelw/SDuX651fsCKvlPzyWrsrUkqpTqHrBTrAyFuIri9gnGMzb60ptLsapZTqFLpmoA+ZDEFR3BP5De/kFOolxEopRVcN9IAQGHYDZ7u/pqRkL1v2VNldkVJK2a5rBjrAmbfg9Lq51vUN7649eq4wpZTqfrpuoCcOh8Th/CBkKe+tLdJuF6VUt9d1Ax1g1O2kNuYRu3896woq7a5GKaVs1bUDPfN6TEAYMwI+1W4XpVS317UDPSgCyZzKVc7lfLEuF69Xu12UUt1X1w50gKyZBJkGxtV8yqrdFXZXo5RStun6gZ40Ek+v4cxwfca7OXqRkVKq++r6gQ44s2YyUHaze/1Smjxeu8tRSilb+EWgkzmVJmcoVzZ8wIod5XZXo5RStvCPQA+KgMypTHIuZ0nONrurUUopW/hHoAOurNsJETdsXoRHR7sopbohvwl0ks+kOjyNixs/Z9UuHe2ilOp+fAp0EZkoIltFJFdEHmll/e0iUiIiOc1/d7Z/qcctkoCR0xjn2MzXq9ac9pdXSim7HTfQRcQJzAIuB4YA00VkSCubzjPGjGj++3s71+mToJE3AhC4eaFeZKSU6nZ8aaGPAXKNMXnGGDcwF5jSsWWdpNi+lMWM4KLGL1iTv9/uapRS6rTyJdCTgfwWjwualx3tOhFZJyILRKR3u1R3EkKzpjPIkc+qFV/aVYJSStnCl0CXVpYd3Z/xLpBmjBkGfALMbnVHIneLSLaIZJeUlJxYpT4KGTGVJpyEbX1Tp9RVSnUrvgR6AdCyxZ0CHDG1oTGmzBjT0Pzwb8Co1nZkjHnRGJNljMmKj48/mXqPL6wH+xLGc2HTUtYX6GgXpVT34UugrwT6i0i6iAQC04BFLTcQkcQWDycDm9uvxBMXNXYGiVLOhq/ft7MMpZQ6rY4b6MaYJuBe4EOsoJ5vjNkoIo+LyOTmze4XkY0isha4H7i9owr2RVjmVdRJCFG5C7XbRSnVbbh82cgY8z7w/lHLHm3x378AftG+pZ2CwFCKky5hQsHHbMnfx+DUnnZXpJRSHc5/rhQ9Stz424iQOvK+nGd3KUopdVr4baBHDbqQEmcCCXkL7S5FKaVOC78NdBwOilOncGZTDjt25NpdjVJKdTj/DXQg8byZOMVQtPQVu0tRSqkO59eBHp82lC2uwaTsfgd0tItSys/5daADlPa7hj6e3RRvWW53KUop1aH8PtDTzruFBhNA2dev2F2KUkp1KL8P9JSkJFYGjSW18H1octtdjlJKdRi/D3SA/QOmEmkOUL72PbtLUUqpDtMtAn3IOVdTYiI5sOI1u0tRSqkO0y0CvW+vGJYGnU/Kvi+gttzucpRSqkN0i0AHqB10PS6aqFmzwO5SlFKqQ3SbQB85ZgJbvSnUZWu3i1LKP3WbQB+aHMUngRfSo2ItlH1ndzlKKdXuuk2giwjuwdfhNYJ79Rt2l6OUUu2u2wQ6wPgzh/GVN4OmNa+D12t3OUop1a66VaCP6hPDR64LCK0thHydCkAp5V+6VaA7HYJj6CRqTRCeHO12UUr5l24V6AAXZKaz2DsGs2EhuGvsLkcppdpNtwv0s/vFschxMa7Gatj4tt3lKKVUu+l2gR7kchI1cAI7SMasetnucpRSqt10u0AHuGJYEnMaz0cKVsK+zXaXo5RS7cKnQBeRiSKyVURyReSRY2w3VUSMiGS1X4nt7/yB8XzgPJ8mccGq2XaXo5RS7eK4gS4iTmAWcDkwBJguIkNa2S4CuB9Y0d5FtrfgACejhvTnUzMas24uNNbbXZJSSp0yX1roY4BcY0yeMcYNzAWmtLLdE8DTQJdIxyszE5ntvgCpq4DN79pdjlJKnTJfAj0ZyG/xuKB52SEiMhLobYw55h0kRORuEckWkeySkpITLrY9TRgQz/qAYZQFJMFq7XZRSnV9vgS6tLLMHFop4gCeA352vB0ZY140xmQZY7Li4+N9r7IDBAc4uXhIIq81ng87v4TSXFvrUUqpU+VLoBcAvVs8TgGKWjyOADKAz0VkJzAOWNTZT4yC1e3yWv14vOKENf+0uxyllDolvgT6SqC/iKSLSCAwDVh0cKUxptIY08MYk2aMSQOWA5ONMdkdUnE7OndAD+qD4tkcPhbWzgVPk90lKaXUSTtuoBtjmoB7gQ+BzcB8Y8xGEXlcRCZ3dIEdKcjl5JKhPXmx6myo3gPffWp3SUopddJ8GodujHnfGDPAGNPPGPNk87JHjTGLWtn2/K7QOj9o0rBE3q8fhjsoBtbo3YyUUl1Xt7xStKVzzognJDiYZWEXw9bFUFNmd0lKKXVSun2gB7ocXDa0F8+XjQVvI6z/l90lKaXUSen2gQ4waXgSaxqSqIwZCjna7aKU6po00LGm1I0JDeCjgIthz3ooXmd3SUopdcI00IEAp4OJGb14ds8wjDMQcubYXZJSSp0wDfRmk4YlUewOoTjxIlg3Dxrr7C5JKaVOiAZ6s7HpsfQID2SeuRTqKiDndbtLUkqpE6KB3szldHB5RiJ/3d0LT+KZsOzP4PXYXZZSSvlMA72FScMSqW80rEq5FcrzYMsxJ49USqlORQO9hay0WBIigvh76RCI7QtfvwDGHP+JSinVCWigt+B0CFdkJvL5tnLqRv8YClfBrm/sLksppXyigX6UySOScHu8vO+4AEJ7WK10pZTqAjTQjzKydzS9Y0N4e0M5jP0hbP8Q9m22uyyllDouDfSjiAhXDUvim+/KKBtyCwSEaitdKdUlaKC3YvKIJDxew79zG+DM26wJu/bnH/+JSillIw30VgzqFcmAnuEsyimCs35iLVw2y96ilFLqODTQ2zBlRDLZuyoopAdk3gCrZ+tc6UqpTk0DvQ1XDUsC4N21RTD+p9BYC9++aHNVSinVNg30NqTGhTKid7TV7ZIwCAZNgm//Cg3VdpemlFKt0kA/hsnDk9hUfIDcfVUw/j+sSbtWv2p3WUop1SoN9GOYNCwRh8Dba4qg92hIO9eatKux3u7SlFLqe3wKdBGZKCJbRSRXRB5pZf2PRGS9iOSIyFciMqT9Sz39EiKDmTAgnvnZ+TR6vHDez+FAIXzxO7tLU0qp7zluoIuIE5gFXA4MAaa3EtivG2MyjTEjgKeBZ9u9UpvMGNuHfVUNfLJpL6RPgJEzrAuNClfZXZpSSh3Blxb6GCDXGJNnjHEDc4EpLTcwxhxo8TAM8JspCi8YlEBSVDCvrdhlLbjsvyEiEd6+R7telFKdii+Bngy0vEyyoHnZEUTkJyLyHVYL/f7WdiQid4tItohkl5SUnEy9p53TIUwfk8rXuWXklVRDcBRc9Sco2aJdL0qpTsWXQJdWln2vBW6MmWWM6Qc8DPyqtR0ZY140xmQZY7Li4+NPrFIb3TimNy6H8PqK3daC/hdr14tSqtPxJdALgN4tHqcARcfYfi5w9akU1dkkRARz2dBe/GtVAfWNzbelO9j18s594Gmyt0CllMK3QF8J9BeRdBEJBKYBi1puICL9Wzy8EtjefiV2DjePS6WyrpH31hVbC4KjYOLvYN9GvYJUKdUpHDfQjTFNwL3Ah8BmYL4xZqOIPC4ik5s3u1dENopIDvCfwG0dVrFNzuobR9/4MF5bvuvwwsFXwRkXw5L/hgPF9hWnlFL4OA7dGPO+MWaAMaafMebJ5mWPGmMWNf/3T40xQ40xI4wxFxhjNnZk0XYQEW4e24ec/P2szd9/cCFc/jR43PBRq6cNlFLqtNErRU/ADVkpRAS5eHFp3uGFcf3gnP+ADQsg7wv7ilNKdXsa6CcgIjiAm8f1YfGGYnaW1hxecc4DEN0H3n8QmhrsK1Ap1a1poJ+gmePTcDkc/P2rFq30gBC44hko3QZzbwJ3rX0FKqW6LQ30E9QzMphrRibzr+wCSqtbtMYHXGZdcPTdZ/DPq62ZGZVS6jTSQD8Jd03oS0OTl1e/2XnkilG3wdSXoXA1vDIJqvbaUp9SqnvSQD8JZySEc8mQnsxetouahqMuKhp6Ndw8H8p3wCtX6m3rlFKnjQb6SfrReX2prGtk3sr876/sdyHMWACV+fD69eCu+f42SinVzjTQT9KoPrGMSY9l1pJcKusav79Bn7Nh6ktQtAbm3waeVrZRSql2pIF+Ch6dNITyWjfPf7Kt9Q0GXQmTnofcj+Gde8HrPb0FKqW6FQ30U5CRHMX0Mam8umwXW/dUtb7RqNvggl/Burnwr1uhbv/pLVIp1W1ooJ+ihy4dSHiQi8cWbcSYNu7rMeFBuPRJ2LoY/nouFOiUu0qp9qeBfopiwgJ58LKBLMsr4/31e1rfSATOvhd+8KE1k/xLl8Lyv5zWOpVS/k8DvR3cNCaVIYmRPPnvTdS6jzE3ekoW/Ggp9L8MPngYVui0u0qp9qOB3g6cDuHxKUMpqqzn+U+OMxV8SAzc8CoMvAIW/xw2vnV6ilRK+T0N9HaSlRbL9DGp/P3LPNYXVB57Y6fLGtKYOg4W3q2zNCql2oUGejt65PJB9AgP4uE319HoOc4QxYAQmP4GxPaDuTdD/renp0illN/SQG9HUSEBPD5lKJuKD/CPr3Yc/wkhMXDLQgiNhZcvt246rWPVlVInSQO9nU3MSOTSIT157uNtR86Z3pbIJPjhFzDwcvj4UZgzFapLOr5QpZTf0UDvAI9PySDQ6eCRhevwetsYm95SSAzc8E+48o+w8yuYNRree8DqW/d6Or5gpZRf0EDvAL2igvnllYNZnlfOK0dPsdsWERh9J9y9BPqeD2vnwquT4Y8D4dMn9ApTpdRxaaB3kBtH9+aiQQn8/oMt5O5rY1qA1vQcCte/Ag/lwvWzofdY+PIP8MJw+Op5vRuSUqpNGugdRER46rpMQgOdPDBv7fFHvRwtMMyaW33aHPjhUkgZDZ/8F/xpJHzzZ2io7pjClVJdlk+BLiITRWSriOSKyCOtrP9PEdkkIutE5FMR6dP+pXY9CRHBPHVtJusLK/mfz3JPfkeJw6351Wcuhh794aNfwnNDYcl/6w00lFKHHDfQRcQJzAIuB4YA00VkyFGbrQGyjDHDgAXA0+1daFc1MSORa89MZtaSXL75rvTUdtbnbLj9PbjjE+gzHr74PbwwzOpjry1vn4KVUl2WLy30MUCuMSbPGOMG5gJTWm5gjFlijDnYubscSGnfMru2xyYPJb1HGD94ZSVf555iqAP0Hg3TX4d7lkP/Sw73sX/+O+2KUaob8yXQk4GW91kraF7WljuAxa2tEJG7RSRbRLJLSrrPWOvI4ADm3j2OtDgr1D/fuq99dpww2DqB+qOvIX0CfP4U/Hk0rF8AbU3lq5TyW74EurSyrNW0EJEZQBbwTGvrjTEvGmOyjDFZ8fHxvlfpB3qEB/HGXeM4IyGcu19dxceb9rbfzntlWCdP7/gYwuPhzTvglUmwbj58+Ud45yfw2lSdM0YpP+dLoBcAvVs8TgGKjt5IRC4GfglMNsY0tE95/iUmLJDX7xzH4KRI7v5nNs99vA2PLxce+ar3GLhrCUx6DvZthIV3waePw/aPYc86eGM6FK5uv9dTSnUq0uZddg5uIOICtgEXAYXASuAmY8zGFtuMxDoZOtEYc5z5Yy1ZWVkmOzv7ZOvu0moamnj0nY28ubqAsemxvDBtJL2igtv3ReorYX8+xKRBUDhU7YF/XGKNY7/jI4jr176vp5Q6LURklTEmq7V1x22hG2OagHuBD4HNwHxjzEYReVxEJjdv9gwQDvxLRHJEZFE71e6XwoJc/PGG4fzh+uGsK6jkij99yapd7TxKJTjK6ooJCrceR/SCGQvBeOG163S+GKX80HFb6B2lO7fQW8rdV82ds1dS3dDEe/ed2/4t9aMVZFv96yHREJFoTTkgDohMhoQh0HMIJI6A6N7H35dS6rQ7pRa66lhnJITzt1uzqHV7uGfOKtxNHTx9bkoW3DTXCu3QOAiOtq5KLV5rjZKZNwOez4S3fgwHig8/z+uF7z6Dj34FVa2c0C1cBbPGwoY3O7Z+pVSbtIXeSby3roh7X1/DbWf14TdTMuwpwl0DJVtg49uw4i/gcMH4/7C6bVb+A8q/s7aLSYdb37b65wGKcqyJxOoPWM+5+V/Q7wJ73oNSfk5b6F3ApGFJ3HlOOrOX7eKtNQX2FBEYBsmj4NIn4CffWhctff7f8OH/g7AecO3f4Pb3oa4C/nEZ7N0Ee9bDP6+GoEj40ZfQY4DVyi9ea897UKob0xZ6J9Lo8XLz31ewelcF156ZzA/P60e/+HB7iypeBw6nNQvkQXs3wT+vgaZ6a50rGG7/N8Smw4Ei+Mel0NRgjaaJTf/+Pqv3wb5NkH6e1YevlPLZsVroGuidTEWNm+c+2ca8lfm4PV4mDu3Fzy4dwBkJEXaXdqSKnfDq1Vao3/7vI4dBlmyFly4DRwCMvRtGzbRa+PUH4Jv/gWWzoLEG+l8KV/0JIhNtextKdTUa6F1QaXUDL3+9g1eX7aLR4+WJKRlcn9XJRp401oGnEYIjv7+ueK11S728z8EZCAMmwq6vobYMhl4DvYZZk4u5guGKP1gna3d+ZW1Tlmu13odMgV6Z2opXqgUN9C5sX1U9P30jh2V5ZUwdlcITUzIICXTaXZbvSrbCt3+D9fOtkTUXPwbJZ1rrSrfD2z+GgpWHtw+Ns066Fq22xszH9oWsH8DYH4EzwI53oFSnooHexXm8hhc+2cb/LMmlf0I4T08dzoje0XaX1T68HsiZY/W5p50L8QOtFnlNKWx+1xoGufNLiB8EVz4LaeOt5+3bDJveAXHCWfdYJ3SPZc8GiE5t/deEUl2IBrqfWLqthAf/tZaS6gamj0nl4csGERXaDVqtWxfD4p/D/t0w8Aooz7OGVyKAgahUmPSsNSrnaEU58NkTkPsJJAyF296FsLgjt9n5tfWFkDTidLwbpU6JBrofqapv5PlPtvPKNzuJDgng0auGMGXEsWYz9hPuWmve92//ZvW/D70aBl9lhfu7P4XSbVbffJ/xh6cO3vWV1YoPiYERN8PKv0Nsv8Oh7mmETx6DZX+2th96DVz4a+sEb0O11U206hUIDLd+HSQMsuvdK3WIBrof2lR0gF++vZ41u/dz9Ygknrg6g4jgbtBab01Tg3UD7RqqLN4AABMLSURBVC//AB734eWB4XDWT6y/4CjrStc3pluhfvX/wvsPWv33WXdAWLw1AsfTAGdcYp2cbTgAPTOhqsgK+Iv/C8b+GBwO68rZsu3WJGgJgyEo4sh69m60/vbvhv27oLIAemZY3UMHL8hS6iRooPspj9cwa0kuL3y6naToYF6YNpIzU2PsLss+DdXWyBsRQKxulICj5sY5GOpN9RAYAZP/BBnXWuuq98EXT8PGhXDGxTD6Tuvm3DUlsOh+2LbYehwQYnXlNBw4vN+YdGsunKoiK8gPfrEcnCcnIhGK1lgneodeY53kjUmzvmhcgda9YfNXwO5l1sVariBrXXCUdV4h84b26f+v2gurZ1uvc9ZPrPfZ0p4N8M2fYPg06Hfhqb+eOnnGWJ+ZvRsgfrB1LUhgqAa6v1u1q5z738hhz4F6rsxM5Laz0zgzNRrR4X6ty/sCVr18uHvFF8ZYJ28/exLCE6wrapNHQWis9Q9uz3rrRG14T2sUT9JIq2soqrcV2ACVhbDi/yD7ZXC3uFWgK9j6ggFr7H7PoVbw1++HukpoqLR+bYy4yRrx01hn/UMvWmP9AjAt5v+JSLS+AOIHWSeBm+qhocr6JbH5Xdi8CLxN1i+SmhIYdTtc+ltraOnSZ+Cr56z1ACNnwKVPWhO5Ha1iF6z/F1QVwzkPQNRRd52sLrFOZqee1fZ1Bl6P9cW44wvrfRz8Ina4rLn9z7j4yNeur7Tm849OPfb/bw3VsOU961dW0kjodxHEtHHf+n2brRPvteUw6ApruOzB0VRNbusYVxVZI7Ri0lofQuuute43ULjaakT0u8CqsSVjrIvu9m22Lqor3WYtcwZYxz4wFMISrM9WSLR1XmfjQut6j4PECfEDkZ8s10D3d5V1jfzp0+3MX5lPVUMTmclR3HluOlcNS8Lh0GDvVOr2Wydp6yqaQ3u/NVwz9SwrgI7+VVGwCr79K2xYCN7Gw8tDYiCuv3W17sETxJUFUJlPq4KiYOTNVhdTVAosedLqZoruDa4QKN0Kw6fDRY/Cir9aLfXwnnD2/dYvBuO1voi2fgD5y619OgOtv4sfs/brccPy/4UvnwV3lbVNyhgYMtl6zcpCOFBonfvYtcz6sgLrCwas12hqsF7H4bJGPsX1s3697NnAoZul9RhoBXDaOdbjpgYrWL/7FDYtsi5cCwiFxuZbHcf2g8ThVlgGR1u/nLYutm4EIw7r/TfWWOsGXGbdP6Bg5eHng/X/UXKW9UvJXWutqym1Atp4jjzWcWdA73HW/8cVO62/xprD68MSrOPmcVvdfO6aw1+kYIV3+gTIuA5Sx1nDf4vXQnEOMmOBBnp3UdPQxMI1hcz+Zie5+6oZnBjJLy4fxIQB3euWf36pep91kjcs3gr+6NTWW4wNVVYLsLIAAsKsVmNQuBVqgaFHbrt7uXUtQJMbrnr+yJFChavhnXut0GspfhAMuwEyr7cC+L0HrK6s5Cyo3mt9oQy4HMb9yArFTYusFuxBAaHWL5fUsVaLOH2C1TI9yOuFwmzY8m/r70Ch1dXVZ7x1AVrpdtj6vtUCbxmCYM0pNPRq64up9zjrIrXvPrP+ynIPf4Eaj/VFkzkVhlx9+BzLpretO3xFJlmvlzbeqrU4x5p6unCV9asnIMw6lsHR1hdF8ijrl1l95eHXK1xlBXdMmvUX18/qlksYbP2ya8nb/Iuseq/1JZEw2Lq6uhXa5dINeb2Gd9cV8cyHWymoqOOcM3owaVgigxIjGdgzomtdnKQ6lqcJMK1fuOX1WK1Vh9NqMTtcVvi1/CIxxrp/7ce/tm6kculvrZBuaf9ua+qHqOTmFvIJ/Go0pvXt6yqs8xXOQOsXhCsYovt8/xdOa/vzuK3ndEEa6N1YQ5OH15bv5n+X5FJWY52ocwj0T4jg/EHxXDgwgVF9YnA5HdQ3ethTWY9DhNS40OPsWSllBw10hddryK+oZXPxATYXV5G9q5xvd5TT6DFEBrsIdDkorT485O+pazOZPib1GHtUStnhWIHuOt3FKHs4HEKfuDD6xIUxMcMadVBV38hX20tZut26v2hSVAiJ0SG8t66I//fWegKdDq4blXKs3SqlOhEN9G4sIjiAyzMTuTzzyGFlk4YlcufsbB5asJZAl4Orhifh9Rq276tmV1kNEwbEExygffBKdTba5aJaVetu4vaXVrJqdwVn94tjbf5+DtRbIwpSYkL45RWDmZjRS8e6K3WanfIt6ERkoohsFZFcEXmklfUTRGS1iDSJyNRTLVjZLzTQxUszR3P+gHiKK+u5IjORZ6YO48VbRhEe5OLHc1Yz/W/L2bLnwPF3ppQ6LY7bQhcRJ7ANuAQoAFYC040xm1pskwZEAg8Ci4wxC473wtpC77qaPF7eWJnPHz/aSm2Dh19cMYjbz07T1rpSp8GpttDHALnGmDxjjBuYC0xpuYExZqcxZh3gbW0Hyr+4nA5uGdeHz352PhMG9OA3727iztnZlNe4j/9kpVSH8eWkaDLQ8lriAmDsybyYiNwN3A2QmqpD4rq62LBA/nZrFq98s5On3t/CZc8vZUxaLJEhLiKDA0iKDuHc/j1I7xGmrXelTgNfAr21f4kndSbVGPMi8CJYXS4nsw/VuYgIM8enMyY9lqfe38KWPQc4UN/EgbpGGpqsH2y9Y0M4b0A8QxKj6B0bQmpsKEnRIQQ4fTqFo5TykS+BXgC0vDtxClDUMeWormpoUhSv3XnkD7f88lo+31bCF1tLWLi6kNfcuw+tC3Q5GNk7mrP6xXFW3zhGpEYT5NKhkEqdCl9OirqwTopeBBRinRS9yRizsZVtXwHe05Oi6mger2HPgXryy2vJL69l654qlu8oY2PRAYyB0EAnZ/frwXkD4zkzNZo9lfXk7qsmr6SG9PgwZo5P08BXina49F9ErgCeB5zAS8aYJ0XkcSDbGLNIREYDbwExQD2wxxgz9Fj71EBXAJW1jazYUcbS7SV8vrWEgoq6I9bHhAZQUdtI3/gwnrw6k7P6xbWxJ6W6B53LRXUJxhjySmvYWHSA5OgQzogPJyo0gC+2lfDrtzewu7yWa0YmM2FAD1JiQkmJCaHW7WFFXjkrdpSxrqCSM1NjuO3sPgxLaeWmDEr5AQ101eXVN3r482e5vLg0D7fn+6Nj4yOCyEiKZMWOcmrdHob3jmZSZiIBTsFrrLP45/bvwYCeEd/fuVJdiAa68hv1jR4KKuoo3F9HQUUtThHGpMceGhpZVd/IwtWFzF62k7ySmiOe6xC4cXQq/3nJAOIjuuZc2EppoKtuxxhDRW0jAjhEqGv08Nel3/HPZbsIcjmYcVYf4sICD20fEugiPjyQuPAgYsMCCQt0ERLoJCTASYBTdBy96jQ00JVqlldSze8Wb+GjTXt9fk5USACDekUwODGSQb0iGJYSzYCe4bh0HL2ygc6HrlSzvvHhvHhrFnVuD97mxowBahuaKKluoKzaTXmNm1q3h7pGD3XuJooq69lSfID52fnUuq2bAYcEOMlMiSIjKYq+8WH07RFGenwYCRHBOPWm3MomGuiqWzr6nqrhQS4SIo99L0qv17CrvJa1+fvJyd/Pmvz9zFmx69AVsWD108eFB9EjPIiIIBfVDU1UNTRSXd9EVEgA6T3CSO8RTnp8GIN7RTCwVwQRwa3cy1Opk6CBrpSPHA5pDuQwrh6ZDFghv+dAPTtKa9hRWsO+A/WUVDdQUtVAVX0TSdHBhAeFEx7soqKmkR2lNSzPK6eu0XNov71jQ0iLC6NXZDC9ooJJiAgiqLnvPsDpINjlJDzYRXiQNUdOaJCT0Ob+/VPt269paOKdnCIigl1MGpao5wq6OA10pU6BwyEkRYeQFB3C+DN6+PQcYwxFlfVs3WPd33Vz8QHyy2vZtreKkqoGvD6e1hKx+vf79gjjjIRw+sWHkxwTQnx4EAmRwYQFOimqrKewoo7C/bUEuZykxoXSJzaUAKeD11bs4o0Vuw/duOSDjXv43bWZ+ouhC9OTokp1Ik0eL+U1bhqavDR5DU0eL3WNHqrrm6hqaKKqvoladxO1bg+1DU2U1rj5bl8135XUUFrdcEKv5RC4PCORH5yTxrc7KvjDR1tJiQlh1k1nkpEc1UHvUJ0qPSmqVBfhcjqO25fflsq6RvZU1lNS1cC+qnpqGproFRVCSkwIyTEhNDR62VVWw66yWipq3UzM6EVKTCgAo/rEkpUWw32vr+HqWV8TEezC4zV4DTgdQmxYINGhAcSEBtLo8VLT0HToxLHXGIwBY8Dt8eJu8tLQ5MHrhciQgObnBZAaG8bI1GhGpkYzsGeEjhLqANpCV0odUl7j5sWledQ0NOF0CA4RGj1eKmrd7K9tpKLWTYDTQViQ89BYfYcIIiAIgS4hyOUkyOVARKisa2R/rZuKWjfb91ZT1nwTlOAAB2lxYfSJC6VPXBihgU5KW4wyiggOID4iiISIIOIjgg59ocSGBRIfHkRMaCAOH0YT1bk9bCiqZM3uCqrrm4hv3l9CZDADe0YQFtT12rQ6Dl0pZTtjDAUVdazeXcG6gkp2ldWws6yW3eW1uJu8xIQGEBceRExoAFX1TZRUNRz6AjhagFNIiAgmKiQAt8dLndtDfaMHESEsyDphDLB9XzWe5pMSItaviIMcAgN6RjCidzQZyVH0TwjnjIRw4sI791XE2uWilLKdiNA7NpTesaFMGZF8aLnXa/AY0+oNTxqbzylU1Fot94qaRkqq6tlb1cDeynoq6xoJDnA2/znwGqhzN1Hj9uDxGi4anMDI3jGMSI0mOiSA8lo3JVUNFO2vZ31hJTn5+1m8YQ9zVx6+KVt0aADBLidNXoPH68VrwOUQnA45VKMxVneUx1jnORo9hkaPt7mbyhw6sR0c4CA00EVIgJOEyCAGJ0YeukDNIUJ9o4c6twePMYQHWSOZwoJc1i+SkIBDv0LcTV4KKmrZVV57zGOsga6UspXDIThavTEaBDgd9IwMpudJnlc4WkJEMAkRwQxNiuKSIT0BK5wL99eRu6/amoO/tAaPx+B0Ci6HIBwMbkOjx0pqh1hTSjgcVo0uh4MAp+BySnMXlPVzoL7Ja53EbvBQVFnHe2uLeH3F7mNU2OK4iHWbxyCXk+LKOp9GP2mgK6W6NRFpno45lPMHJnToax0csrp9bxUiQkjAwesJrGsCqpv/KmrclNW4Ka12U9/ooXdMCKnN5xzG/L7t/WugK6XUaSIiJEeHkBwd0iH713FDSinlJzTQlVLKT2igK6WUn9BAV0opP6GBrpRSfkIDXSml/IQGulJK+QkNdKWU8hO2Tc4lIlXAVltevPPrAZTaXUQnpsenbXps2uYvx6aPMSa+tRV2Xim6ta0Zw7o7EcnWY9M2PT5t02PTtu5wbLTLRSml/IQGulJK+Qk7A/1FG1+7s9Njc2x6fNqmx6Ztfn9sbDspqpRSqn1pl4tSSvkJDXSllPITtgS6iEwUka0ikisij9hRQ2chIr1FZImIbBaRjSLy0+blsSLysYhsb/7fGLtrtYuIOEVkjYi81/w4XURWNB+beSISaHeNdhCRaBFZICJbmj8/Z+nnxiIiDzT/e9ogIm+ISHB3+Nyc9kAXEScwC7gcGAJMF5Ehp7uOTqQJ+JkxZjAwDvhJ8/F4BPjUGNMf+LT5cXf1U2Bzi8e/B55rPjYVwB22VGW/F4APjDGDgOFYx6jbf25EJBm4H8gyxmQATmAa3eBzY0cLfQyQa4zJM8a4gbnAFBvq6BSMMcXGmNXN/12F9Y8yGeuYzG7ebDZwtT0V2ktEUoArgb83PxbgQmBB8ybd8tiISCQwAfgHgDHGbYzZj35uDnIBISLiAkKBYrrB58aOQE8G8ls8Lmhe1u2JSBowElgB9DTGFIMV+kDH3r2283oe+DngbX4cB+w3xjQ1P+6un5++QAnwcnN31N9FJAz93GCMKQT+AOzGCvJKYBXd4HNjR6BLK8u6/dhJEQkH3gT+wxhzwO56OgMRmQTsM8asarm4lU274+fHBZwJ/J8xZiRQQzfsXmlN83mDKUA6kASEYXXxHs3vPjd2BHoB0LvF4xSgyIY6Og0RCcAK8znGmIXNi/eKSGLz+kRgn1312Wg8MFlEdmJ1zV2I1WKPbv4pDd3381MAFBhjVjQ/XoAV8Pq5gYuBHcaYEmNMI7AQOJtu8LmxI9BXAv2bzzgHYp2sWGRDHZ1Cc5/wP4DNxphnW6xaBNzW/N+3Ae+c7trsZoz5hTEmxRiThvU5+cwYczOwBJjavFl3PTZ7gHwRGdi86CJgE/q5AaurZZyIhDb/+zp4bPz+c2PLlaIicgVWS8sJvGSMefK0F9FJiMg5wJfAeg73E/8/rH70+UAq1gf0emNMuS1FdgIicj7woDFmkoj0xWqxxwJrgBnGmAY767ODiIzAOlkcCOQBM7Eaad3+cyMivwFuxBpFtga4E6vP3K8/N3rpv1JK+Qm9UlQppfyEBrpSSvkJDXSllPITGuhKKeUnNNCVUspPaKArpZSf0EBXSik/8f8BkkGVgKlt1+sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_model_med_es_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_med_es_dropout = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model_med_es_dropout.add(Dense(30, activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "model_med_es_dropout.add(Dropout(0.2))\n",
    "model_med_es_dropout.add(Dense(15, activation='relu'))\n",
    "model_med_es_dropout.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model_med_es_dropout.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_med_es_dropout.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/600\n",
      "364/364 [==============================] - 1s 3ms/sample - loss: 0.6839 - val_loss: 0.6719\n",
      "Epoch 2/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.6666 - val_loss: 0.6505\n",
      "Epoch 3/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.6446 - val_loss: 0.6275\n",
      "Epoch 4/600\n",
      "364/364 [==============================] - 0s 174us/sample - loss: 0.6227 - val_loss: 0.5894\n",
      "Epoch 5/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.5817 - val_loss: 0.5434\n",
      "Epoch 6/600\n",
      "364/364 [==============================] - 0s 165us/sample - loss: 0.5377 - val_loss: 0.5031\n",
      "Epoch 7/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.4947 - val_loss: 0.4686\n",
      "Epoch 8/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.4456 - val_loss: 0.4277\n",
      "Epoch 9/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.4369 - val_loss: 0.3960\n",
      "Epoch 10/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.4249 - val_loss: 0.3664\n",
      "Epoch 11/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.3653 - val_loss: 0.3431\n",
      "Epoch 12/600\n",
      "364/364 [==============================] - 0s 168us/sample - loss: 0.3400 - val_loss: 0.3260\n",
      "Epoch 13/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.3358 - val_loss: 0.3062\n",
      "Epoch 14/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.3079 - val_loss: 0.2946\n",
      "Epoch 15/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.2856 - val_loss: 0.2759\n",
      "Epoch 16/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.2652 - val_loss: 0.2668\n",
      "Epoch 17/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.2516 - val_loss: 0.2642\n",
      "Epoch 18/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.2481 - val_loss: 0.2517\n",
      "Epoch 19/600\n",
      "364/364 [==============================] - 0s 166us/sample - loss: 0.2433 - val_loss: 0.2439\n",
      "Epoch 20/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.2277 - val_loss: 0.2379\n",
      "Epoch 21/600\n",
      "364/364 [==============================] - 0s 180us/sample - loss: 0.2170 - val_loss: 0.2384\n",
      "Epoch 22/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.2172 - val_loss: 0.2287\n",
      "Epoch 23/600\n",
      "364/364 [==============================] - 0s 175us/sample - loss: 0.1982 - val_loss: 0.2222\n",
      "Epoch 24/600\n",
      "364/364 [==============================] - 0s 172us/sample - loss: 0.1896 - val_loss: 0.2315\n",
      "Epoch 25/600\n",
      "364/364 [==============================] - 0s 167us/sample - loss: 0.1869 - val_loss: 0.2151\n",
      "Epoch 26/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.1908 - val_loss: 0.2097\n",
      "Epoch 27/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.1682 - val_loss: 0.2113\n",
      "Epoch 28/600\n",
      "364/364 [==============================] - 0s 163us/sample - loss: 0.1741 - val_loss: 0.2031\n",
      "Epoch 29/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.1798 - val_loss: 0.1967\n",
      "Epoch 30/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1546 - val_loss: 0.1940\n",
      "Epoch 31/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.1789 - val_loss: 0.1999\n",
      "Epoch 32/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.1504 - val_loss: 0.1899\n",
      "Epoch 33/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.1533 - val_loss: 0.1859\n",
      "Epoch 34/600\n",
      "364/364 [==============================] - 0s 161us/sample - loss: 0.1523 - val_loss: 0.1811\n",
      "Epoch 35/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.1489 - val_loss: 0.1757\n",
      "Epoch 36/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.1560 - val_loss: 0.1819\n",
      "Epoch 37/600\n",
      "364/364 [==============================] - 0s 172us/sample - loss: 0.1508 - val_loss: 0.1718\n",
      "Epoch 38/600\n",
      "364/364 [==============================] - 0s 161us/sample - loss: 0.1370 - val_loss: 0.1702\n",
      "Epoch 39/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.1368 - val_loss: 0.1767\n",
      "Epoch 40/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1324 - val_loss: 0.1677\n",
      "Epoch 41/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.1288 - val_loss: 0.1794\n",
      "Epoch 42/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1038 - val_loss: 0.1628\n",
      "Epoch 43/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.1041 - val_loss: 0.1602\n",
      "Epoch 44/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.1268 - val_loss: 0.1835\n",
      "Epoch 45/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.1165 - val_loss: 0.1588\n",
      "Epoch 46/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.1128 - val_loss: 0.1532\n",
      "Epoch 47/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.1174 - val_loss: 0.1693\n",
      "Epoch 48/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.1134 - val_loss: 0.1580\n",
      "Epoch 49/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.1148 - val_loss: 0.1523\n",
      "Epoch 50/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.1025 - val_loss: 0.1440\n",
      "Epoch 51/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0967 - val_loss: 0.1390\n",
      "Epoch 52/600\n",
      "364/364 [==============================] - 0s 168us/sample - loss: 0.0954 - val_loss: 0.1487\n",
      "Epoch 53/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.1030 - val_loss: 0.1507\n",
      "Epoch 54/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0901 - val_loss: 0.1508\n",
      "Epoch 55/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.1089 - val_loss: 0.1465\n",
      "Epoch 56/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0966 - val_loss: 0.1366\n",
      "Epoch 57/600\n",
      "364/364 [==============================] - 0s 161us/sample - loss: 0.0730 - val_loss: 0.1440\n",
      "Epoch 58/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0746 - val_loss: 0.1393\n",
      "Epoch 59/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0927 - val_loss: 0.1427\n",
      "Epoch 60/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0805 - val_loss: 0.1392\n",
      "Epoch 61/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0857 - val_loss: 0.1342\n",
      "Epoch 62/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0900 - val_loss: 0.1423\n",
      "Epoch 63/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0725 - val_loss: 0.1415\n",
      "Epoch 64/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0729 - val_loss: 0.1315\n",
      "Epoch 65/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0762 - val_loss: 0.1422\n",
      "Epoch 66/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0678 - val_loss: 0.1393\n",
      "Epoch 67/600\n",
      "364/364 [==============================] - 0s 163us/sample - loss: 0.0749 - val_loss: 0.1286\n",
      "Epoch 68/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0739 - val_loss: 0.1374\n",
      "Epoch 69/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0738 - val_loss: 0.1320\n",
      "Epoch 70/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.0661 - val_loss: 0.1302\n",
      "Epoch 71/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0596 - val_loss: 0.1331\n",
      "Epoch 72/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0755 - val_loss: 0.1237\n",
      "Epoch 73/600\n",
      "364/364 [==============================] - 0s 164us/sample - loss: 0.0635 - val_loss: 0.1289\n",
      "Epoch 74/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0598 - val_loss: 0.1304\n",
      "Epoch 75/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.0697 - val_loss: 0.1279\n",
      "Epoch 76/600\n",
      "364/364 [==============================] - 0s 165us/sample - loss: 0.0660 - val_loss: 0.1188\n",
      "Epoch 77/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0788 - val_loss: 0.1344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0735 - val_loss: 0.1356\n",
      "Epoch 79/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0727 - val_loss: 0.1191\n",
      "Epoch 80/600\n",
      "364/364 [==============================] - 0s 198us/sample - loss: 0.0806 - val_loss: 0.1282\n",
      "Epoch 81/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0761 - val_loss: 0.1168\n",
      "Epoch 82/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0632 - val_loss: 0.1337\n",
      "Epoch 83/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0565 - val_loss: 0.1209\n",
      "Epoch 84/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0564 - val_loss: 0.1200\n",
      "Epoch 85/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0720 - val_loss: 0.1325\n",
      "Epoch 86/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0526 - val_loss: 0.1270\n",
      "Epoch 87/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0483 - val_loss: 0.1252\n",
      "Epoch 88/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0652 - val_loss: 0.1310\n",
      "Epoch 89/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0608 - val_loss: 0.1319\n",
      "Epoch 90/600\n",
      "364/364 [==============================] - 0s 182us/sample - loss: 0.0598 - val_loss: 0.1205\n",
      "Epoch 91/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.0461 - val_loss: 0.1373\n",
      "Epoch 92/600\n",
      "364/364 [==============================] - 0s 162us/sample - loss: 0.0573 - val_loss: 0.1405\n",
      "Epoch 93/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0645 - val_loss: 0.1207\n",
      "Epoch 94/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.0544 - val_loss: 0.1331\n",
      "Epoch 95/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0510 - val_loss: 0.1306\n",
      "Epoch 96/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0493 - val_loss: 0.1294\n",
      "Epoch 97/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0551 - val_loss: 0.1225\n",
      "Epoch 98/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0511 - val_loss: 0.1221\n",
      "Epoch 99/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0538 - val_loss: 0.1232\n",
      "Epoch 100/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0489 - val_loss: 0.1225\n",
      "Epoch 101/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0552 - val_loss: 0.1202\n",
      "Epoch 102/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0591 - val_loss: 0.1292\n",
      "Epoch 103/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0462 - val_loss: 0.1211\n",
      "Epoch 104/600\n",
      "364/364 [==============================] - 0s 162us/sample - loss: 0.0486 - val_loss: 0.1202\n",
      "Epoch 105/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0574 - val_loss: 0.1316\n",
      "Epoch 106/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0541 - val_loss: 0.1232\n",
      "Epoch 00106: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc75e562c8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_med_es_dropout.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_val, y_val), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model_med_es_dropout_df = pd.DataFrame(model_med_es_dropout.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc7653e0c8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_model_med_es_dropout_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiny_df = model_tiny.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tiny_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        43\n",
      "           1       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_tiny_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  1]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred_tiny_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model_med_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_med_es_df = model_med_es.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        43\n",
      "           1       0.99      0.97      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_med_es_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  1]\n",
      " [ 2 69]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred_med_es_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  model_med_es_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_med_es_dropout_df = model_med_es_dropout.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        43\n",
      "           1       0.99      0.97      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_med_es_dropout_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  1]\n",
      " [ 2 69]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred_med_es_dropout_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
