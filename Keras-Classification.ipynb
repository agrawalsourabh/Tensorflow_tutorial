{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  benign_0__mal_1  \n",
       "0          0.4601                  0.11890                0  \n",
       "1          0.2750                  0.08902                0  \n",
       "2          0.3613                  0.08758                0  \n",
       "3          0.6638                  0.17300                0  \n",
       "4          0.2364                  0.07678                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>28.11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>188.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>2501.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.16340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.34540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.20120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.30400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>2.87300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>4.88500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>21.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>542.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.13540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.05279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.07895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal dimension error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.02984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>36.04000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>49.54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>251.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>4254.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.22260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>1.05800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>1.25200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.66380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign_0__mal_1</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.627417</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean         std         min  \\\n",
       "mean radius              569.0   14.127292    3.524049    6.981000   \n",
       "mean texture             569.0   19.289649    4.301036    9.710000   \n",
       "mean perimeter           569.0   91.969033   24.298981   43.790000   \n",
       "mean area                569.0  654.889104  351.914129  143.500000   \n",
       "mean smoothness          569.0    0.096360    0.014064    0.052630   \n",
       "mean compactness         569.0    0.104341    0.052813    0.019380   \n",
       "mean concavity           569.0    0.088799    0.079720    0.000000   \n",
       "mean concave points      569.0    0.048919    0.038803    0.000000   \n",
       "mean symmetry            569.0    0.181162    0.027414    0.106000   \n",
       "mean fractal dimension   569.0    0.062798    0.007060    0.049960   \n",
       "radius error             569.0    0.405172    0.277313    0.111500   \n",
       "texture error            569.0    1.216853    0.551648    0.360200   \n",
       "perimeter error          569.0    2.866059    2.021855    0.757000   \n",
       "area error               569.0   40.337079   45.491006    6.802000   \n",
       "smoothness error         569.0    0.007041    0.003003    0.001713   \n",
       "compactness error        569.0    0.025478    0.017908    0.002252   \n",
       "concavity error          569.0    0.031894    0.030186    0.000000   \n",
       "concave points error     569.0    0.011796    0.006170    0.000000   \n",
       "symmetry error           569.0    0.020542    0.008266    0.007882   \n",
       "fractal dimension error  569.0    0.003795    0.002646    0.000895   \n",
       "worst radius             569.0   16.269190    4.833242    7.930000   \n",
       "worst texture            569.0   25.677223    6.146258   12.020000   \n",
       "worst perimeter          569.0  107.261213   33.602542   50.410000   \n",
       "worst area               569.0  880.583128  569.356993  185.200000   \n",
       "worst smoothness         569.0    0.132369    0.022832    0.071170   \n",
       "worst compactness        569.0    0.254265    0.157336    0.027290   \n",
       "worst concavity          569.0    0.272188    0.208624    0.000000   \n",
       "worst concave points     569.0    0.114606    0.065732    0.000000   \n",
       "worst symmetry           569.0    0.290076    0.061867    0.156500   \n",
       "worst fractal dimension  569.0    0.083946    0.018061    0.055040   \n",
       "benign_0__mal_1          569.0    0.627417    0.483918    0.000000   \n",
       "\n",
       "                                25%         50%          75%         max  \n",
       "mean radius               11.700000   13.370000    15.780000    28.11000  \n",
       "mean texture              16.170000   18.840000    21.800000    39.28000  \n",
       "mean perimeter            75.170000   86.240000   104.100000   188.50000  \n",
       "mean area                420.300000  551.100000   782.700000  2501.00000  \n",
       "mean smoothness            0.086370    0.095870     0.105300     0.16340  \n",
       "mean compactness           0.064920    0.092630     0.130400     0.34540  \n",
       "mean concavity             0.029560    0.061540     0.130700     0.42680  \n",
       "mean concave points        0.020310    0.033500     0.074000     0.20120  \n",
       "mean symmetry              0.161900    0.179200     0.195700     0.30400  \n",
       "mean fractal dimension     0.057700    0.061540     0.066120     0.09744  \n",
       "radius error               0.232400    0.324200     0.478900     2.87300  \n",
       "texture error              0.833900    1.108000     1.474000     4.88500  \n",
       "perimeter error            1.606000    2.287000     3.357000    21.98000  \n",
       "area error                17.850000   24.530000    45.190000   542.20000  \n",
       "smoothness error           0.005169    0.006380     0.008146     0.03113  \n",
       "compactness error          0.013080    0.020450     0.032450     0.13540  \n",
       "concavity error            0.015090    0.025890     0.042050     0.39600  \n",
       "concave points error       0.007638    0.010930     0.014710     0.05279  \n",
       "symmetry error             0.015160    0.018730     0.023480     0.07895  \n",
       "fractal dimension error    0.002248    0.003187     0.004558     0.02984  \n",
       "worst radius              13.010000   14.970000    18.790000    36.04000  \n",
       "worst texture             21.080000   25.410000    29.720000    49.54000  \n",
       "worst perimeter           84.110000   97.660000   125.400000   251.20000  \n",
       "worst area               515.300000  686.500000  1084.000000  4254.00000  \n",
       "worst smoothness           0.116600    0.131300     0.146000     0.22260  \n",
       "worst compactness          0.147200    0.211900     0.339100     1.05800  \n",
       "worst concavity            0.114500    0.226700     0.382900     1.25200  \n",
       "worst concave points       0.064930    0.099930     0.161400     0.29100  \n",
       "worst symmetry             0.250400    0.282200     0.317900     0.66380  \n",
       "worst fractal dimension    0.071460    0.080040     0.092080     0.20750  \n",
       "benign_0__mal_1            0.000000    1.000000     1.000000     1.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc67a468c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='benign_0__mal_1', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1', axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 30)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 30)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tiny = Sequential()\n",
    "\n",
    "model_tiny.add(Dense(30, activation='relu'))\n",
    "\n",
    "model_tiny.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_tiny.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/600\n",
      "364/364 [==============================] - 2s 4ms/sample - loss: 0.6790 - val_loss: 0.6654\n",
      "Epoch 2/600\n",
      "364/364 [==============================] - 0s 283us/sample - loss: 0.6589 - val_loss: 0.6481\n",
      "Epoch 3/600\n",
      "364/364 [==============================] - 0s 194us/sample - loss: 0.6392 - val_loss: 0.6310\n",
      "Epoch 4/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.6210 - val_loss: 0.6129\n",
      "Epoch 5/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.6012 - val_loss: 0.5939\n",
      "Epoch 6/600\n",
      "364/364 [==============================] - 0s 171us/sample - loss: 0.5813 - val_loss: 0.5740\n",
      "Epoch 7/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.5603 - val_loss: 0.5539\n",
      "Epoch 8/600\n",
      "364/364 [==============================] - 0s 165us/sample - loss: 0.5392 - val_loss: 0.5338\n",
      "Epoch 9/600\n",
      "364/364 [==============================] - 0s 177us/sample - loss: 0.5178 - val_loss: 0.5135\n",
      "Epoch 10/600\n",
      "364/364 [==============================] - 0s 163us/sample - loss: 0.4964 - val_loss: 0.4934\n",
      "Epoch 11/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.4755 - val_loss: 0.4739\n",
      "Epoch 12/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.4552 - val_loss: 0.4555\n",
      "Epoch 13/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.4355 - val_loss: 0.4375\n",
      "Epoch 14/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.4163 - val_loss: 0.4200\n",
      "Epoch 15/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.3956 - val_loss: 0.4016\n",
      "Epoch 16/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.3766 - val_loss: 0.3851\n",
      "Epoch 17/600\n",
      "364/364 [==============================] - 0s 161us/sample - loss: 0.3592 - val_loss: 0.3698\n",
      "Epoch 18/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.3416 - val_loss: 0.3561\n",
      "Epoch 19/600\n",
      "364/364 [==============================] - 0s 164us/sample - loss: 0.3271 - val_loss: 0.3435\n",
      "Epoch 20/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.3137 - val_loss: 0.3326\n",
      "Epoch 21/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.3013 - val_loss: 0.3261\n",
      "Epoch 22/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.2911 - val_loss: 0.3136\n",
      "Epoch 23/600\n",
      "364/364 [==============================] - 0s 188us/sample - loss: 0.2796 - val_loss: 0.3073\n",
      "Epoch 24/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.2706 - val_loss: 0.2983\n",
      "Epoch 25/600\n",
      "364/364 [==============================] - 0s 172us/sample - loss: 0.2617 - val_loss: 0.2919\n",
      "Epoch 26/600\n",
      "364/364 [==============================] - 0s 166us/sample - loss: 0.2529 - val_loss: 0.2881\n",
      "Epoch 27/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.2459 - val_loss: 0.2832\n",
      "Epoch 28/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.2392 - val_loss: 0.2763\n",
      "Epoch 29/600\n",
      "364/364 [==============================] - 0s 107us/sample - loss: 0.2330 - val_loss: 0.2752\n",
      "Epoch 30/600\n",
      "364/364 [==============================] - 0s 112us/sample - loss: 0.2271 - val_loss: 0.2696\n",
      "Epoch 31/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.2210 - val_loss: 0.2631\n",
      "Epoch 32/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.2159 - val_loss: 0.2620\n",
      "Epoch 33/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.2121 - val_loss: 0.2571\n",
      "Epoch 34/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.2066 - val_loss: 0.2557\n",
      "Epoch 35/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.2023 - val_loss: 0.2502\n",
      "Epoch 36/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.1975 - val_loss: 0.2496\n",
      "Epoch 37/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.1938 - val_loss: 0.2470\n",
      "Epoch 38/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.1898 - val_loss: 0.2410\n",
      "Epoch 39/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.1879 - val_loss: 0.2383\n",
      "Epoch 40/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1835 - val_loss: 0.2396\n",
      "Epoch 41/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.1796 - val_loss: 0.2337\n",
      "Epoch 42/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.1762 - val_loss: 0.2314\n",
      "Epoch 43/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1732 - val_loss: 0.2312\n",
      "Epoch 44/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1707 - val_loss: 0.2257\n",
      "Epoch 45/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.1671 - val_loss: 0.2238\n",
      "Epoch 46/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1644 - val_loss: 0.2181\n",
      "Epoch 47/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1618 - val_loss: 0.2178\n",
      "Epoch 48/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1592 - val_loss: 0.2179\n",
      "Epoch 49/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.1558 - val_loss: 0.2134\n",
      "Epoch 50/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.1533 - val_loss: 0.2099\n",
      "Epoch 51/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1508 - val_loss: 0.2078\n",
      "Epoch 52/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.1489 - val_loss: 0.2056\n",
      "Epoch 53/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.1464 - val_loss: 0.2075\n",
      "Epoch 54/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1447 - val_loss: 0.2088\n",
      "Epoch 55/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.1420 - val_loss: 0.2009\n",
      "Epoch 56/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.1408 - val_loss: 0.2036\n",
      "Epoch 57/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.1393 - val_loss: 0.1965\n",
      "Epoch 58/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.1361 - val_loss: 0.2003\n",
      "Epoch 59/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.1355 - val_loss: 0.1922\n",
      "Epoch 60/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.1315 - val_loss: 0.1947\n",
      "Epoch 61/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.1302 - val_loss: 0.1917\n",
      "Epoch 62/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1281 - val_loss: 0.1914\n",
      "Epoch 63/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1273 - val_loss: 0.1952\n",
      "Epoch 64/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.1263 - val_loss: 0.1862\n",
      "Epoch 65/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.1237 - val_loss: 0.1838\n",
      "Epoch 66/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1217 - val_loss: 0.1853\n",
      "Epoch 67/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.1202 - val_loss: 0.1829\n",
      "Epoch 68/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.1195 - val_loss: 0.1871\n",
      "Epoch 69/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.1170 - val_loss: 0.1766\n",
      "Epoch 70/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.1167 - val_loss: 0.1751\n",
      "Epoch 71/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.1146 - val_loss: 0.1804\n",
      "Epoch 72/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1134 - val_loss: 0.1771\n",
      "Epoch 73/600\n",
      "364/364 [==============================] - 0s 102us/sample - loss: 0.1124 - val_loss: 0.1786\n",
      "Epoch 74/600\n",
      "364/364 [==============================] - 0s 103us/sample - loss: 0.1103 - val_loss: 0.1748\n",
      "Epoch 75/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.1100 - val_loss: 0.1699\n",
      "Epoch 76/600\n",
      "364/364 [==============================] - 0s 115us/sample - loss: 0.1087 - val_loss: 0.1765\n",
      "Epoch 77/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1070 - val_loss: 0.1717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1056 - val_loss: 0.1678\n",
      "Epoch 79/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1045 - val_loss: 0.1681\n",
      "Epoch 80/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.1037 - val_loss: 0.1681\n",
      "Epoch 81/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1024 - val_loss: 0.1637\n",
      "Epoch 82/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.1015 - val_loss: 0.1700\n",
      "Epoch 83/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1007 - val_loss: 0.1619\n",
      "Epoch 84/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0989 - val_loss: 0.1645\n",
      "Epoch 85/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0981 - val_loss: 0.1648\n",
      "Epoch 86/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0968 - val_loss: 0.1611\n",
      "Epoch 87/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0966 - val_loss: 0.1600\n",
      "Epoch 88/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0949 - val_loss: 0.1641\n",
      "Epoch 89/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0943 - val_loss: 0.1573\n",
      "Epoch 90/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0935 - val_loss: 0.1579\n",
      "Epoch 91/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0926 - val_loss: 0.1551\n",
      "Epoch 92/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0913 - val_loss: 0.1563\n",
      "Epoch 93/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0910 - val_loss: 0.1576\n",
      "Epoch 94/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0908 - val_loss: 0.1492\n",
      "Epoch 95/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0890 - val_loss: 0.1534\n",
      "Epoch 96/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0879 - val_loss: 0.1545\n",
      "Epoch 97/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0872 - val_loss: 0.1492\n",
      "Epoch 98/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0863 - val_loss: 0.1497\n",
      "Epoch 99/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0860 - val_loss: 0.1486\n",
      "Epoch 100/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0861 - val_loss: 0.1535\n",
      "Epoch 101/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0839 - val_loss: 0.1491\n",
      "Epoch 102/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0830 - val_loss: 0.1455\n",
      "Epoch 103/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0824 - val_loss: 0.1439\n",
      "Epoch 104/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0815 - val_loss: 0.1471\n",
      "Epoch 105/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0812 - val_loss: 0.1444\n",
      "Epoch 106/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0810 - val_loss: 0.1525\n",
      "Epoch 107/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0797 - val_loss: 0.1436\n",
      "Epoch 108/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0787 - val_loss: 0.1439\n",
      "Epoch 109/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0779 - val_loss: 0.1437\n",
      "Epoch 110/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0785 - val_loss: 0.1444\n",
      "Epoch 111/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0772 - val_loss: 0.1393\n",
      "Epoch 112/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0760 - val_loss: 0.1470\n",
      "Epoch 113/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0754 - val_loss: 0.1414\n",
      "Epoch 114/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0760 - val_loss: 0.1370\n",
      "Epoch 115/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0745 - val_loss: 0.1409\n",
      "Epoch 116/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0743 - val_loss: 0.1452\n",
      "Epoch 117/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0730 - val_loss: 0.1355\n",
      "Epoch 118/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0737 - val_loss: 0.1423\n",
      "Epoch 119/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0724 - val_loss: 0.1359\n",
      "Epoch 120/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0711 - val_loss: 0.1400\n",
      "Epoch 121/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0711 - val_loss: 0.1381\n",
      "Epoch 122/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0711 - val_loss: 0.1325\n",
      "Epoch 123/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0696 - val_loss: 0.1388\n",
      "Epoch 124/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0694 - val_loss: 0.1387\n",
      "Epoch 125/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0692 - val_loss: 0.1361\n",
      "Epoch 126/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0682 - val_loss: 0.1315\n",
      "Epoch 127/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0683 - val_loss: 0.1339\n",
      "Epoch 128/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0671 - val_loss: 0.1327\n",
      "Epoch 129/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0673 - val_loss: 0.1314\n",
      "Epoch 130/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0662 - val_loss: 0.1349\n",
      "Epoch 131/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0660 - val_loss: 0.1339\n",
      "Epoch 132/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0650 - val_loss: 0.1300\n",
      "Epoch 133/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0649 - val_loss: 0.1310\n",
      "Epoch 134/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0645 - val_loss: 0.1316\n",
      "Epoch 135/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0640 - val_loss: 0.1306\n",
      "Epoch 136/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0636 - val_loss: 0.1322\n",
      "Epoch 137/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0633 - val_loss: 0.1311\n",
      "Epoch 138/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0628 - val_loss: 0.1311\n",
      "Epoch 139/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0633 - val_loss: 0.1285\n",
      "Epoch 140/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0619 - val_loss: 0.1356\n",
      "Epoch 141/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0617 - val_loss: 0.1299\n",
      "Epoch 142/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0615 - val_loss: 0.1268\n",
      "Epoch 143/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0612 - val_loss: 0.1313\n",
      "Epoch 144/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0605 - val_loss: 0.1304\n",
      "Epoch 145/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0609 - val_loss: 0.1260\n",
      "Epoch 146/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0610 - val_loss: 0.1353\n",
      "Epoch 147/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0603 - val_loss: 0.1248\n",
      "Epoch 148/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0593 - val_loss: 0.1289\n",
      "Epoch 149/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0599 - val_loss: 0.1247\n",
      "Epoch 150/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0591 - val_loss: 0.1301\n",
      "Epoch 151/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0586 - val_loss: 0.1287\n",
      "Epoch 152/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0576 - val_loss: 0.1256\n",
      "Epoch 153/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0572 - val_loss: 0.1267\n",
      "Epoch 154/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0571 - val_loss: 0.1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0564 - val_loss: 0.1270\n",
      "Epoch 156/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0566 - val_loss: 0.1258\n",
      "Epoch 157/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0558 - val_loss: 0.1291\n",
      "Epoch 158/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0556 - val_loss: 0.1254\n",
      "Epoch 159/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0556 - val_loss: 0.1248\n",
      "Epoch 160/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0546 - val_loss: 0.1293\n",
      "Epoch 161/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0554 - val_loss: 0.1307\n",
      "Epoch 162/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0548 - val_loss: 0.1237\n",
      "Epoch 163/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0543 - val_loss: 0.1249\n",
      "Epoch 164/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0538 - val_loss: 0.1262\n",
      "Epoch 165/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0533 - val_loss: 0.1231\n",
      "Epoch 166/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0538 - val_loss: 0.1284\n",
      "Epoch 167/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0531 - val_loss: 0.1258\n",
      "Epoch 168/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0527 - val_loss: 0.1260\n",
      "Epoch 169/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0526 - val_loss: 0.1267\n",
      "Epoch 170/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0519 - val_loss: 0.1246\n",
      "Epoch 171/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0525 - val_loss: 0.1266\n",
      "Epoch 172/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0514 - val_loss: 0.1230\n",
      "Epoch 173/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0514 - val_loss: 0.1248\n",
      "Epoch 174/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0510 - val_loss: 0.1240\n",
      "Epoch 175/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0507 - val_loss: 0.1245\n",
      "Epoch 176/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0506 - val_loss: 0.1257\n",
      "Epoch 177/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0506 - val_loss: 0.1236\n",
      "Epoch 178/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0500 - val_loss: 0.1236\n",
      "Epoch 179/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0497 - val_loss: 0.1242\n",
      "Epoch 180/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0494 - val_loss: 0.1237\n",
      "Epoch 181/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0493 - val_loss: 0.1236\n",
      "Epoch 182/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0490 - val_loss: 0.1210\n",
      "Epoch 183/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0496 - val_loss: 0.1233\n",
      "Epoch 184/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0489 - val_loss: 0.1222\n",
      "Epoch 185/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0483 - val_loss: 0.1234\n",
      "Epoch 186/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0481 - val_loss: 0.1262\n",
      "Epoch 187/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0482 - val_loss: 0.1226\n",
      "Epoch 188/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0478 - val_loss: 0.1227\n",
      "Epoch 189/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0475 - val_loss: 0.1243\n",
      "Epoch 190/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0473 - val_loss: 0.1229\n",
      "Epoch 191/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0469 - val_loss: 0.1240\n",
      "Epoch 192/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0468 - val_loss: 0.1271\n",
      "Epoch 193/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0475 - val_loss: 0.1268\n",
      "Epoch 194/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0464 - val_loss: 0.1207\n",
      "Epoch 195/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0465 - val_loss: 0.1224\n",
      "Epoch 196/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0468 - val_loss: 0.1230\n",
      "Epoch 197/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0462 - val_loss: 0.1288\n",
      "Epoch 198/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0458 - val_loss: 0.1224\n",
      "Epoch 199/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0458 - val_loss: 0.1233\n",
      "Epoch 200/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0454 - val_loss: 0.1262\n",
      "Epoch 201/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0451 - val_loss: 0.1234\n",
      "Epoch 202/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0448 - val_loss: 0.1234\n",
      "Epoch 203/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0451 - val_loss: 0.1220\n",
      "Epoch 204/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0443 - val_loss: 0.1241\n",
      "Epoch 205/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0450 - val_loss: 0.1289\n",
      "Epoch 206/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0445 - val_loss: 0.1220\n",
      "Epoch 207/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0443 - val_loss: 0.1215\n",
      "Epoch 208/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0439 - val_loss: 0.1232\n",
      "Epoch 209/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0444 - val_loss: 0.1306\n",
      "Epoch 210/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0435 - val_loss: 0.1223\n",
      "Epoch 211/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0434 - val_loss: 0.1228\n",
      "Epoch 212/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0428 - val_loss: 0.1250\n",
      "Epoch 213/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0429 - val_loss: 0.1247\n",
      "Epoch 214/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0428 - val_loss: 0.1236\n",
      "Epoch 215/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0427 - val_loss: 0.1230\n",
      "Epoch 216/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0424 - val_loss: 0.1243\n",
      "Epoch 217/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0425 - val_loss: 0.1247\n",
      "Epoch 218/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0420 - val_loss: 0.1229\n",
      "Epoch 219/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0420 - val_loss: 0.1209\n",
      "Epoch 220/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0418 - val_loss: 0.1259\n",
      "Epoch 221/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0417 - val_loss: 0.1227\n",
      "Epoch 222/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0414 - val_loss: 0.1231\n",
      "Epoch 223/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0411 - val_loss: 0.1224\n",
      "Epoch 224/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0409 - val_loss: 0.1233\n",
      "Epoch 225/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0409 - val_loss: 0.1248\n",
      "Epoch 226/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0408 - val_loss: 0.1233\n",
      "Epoch 227/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0406 - val_loss: 0.1253\n",
      "Epoch 228/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0412 - val_loss: 0.1231\n",
      "Epoch 229/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0404 - val_loss: 0.1252\n",
      "Epoch 230/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0405 - val_loss: 0.1222\n",
      "Epoch 231/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0400 - val_loss: 0.1239\n",
      "Epoch 232/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0399 - val_loss: 0.1248\n",
      "Epoch 233/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0399 - val_loss: 0.1228\n",
      "Epoch 234/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0397 - val_loss: 0.1249\n",
      "Epoch 235/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0398 - val_loss: 0.1249\n",
      "Epoch 236/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0393 - val_loss: 0.1227\n",
      "Epoch 237/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0396 - val_loss: 0.1262\n",
      "Epoch 238/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0393 - val_loss: 0.1231\n",
      "Epoch 239/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0390 - val_loss: 0.1234\n",
      "Epoch 240/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0388 - val_loss: 0.1244\n",
      "Epoch 241/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0396 - val_loss: 0.1218\n",
      "Epoch 242/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0387 - val_loss: 0.1243\n",
      "Epoch 243/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0382 - val_loss: 0.1248\n",
      "Epoch 244/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0391 - val_loss: 0.1259\n",
      "Epoch 245/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0386 - val_loss: 0.1212\n",
      "Epoch 246/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0387 - val_loss: 0.1252\n",
      "Epoch 247/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0380 - val_loss: 0.1253\n",
      "Epoch 248/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0382 - val_loss: 0.1230\n",
      "Epoch 249/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0379 - val_loss: 0.1281\n",
      "Epoch 250/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0376 - val_loss: 0.1246\n",
      "Epoch 251/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0377 - val_loss: 0.1229\n",
      "Epoch 252/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0374 - val_loss: 0.1257\n",
      "Epoch 253/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0377 - val_loss: 0.1237\n",
      "Epoch 254/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0375 - val_loss: 0.1244\n",
      "Epoch 255/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0376 - val_loss: 0.1280\n",
      "Epoch 256/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0365 - val_loss: 0.1243\n",
      "Epoch 257/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0368 - val_loss: 0.1232\n",
      "Epoch 258/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0367 - val_loss: 0.1252\n",
      "Epoch 259/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0363 - val_loss: 0.1259\n",
      "Epoch 260/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0365 - val_loss: 0.1249\n",
      "Epoch 261/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0363 - val_loss: 0.1256\n",
      "Epoch 262/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0362 - val_loss: 0.1265\n",
      "Epoch 263/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0366 - val_loss: 0.1246\n",
      "Epoch 264/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0357 - val_loss: 0.1290\n",
      "Epoch 265/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0361 - val_loss: 0.1274\n",
      "Epoch 266/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0355 - val_loss: 0.1263\n",
      "Epoch 267/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0362 - val_loss: 0.1245\n",
      "Epoch 268/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0356 - val_loss: 0.1289\n",
      "Epoch 269/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0355 - val_loss: 0.1266\n",
      "Epoch 270/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0356 - val_loss: 0.1261\n",
      "Epoch 271/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0351 - val_loss: 0.1257\n",
      "Epoch 272/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0358 - val_loss: 0.1260\n",
      "Epoch 273/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0348 - val_loss: 0.1282\n",
      "Epoch 274/600\n",
      "364/364 [==============================] - 0s 168us/sample - loss: 0.0351 - val_loss: 0.1288\n",
      "Epoch 275/600\n",
      "364/364 [==============================] - 0s 118us/sample - loss: 0.0352 - val_loss: 0.1277\n",
      "Epoch 276/600\n",
      "364/364 [==============================] - 0s 91us/sample - loss: 0.0354 - val_loss: 0.1245\n",
      "Epoch 277/600\n",
      "364/364 [==============================] - 0s 94us/sample - loss: 0.0343 - val_loss: 0.1276\n",
      "Epoch 278/600\n",
      "364/364 [==============================] - 0s 104us/sample - loss: 0.0346 - val_loss: 0.1315\n",
      "Epoch 279/600\n",
      "364/364 [==============================] - 0s 95us/sample - loss: 0.0349 - val_loss: 0.1270\n",
      "Epoch 280/600\n",
      "364/364 [==============================] - 0s 99us/sample - loss: 0.0355 - val_loss: 0.1262\n",
      "Epoch 281/600\n",
      "364/364 [==============================] - 0s 96us/sample - loss: 0.0338 - val_loss: 0.1322\n",
      "Epoch 282/600\n",
      "364/364 [==============================] - 0s 92us/sample - loss: 0.0343 - val_loss: 0.1281\n",
      "Epoch 283/600\n",
      "364/364 [==============================] - 0s 107us/sample - loss: 0.0338 - val_loss: 0.1266\n",
      "Epoch 284/600\n",
      "364/364 [==============================] - 0s 110us/sample - loss: 0.0339 - val_loss: 0.1297\n",
      "Epoch 285/600\n",
      "364/364 [==============================] - 0s 116us/sample - loss: 0.0338 - val_loss: 0.1294\n",
      "Epoch 286/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0338 - val_loss: 0.1291\n",
      "Epoch 287/600\n",
      "364/364 [==============================] - 0s 104us/sample - loss: 0.0338 - val_loss: 0.1290\n",
      "Epoch 288/600\n",
      "364/364 [==============================] - 0s 104us/sample - loss: 0.0333 - val_loss: 0.1269\n",
      "Epoch 289/600\n",
      "364/364 [==============================] - 0s 99us/sample - loss: 0.0337 - val_loss: 0.1268\n",
      "Epoch 290/600\n",
      "364/364 [==============================] - 0s 96us/sample - loss: 0.0334 - val_loss: 0.1298\n",
      "Epoch 291/600\n",
      "364/364 [==============================] - 0s 95us/sample - loss: 0.0331 - val_loss: 0.1278\n",
      "Epoch 292/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0336 - val_loss: 0.1299\n",
      "Epoch 293/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0327 - val_loss: 0.1261\n",
      "Epoch 294/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0334 - val_loss: 0.1273\n",
      "Epoch 295/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0332 - val_loss: 0.1286\n",
      "Epoch 296/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0325 - val_loss: 0.1272\n",
      "Epoch 297/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0331 - val_loss: 0.1274\n",
      "Epoch 298/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0331 - val_loss: 0.1272\n",
      "Epoch 299/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0323 - val_loss: 0.1290\n",
      "Epoch 300/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0326 - val_loss: 0.1329\n",
      "Epoch 301/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0331 - val_loss: 0.1306\n",
      "Epoch 302/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0321 - val_loss: 0.1276\n",
      "Epoch 303/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0324 - val_loss: 0.1284\n",
      "Epoch 304/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0324 - val_loss: 0.1287\n",
      "Epoch 305/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0327 - val_loss: 0.1321\n",
      "Epoch 306/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0320 - val_loss: 0.1296\n",
      "Epoch 307/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0324 - val_loss: 0.1283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0318 - val_loss: 0.1308\n",
      "Epoch 309/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0317 - val_loss: 0.1293\n",
      "Epoch 310/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0315 - val_loss: 0.1300\n",
      "Epoch 311/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0315 - val_loss: 0.1288\n",
      "Epoch 312/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0318 - val_loss: 0.1316\n",
      "Epoch 313/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0313 - val_loss: 0.1283\n",
      "Epoch 314/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0315 - val_loss: 0.1284\n",
      "Epoch 315/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0313 - val_loss: 0.1304\n",
      "Epoch 316/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0310 - val_loss: 0.1295\n",
      "Epoch 317/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0309 - val_loss: 0.1292\n",
      "Epoch 318/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0320 - val_loss: 0.1284\n",
      "Epoch 319/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0307 - val_loss: 0.1309\n",
      "Epoch 320/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0312 - val_loss: 0.1304\n",
      "Epoch 321/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0307 - val_loss: 0.1312\n",
      "Epoch 322/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0306 - val_loss: 0.1305\n",
      "Epoch 323/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0305 - val_loss: 0.1307\n",
      "Epoch 324/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0307 - val_loss: 0.1320\n",
      "Epoch 325/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0331 - val_loss: 0.1283\n",
      "Epoch 326/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0322 - val_loss: 0.1334\n",
      "Epoch 327/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0304 - val_loss: 0.1309\n",
      "Epoch 328/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0300 - val_loss: 0.1299\n",
      "Epoch 329/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0314 - val_loss: 0.1325\n",
      "Epoch 330/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0299 - val_loss: 0.1289\n",
      "Epoch 331/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0306 - val_loss: 0.1297\n",
      "Epoch 332/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0300 - val_loss: 0.1322\n",
      "Epoch 333/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0302 - val_loss: 0.1309\n",
      "Epoch 334/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0299 - val_loss: 0.1315\n",
      "Epoch 335/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0298 - val_loss: 0.1316\n",
      "Epoch 336/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0296 - val_loss: 0.1320\n",
      "Epoch 337/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0299 - val_loss: 0.1315\n",
      "Epoch 338/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0297 - val_loss: 0.1317\n",
      "Epoch 339/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0293 - val_loss: 0.1311\n",
      "Epoch 340/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0294 - val_loss: 0.1312\n",
      "Epoch 341/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0297 - val_loss: 0.1315\n",
      "Epoch 342/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0295 - val_loss: 0.1320\n",
      "Epoch 343/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0292 - val_loss: 0.1316\n",
      "Epoch 344/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0290 - val_loss: 0.1340\n",
      "Epoch 345/600\n",
      "364/364 [==============================] - 0s 102us/sample - loss: 0.0291 - val_loss: 0.1324\n",
      "Epoch 346/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0290 - val_loss: 0.1322\n",
      "Epoch 347/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0290 - val_loss: 0.1319\n",
      "Epoch 348/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0289 - val_loss: 0.1328\n",
      "Epoch 349/600\n",
      "364/364 [==============================] - 0s 172us/sample - loss: 0.0293 - val_loss: 0.1316\n",
      "Epoch 350/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0287 - val_loss: 0.1320\n",
      "Epoch 351/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0286 - val_loss: 0.1332\n",
      "Epoch 352/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0285 - val_loss: 0.1335\n",
      "Epoch 353/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0297 - val_loss: 0.1321\n",
      "Epoch 354/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0322 - val_loss: 0.1373\n",
      "Epoch 355/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0288 - val_loss: 0.1340\n",
      "Epoch 356/600\n",
      "364/364 [==============================] - 0s 164us/sample - loss: 0.0307 - val_loss: 0.1320\n",
      "Epoch 357/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0287 - val_loss: 0.1355\n",
      "Epoch 358/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.0285 - val_loss: 0.1339\n",
      "Epoch 359/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0282 - val_loss: 0.1331\n",
      "Epoch 360/600\n",
      "364/364 [==============================] - 0s 111us/sample - loss: 0.0283 - val_loss: 0.1340\n",
      "Epoch 361/600\n",
      "364/364 [==============================] - 0s 116us/sample - loss: 0.0282 - val_loss: 0.1325\n",
      "Epoch 362/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0282 - val_loss: 0.1341\n",
      "Epoch 363/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0291 - val_loss: 0.1353\n",
      "Epoch 364/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0289 - val_loss: 0.1325\n",
      "Epoch 365/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0306 - val_loss: 0.1344\n",
      "Epoch 366/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0276 - val_loss: 0.1339\n",
      "Epoch 367/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0276 - val_loss: 0.1338\n",
      "Epoch 368/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0279 - val_loss: 0.1334\n",
      "Epoch 369/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0280 - val_loss: 0.1340\n",
      "Epoch 370/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0277 - val_loss: 0.1341\n",
      "Epoch 371/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0276 - val_loss: 0.1352\n",
      "Epoch 372/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0277 - val_loss: 0.1347\n",
      "Epoch 373/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0274 - val_loss: 0.1342\n",
      "Epoch 374/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0280 - val_loss: 0.1337\n",
      "Epoch 375/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0282 - val_loss: 0.1363\n",
      "Epoch 376/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0272 - val_loss: 0.1349\n",
      "Epoch 377/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0272 - val_loss: 0.1344\n",
      "Epoch 378/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0278 - val_loss: 0.1352\n",
      "Epoch 379/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0269 - val_loss: 0.1361\n",
      "Epoch 380/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0274 - val_loss: 0.1365\n",
      "Epoch 381/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0281 - val_loss: 0.1341\n",
      "Epoch 382/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0275 - val_loss: 0.1370\n",
      "Epoch 383/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0268 - val_loss: 0.1362\n",
      "Epoch 384/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0273 - val_loss: 0.1353\n",
      "Epoch 385/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0271 - val_loss: 0.1355\n",
      "Epoch 386/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0270 - val_loss: 0.1365\n",
      "Epoch 387/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0266 - val_loss: 0.1372\n",
      "Epoch 388/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0269 - val_loss: 0.1363\n",
      "Epoch 389/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0266 - val_loss: 0.1356\n",
      "Epoch 390/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0266 - val_loss: 0.1363\n",
      "Epoch 391/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0269 - val_loss: 0.1368\n",
      "Epoch 392/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0269 - val_loss: 0.1352\n",
      "Epoch 393/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0284 - val_loss: 0.1351\n",
      "Epoch 394/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0283 - val_loss: 0.1454\n",
      "Epoch 395/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0280 - val_loss: 0.1378\n",
      "Epoch 396/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0259 - val_loss: 0.1361\n",
      "Epoch 397/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0265 - val_loss: 0.1364\n",
      "Epoch 398/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0261 - val_loss: 0.1386\n",
      "Epoch 399/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0260 - val_loss: 0.1376\n",
      "Epoch 400/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0283 - val_loss: 0.1367\n",
      "Epoch 401/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0269 - val_loss: 0.1392\n",
      "Epoch 402/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0264 - val_loss: 0.1373\n",
      "Epoch 403/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0255 - val_loss: 0.1385\n",
      "Epoch 404/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0261 - val_loss: 0.1390\n",
      "Epoch 405/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0259 - val_loss: 0.1374\n",
      "Epoch 406/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0258 - val_loss: 0.1386\n",
      "Epoch 407/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0274 - val_loss: 0.1403\n",
      "Epoch 408/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0267 - val_loss: 0.1372\n",
      "Epoch 409/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0258 - val_loss: 0.1383\n",
      "Epoch 410/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0252 - val_loss: 0.1412\n",
      "Epoch 411/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0262 - val_loss: 0.1395\n",
      "Epoch 412/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0258 - val_loss: 0.1385\n",
      "Epoch 413/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0257 - val_loss: 0.1391\n",
      "Epoch 414/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0266 - val_loss: 0.1403\n",
      "Epoch 415/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0254 - val_loss: 0.1385\n",
      "Epoch 416/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0282 - val_loss: 0.1376\n",
      "Epoch 417/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0256 - val_loss: 0.1430\n",
      "Epoch 418/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0259 - val_loss: 0.1399\n",
      "Epoch 419/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0248 - val_loss: 0.1384\n",
      "Epoch 420/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0257 - val_loss: 0.1384\n",
      "Epoch 421/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0251 - val_loss: 0.1407\n",
      "Epoch 422/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0259 - val_loss: 0.1392\n",
      "Epoch 423/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0248 - val_loss: 0.1405\n",
      "Epoch 424/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0253 - val_loss: 0.1393\n",
      "Epoch 425/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0262 - val_loss: 0.1389\n",
      "Epoch 426/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0253 - val_loss: 0.1420\n",
      "Epoch 427/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0258 - val_loss: 0.1411\n",
      "Epoch 428/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0261 - val_loss: 0.1387\n",
      "Epoch 429/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0257 - val_loss: 0.1391\n",
      "Epoch 430/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0252 - val_loss: 0.1401\n",
      "Epoch 431/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0248 - val_loss: 0.1395\n",
      "Epoch 432/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0248 - val_loss: 0.1393\n",
      "Epoch 433/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0249 - val_loss: 0.1392\n",
      "Epoch 434/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0247 - val_loss: 0.1400\n",
      "Epoch 435/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0250 - val_loss: 0.1396\n",
      "Epoch 436/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0246 - val_loss: 0.1389\n",
      "Epoch 437/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0247 - val_loss: 0.1397\n",
      "Epoch 438/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0244 - val_loss: 0.1392\n",
      "Epoch 439/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0252 - val_loss: 0.1402\n",
      "Epoch 440/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0241 - val_loss: 0.1389\n",
      "Epoch 441/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0245 - val_loss: 0.1391\n",
      "Epoch 442/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0242 - val_loss: 0.1390\n",
      "Epoch 443/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0244 - val_loss: 0.1388\n",
      "Epoch 444/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0245 - val_loss: 0.1391\n",
      "Epoch 445/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0240 - val_loss: 0.1401\n",
      "Epoch 446/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0241 - val_loss: 0.1399\n",
      "Epoch 447/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0244 - val_loss: 0.1395\n",
      "Epoch 448/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0241 - val_loss: 0.1402\n",
      "Epoch 449/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0241 - val_loss: 0.1401\n",
      "Epoch 450/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0244 - val_loss: 0.1396\n",
      "Epoch 451/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0241 - val_loss: 0.1406\n",
      "Epoch 452/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0248 - val_loss: 0.1410\n",
      "Epoch 453/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0240 - val_loss: 0.1395\n",
      "Epoch 454/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0245 - val_loss: 0.1398\n",
      "Epoch 455/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0237 - val_loss: 0.1415\n",
      "Epoch 456/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0243 - val_loss: 0.1413\n",
      "Epoch 457/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0239 - val_loss: 0.1401\n",
      "Epoch 458/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0237 - val_loss: 0.1406\n",
      "Epoch 459/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0237 - val_loss: 0.1417\n",
      "Epoch 460/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0243 - val_loss: 0.1408\n",
      "Epoch 461/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0242 - val_loss: 0.1428\n",
      "Epoch 462/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0239 - val_loss: 0.1414\n",
      "Epoch 463/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0235 - val_loss: 0.1412\n",
      "Epoch 464/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0234 - val_loss: 0.1414\n",
      "Epoch 465/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0243 - val_loss: 0.1426\n",
      "Epoch 466/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0234 - val_loss: 0.1411\n",
      "Epoch 467/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0235 - val_loss: 0.1419\n",
      "Epoch 468/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0237 - val_loss: 0.1419\n",
      "Epoch 469/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0233 - val_loss: 0.1411\n",
      "Epoch 470/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0239 - val_loss: 0.1412\n",
      "Epoch 471/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0229 - val_loss: 0.1424\n",
      "Epoch 472/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0236 - val_loss: 0.1426\n",
      "Epoch 473/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0235 - val_loss: 0.1425\n",
      "Epoch 474/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0235 - val_loss: 0.1423\n",
      "Epoch 475/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0240 - val_loss: 0.1420\n",
      "Epoch 476/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0229 - val_loss: 0.1426\n",
      "Epoch 477/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0234 - val_loss: 0.1435\n",
      "Epoch 478/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0231 - val_loss: 0.1426\n",
      "Epoch 479/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0231 - val_loss: 0.1422\n",
      "Epoch 480/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0234 - val_loss: 0.1427\n",
      "Epoch 481/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0243 - val_loss: 0.1428\n",
      "Epoch 482/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0228 - val_loss: 0.1440\n",
      "Epoch 483/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0231 - val_loss: 0.1441\n",
      "Epoch 484/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0229 - val_loss: 0.1444\n",
      "Epoch 485/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0232 - val_loss: 0.1442\n",
      "Epoch 486/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0262 - val_loss: 0.1439\n",
      "Epoch 487/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0244 - val_loss: 0.1444\n",
      "Epoch 488/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0231 - val_loss: 0.1435\n",
      "Epoch 489/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0229 - val_loss: 0.1438\n",
      "Epoch 490/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0226 - val_loss: 0.1447\n",
      "Epoch 491/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0227 - val_loss: 0.1441\n",
      "Epoch 492/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0231 - val_loss: 0.1439\n",
      "Epoch 493/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0228 - val_loss: 0.1455\n",
      "Epoch 494/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0230 - val_loss: 0.1443\n",
      "Epoch 495/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0226 - val_loss: 0.1436\n",
      "Epoch 496/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0229 - val_loss: 0.1439\n",
      "Epoch 497/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0226 - val_loss: 0.1456\n",
      "Epoch 498/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0225 - val_loss: 0.1447\n",
      "Epoch 499/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0222 - val_loss: 0.1442\n",
      "Epoch 500/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0241 - val_loss: 0.1442\n",
      "Epoch 501/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0230 - val_loss: 0.1460\n",
      "Epoch 502/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0224 - val_loss: 0.1447\n",
      "Epoch 503/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0222 - val_loss: 0.1445\n",
      "Epoch 504/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0226 - val_loss: 0.1447\n",
      "Epoch 505/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0236 - val_loss: 0.1443\n",
      "Epoch 506/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0242 - val_loss: 0.1467\n",
      "Epoch 507/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0228 - val_loss: 0.1450\n",
      "Epoch 508/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0222 - val_loss: 0.1452\n",
      "Epoch 509/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0220 - val_loss: 0.1453\n",
      "Epoch 510/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0222 - val_loss: 0.1453\n",
      "Epoch 511/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0219 - val_loss: 0.1448\n",
      "Epoch 512/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0219 - val_loss: 0.1451\n",
      "Epoch 513/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0219 - val_loss: 0.1452\n",
      "Epoch 514/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0224 - val_loss: 0.1451\n",
      "Epoch 515/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0221 - val_loss: 0.1458\n",
      "Epoch 516/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0228 - val_loss: 0.1448\n",
      "Epoch 517/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0217 - val_loss: 0.1455\n",
      "Epoch 518/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0219 - val_loss: 0.1455\n",
      "Epoch 519/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0231 - val_loss: 0.1460\n",
      "Epoch 520/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0225 - val_loss: 0.1454\n",
      "Epoch 521/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0225 - val_loss: 0.1459\n",
      "Epoch 522/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0220 - val_loss: 0.1465\n",
      "Epoch 523/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0219 - val_loss: 0.1457\n",
      "Epoch 524/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0241 - val_loss: 0.1456\n",
      "Epoch 525/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0224 - val_loss: 0.1480\n",
      "Epoch 526/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0223 - val_loss: 0.1468\n",
      "Epoch 527/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0218 - val_loss: 0.1462\n",
      "Epoch 528/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0222 - val_loss: 0.1475\n",
      "Epoch 529/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0218 - val_loss: 0.1481\n",
      "Epoch 530/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0219 - val_loss: 0.1480\n",
      "Epoch 531/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0209 - val_loss: 0.1472\n",
      "Epoch 532/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0218 - val_loss: 0.1473\n",
      "Epoch 533/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0213 - val_loss: 0.1475\n",
      "Epoch 534/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0215 - val_loss: 0.1476\n",
      "Epoch 535/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0219 - val_loss: 0.1480\n",
      "Epoch 536/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0214 - val_loss: 0.1472\n",
      "Epoch 537/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0232 - val_loss: 0.1487\n",
      "Epoch 538/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0223 - val_loss: 0.1471\n",
      "Epoch 539/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0214 - val_loss: 0.1471\n",
      "Epoch 540/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0213 - val_loss: 0.1472\n",
      "Epoch 541/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0220 - val_loss: 0.1485\n",
      "Epoch 542/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0213 - val_loss: 0.1477\n",
      "Epoch 543/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0211 - val_loss: 0.1475\n",
      "Epoch 544/600\n",
      "364/364 [==============================] - 0s 118us/sample - loss: 0.0211 - val_loss: 0.1473\n",
      "Epoch 545/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0215 - val_loss: 0.1482\n",
      "Epoch 546/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0230 - val_loss: 0.1475\n",
      "Epoch 547/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0210 - val_loss: 0.1477\n",
      "Epoch 548/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0208 - val_loss: 0.1486\n",
      "Epoch 549/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0212 - val_loss: 0.1477\n",
      "Epoch 550/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0210 - val_loss: 0.1481\n",
      "Epoch 551/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0212 - val_loss: 0.1479\n",
      "Epoch 552/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0212 - val_loss: 0.1485\n",
      "Epoch 553/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0210 - val_loss: 0.1483\n",
      "Epoch 554/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0214 - val_loss: 0.1485\n",
      "Epoch 555/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0214 - val_loss: 0.1479\n",
      "Epoch 556/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0207 - val_loss: 0.1488\n",
      "Epoch 557/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0211 - val_loss: 0.1483\n",
      "Epoch 558/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0208 - val_loss: 0.1479\n",
      "Epoch 559/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0209 - val_loss: 0.1483\n",
      "Epoch 560/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0207 - val_loss: 0.1483\n",
      "Epoch 561/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0210 - val_loss: 0.1489\n",
      "Epoch 562/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0215 - val_loss: 0.1484\n",
      "Epoch 563/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0217 - val_loss: 0.1491\n",
      "Epoch 564/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0208 - val_loss: 0.1485\n",
      "Epoch 565/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0206 - val_loss: 0.1488\n",
      "Epoch 566/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0207 - val_loss: 0.1484\n",
      "Epoch 567/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0229 - val_loss: 0.1487\n",
      "Epoch 568/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0205 - val_loss: 0.1489\n",
      "Epoch 569/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0214 - val_loss: 0.1487\n",
      "Epoch 570/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0210 - val_loss: 0.1500\n",
      "Epoch 571/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0207 - val_loss: 0.1491\n",
      "Epoch 572/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0211 - val_loss: 0.1485\n",
      "Epoch 573/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0205 - val_loss: 0.1511\n",
      "Epoch 574/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0212 - val_loss: 0.1494\n",
      "Epoch 575/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0201 - val_loss: 0.1486\n",
      "Epoch 576/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0206 - val_loss: 0.1487\n",
      "Epoch 577/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0205 - val_loss: 0.1490\n",
      "Epoch 578/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0200 - val_loss: 0.1493\n",
      "Epoch 579/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0203 - val_loss: 0.1499\n",
      "Epoch 580/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0200 - val_loss: 0.1495\n",
      "Epoch 581/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0208 - val_loss: 0.1496\n",
      "Epoch 582/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0227 - val_loss: 0.1509\n",
      "Epoch 583/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0222 - val_loss: 0.1498\n",
      "Epoch 584/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0201 - val_loss: 0.1502\n",
      "Epoch 585/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0201 - val_loss: 0.1508\n",
      "Epoch 586/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0204 - val_loss: 0.1498\n",
      "Epoch 587/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0201 - val_loss: 0.1497\n",
      "Epoch 588/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0199 - val_loss: 0.1496\n",
      "Epoch 589/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0202 - val_loss: 0.1497\n",
      "Epoch 590/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0206 - val_loss: 0.1499\n",
      "Epoch 591/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0197 - val_loss: 0.1507\n",
      "Epoch 592/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0206 - val_loss: 0.1509\n",
      "Epoch 593/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0200 - val_loss: 0.1502\n",
      "Epoch 594/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0198 - val_loss: 0.1506\n",
      "Epoch 595/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0200 - val_loss: 0.1512\n",
      "Epoch 596/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0200 - val_loss: 0.1508\n",
      "Epoch 597/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0198 - val_loss: 0.1508\n",
      "Epoch 598/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0207 - val_loss: 0.1506\n",
      "Epoch 599/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0197 - val_loss: 0.1511\n",
      "Epoch 600/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0199 - val_loss: 0.1512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc701adbc8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tiny.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model_tiny_df = pd.DataFrame(model_tiny.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc704b08c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_model_tiny_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  With early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tiny_es = Sequential()\n",
    "\n",
    "model_tiny_es.add(Dense(30, activation='relu'))\n",
    "\n",
    "model_tiny_es.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_tiny_es.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/600\n",
      "364/364 [==============================] - 1s 2ms/sample - loss: 0.6511 - val_loss: 0.6280\n",
      "Epoch 2/600\n",
      "364/364 [==============================] - 0s 115us/sample - loss: 0.6101 - val_loss: 0.5946\n",
      "Epoch 3/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.5772 - val_loss: 0.5647\n",
      "Epoch 4/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.5471 - val_loss: 0.5360\n",
      "Epoch 5/600\n",
      "364/364 [==============================] - 0s 110us/sample - loss: 0.5175 - val_loss: 0.5087\n",
      "Epoch 6/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.4893 - val_loss: 0.4831\n",
      "Epoch 7/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.4638 - val_loss: 0.4592\n",
      "Epoch 8/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.4380 - val_loss: 0.4362\n",
      "Epoch 9/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.4129 - val_loss: 0.4142\n",
      "Epoch 10/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.3905 - val_loss: 0.3952\n",
      "Epoch 11/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.3694 - val_loss: 0.3781\n",
      "Epoch 12/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.3506 - val_loss: 0.3634\n",
      "Epoch 13/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.3344 - val_loss: 0.3504\n",
      "Epoch 14/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.3184 - val_loss: 0.3398\n",
      "Epoch 15/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.3041 - val_loss: 0.3290\n",
      "Epoch 16/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.2913 - val_loss: 0.3190\n",
      "Epoch 17/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.2800 - val_loss: 0.3089\n",
      "Epoch 18/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.2690 - val_loss: 0.3031\n",
      "Epoch 19/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.2593 - val_loss: 0.2971\n",
      "Epoch 20/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.2505 - val_loss: 0.2901\n",
      "Epoch 21/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.2425 - val_loss: 0.2853\n",
      "Epoch 22/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.2341 - val_loss: 0.2781\n",
      "Epoch 23/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.2292 - val_loss: 0.2715\n",
      "Epoch 24/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.2195 - val_loss: 0.2728\n",
      "Epoch 25/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.2167 - val_loss: 0.2697\n",
      "Epoch 26/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.2093 - val_loss: 0.2624\n",
      "Epoch 27/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.2047 - val_loss: 0.2565\n",
      "Epoch 28/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.1991 - val_loss: 0.2556\n",
      "Epoch 29/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.1940 - val_loss: 0.2540\n",
      "Epoch 30/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.1901 - val_loss: 0.2482\n",
      "Epoch 31/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.1856 - val_loss: 0.2467\n",
      "Epoch 32/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.1812 - val_loss: 0.2420\n",
      "Epoch 33/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1775 - val_loss: 0.2372\n",
      "Epoch 34/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1743 - val_loss: 0.2375\n",
      "Epoch 35/600\n",
      "364/364 [==============================] - 0s 162us/sample - loss: 0.1715 - val_loss: 0.2313\n",
      "Epoch 36/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.1671 - val_loss: 0.2328\n",
      "Epoch 37/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.1645 - val_loss: 0.2290\n",
      "Epoch 38/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.1605 - val_loss: 0.2262\n",
      "Epoch 39/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.1577 - val_loss: 0.2220\n",
      "Epoch 40/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.1553 - val_loss: 0.2202\n",
      "Epoch 41/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1525 - val_loss: 0.2199\n",
      "Epoch 42/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.1497 - val_loss: 0.2148\n",
      "Epoch 43/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.1469 - val_loss: 0.2165\n",
      "Epoch 44/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1442 - val_loss: 0.2112\n",
      "Epoch 45/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1427 - val_loss: 0.2124\n",
      "Epoch 46/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.1395 - val_loss: 0.2065\n",
      "Epoch 47/600\n",
      "364/364 [==============================] - 0s 178us/sample - loss: 0.1376 - val_loss: 0.2049\n",
      "Epoch 48/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.1351 - val_loss: 0.2052\n",
      "Epoch 49/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.1338 - val_loss: 0.2058\n",
      "Epoch 50/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.1311 - val_loss: 0.2004\n",
      "Epoch 51/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1288 - val_loss: 0.1996\n",
      "Epoch 52/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1289 - val_loss: 0.2000\n",
      "Epoch 53/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1258 - val_loss: 0.1927\n",
      "Epoch 54/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1243 - val_loss: 0.1975\n",
      "Epoch 55/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1211 - val_loss: 0.1903\n",
      "Epoch 56/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.1199 - val_loss: 0.1892\n",
      "Epoch 57/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.1182 - val_loss: 0.1886\n",
      "Epoch 58/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1184 - val_loss: 0.1928\n",
      "Epoch 59/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.1147 - val_loss: 0.1820\n",
      "Epoch 60/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1145 - val_loss: 0.1825\n",
      "Epoch 61/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.1117 - val_loss: 0.1891\n",
      "Epoch 62/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.1106 - val_loss: 0.1841\n",
      "Epoch 63/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.1085 - val_loss: 0.1787\n",
      "Epoch 64/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1081 - val_loss: 0.1782\n",
      "Epoch 65/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.1070 - val_loss: 0.1832\n",
      "Epoch 66/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.1058 - val_loss: 0.1769\n",
      "Epoch 67/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1033 - val_loss: 0.1771\n",
      "Epoch 68/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.1022 - val_loss: 0.1766\n",
      "Epoch 69/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1007 - val_loss: 0.1713\n",
      "Epoch 70/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.1008 - val_loss: 0.1720\n",
      "Epoch 71/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0992 - val_loss: 0.1736\n",
      "Epoch 72/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0974 - val_loss: 0.1732\n",
      "Epoch 73/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0961 - val_loss: 0.1695\n",
      "Epoch 74/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0957 - val_loss: 0.1656\n",
      "Epoch 75/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0951 - val_loss: 0.1708\n",
      "Epoch 76/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0936 - val_loss: 0.1669\n",
      "Epoch 77/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0923 - val_loss: 0.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0912 - val_loss: 0.1659\n",
      "Epoch 79/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0903 - val_loss: 0.1643\n",
      "Epoch 80/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0895 - val_loss: 0.1692\n",
      "Epoch 81/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0883 - val_loss: 0.1645\n",
      "Epoch 82/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0882 - val_loss: 0.1637\n",
      "Epoch 83/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0867 - val_loss: 0.1602\n",
      "Epoch 84/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0864 - val_loss: 0.1642\n",
      "Epoch 85/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0847 - val_loss: 0.1587\n",
      "Epoch 86/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0840 - val_loss: 0.1603\n",
      "Epoch 87/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0839 - val_loss: 0.1640\n",
      "Epoch 88/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0834 - val_loss: 0.1549\n",
      "Epoch 89/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0811 - val_loss: 0.1615\n",
      "Epoch 90/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0815 - val_loss: 0.1618\n",
      "Epoch 91/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0798 - val_loss: 0.1548\n",
      "Epoch 92/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0793 - val_loss: 0.1538\n",
      "Epoch 93/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0785 - val_loss: 0.1548\n",
      "Epoch 94/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0778 - val_loss: 0.1562\n",
      "Epoch 95/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0772 - val_loss: 0.1536\n",
      "Epoch 96/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0765 - val_loss: 0.1536\n",
      "Epoch 97/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0758 - val_loss: 0.1535\n",
      "Epoch 98/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0751 - val_loss: 0.1518\n",
      "Epoch 99/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0745 - val_loss: 0.1507\n",
      "Epoch 100/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0740 - val_loss: 0.1518\n",
      "Epoch 101/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0731 - val_loss: 0.1472\n",
      "Epoch 102/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0730 - val_loss: 0.1456\n",
      "Epoch 103/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0721 - val_loss: 0.1495\n",
      "Epoch 104/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0714 - val_loss: 0.1492\n",
      "Epoch 105/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0712 - val_loss: 0.1465\n",
      "Epoch 106/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0702 - val_loss: 0.1479\n",
      "Epoch 107/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0711 - val_loss: 0.1524\n",
      "Epoch 108/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0695 - val_loss: 0.1440\n",
      "Epoch 109/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0689 - val_loss: 0.1456\n",
      "Epoch 110/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0690 - val_loss: 0.1516\n",
      "Epoch 111/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0676 - val_loss: 0.1419\n",
      "Epoch 112/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0679 - val_loss: 0.1452\n",
      "Epoch 113/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0670 - val_loss: 0.1445\n",
      "Epoch 114/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0664 - val_loss: 0.1477\n",
      "Epoch 115/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0654 - val_loss: 0.1430\n",
      "Epoch 116/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0659 - val_loss: 0.1402\n",
      "Epoch 117/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0648 - val_loss: 0.1493\n",
      "Epoch 118/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0651 - val_loss: 0.1412\n",
      "Epoch 119/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0639 - val_loss: 0.1446\n",
      "Epoch 120/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0634 - val_loss: 0.1440\n",
      "Epoch 121/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0637 - val_loss: 0.1403\n",
      "Epoch 122/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0629 - val_loss: 0.1401\n",
      "Epoch 123/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0615 - val_loss: 0.1495\n",
      "Epoch 124/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0619 - val_loss: 0.1421\n",
      "Epoch 125/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0637 - val_loss: 0.1507\n",
      "Epoch 126/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0605 - val_loss: 0.1409\n",
      "Epoch 127/600\n",
      "364/364 [==============================] - 0s 117us/sample - loss: 0.0607 - val_loss: 0.1386\n",
      "Epoch 128/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0597 - val_loss: 0.1426\n",
      "Epoch 129/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0611 - val_loss: 0.1466\n",
      "Epoch 130/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0595 - val_loss: 0.1422\n",
      "Epoch 131/600\n",
      "364/364 [==============================] - 0s 116us/sample - loss: 0.0587 - val_loss: 0.1447\n",
      "Epoch 132/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0602 - val_loss: 0.1396\n",
      "Epoch 133/600\n",
      "364/364 [==============================] - 0s 116us/sample - loss: 0.0593 - val_loss: 0.1487\n",
      "Epoch 134/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0580 - val_loss: 0.1383\n",
      "Epoch 135/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0574 - val_loss: 0.1391\n",
      "Epoch 136/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0568 - val_loss: 0.1437\n",
      "Epoch 137/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0571 - val_loss: 0.1397\n",
      "Epoch 138/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0566 - val_loss: 0.1406\n",
      "Epoch 139/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0572 - val_loss: 0.1462\n",
      "Epoch 140/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0557 - val_loss: 0.1359\n",
      "Epoch 141/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0561 - val_loss: 0.1408\n",
      "Epoch 142/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0559 - val_loss: 0.1364\n",
      "Epoch 143/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0554 - val_loss: 0.1465\n",
      "Epoch 144/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0545 - val_loss: 0.1387\n",
      "Epoch 145/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0569 - val_loss: 0.1350\n",
      "Epoch 146/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0546 - val_loss: 0.1504\n",
      "Epoch 147/600\n",
      "364/364 [==============================] - 0s 118us/sample - loss: 0.0549 - val_loss: 0.1368\n",
      "Epoch 148/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0530 - val_loss: 0.1389\n",
      "Epoch 149/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0535 - val_loss: 0.1418\n",
      "Epoch 150/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0525 - val_loss: 0.1357\n",
      "Epoch 151/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0522 - val_loss: 0.1375\n",
      "Epoch 152/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0520 - val_loss: 0.1382\n",
      "Epoch 153/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0529 - val_loss: 0.1418\n",
      "Epoch 154/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0543 - val_loss: 0.1333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0521 - val_loss: 0.1467\n",
      "Epoch 156/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0514 - val_loss: 0.1373\n",
      "Epoch 157/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0505 - val_loss: 0.1338\n",
      "Epoch 158/600\n",
      "364/364 [==============================] - 0s 120us/sample - loss: 0.0510 - val_loss: 0.1367\n",
      "Epoch 159/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0503 - val_loss: 0.1359\n",
      "Epoch 160/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0497 - val_loss: 0.1377\n",
      "Epoch 161/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0497 - val_loss: 0.1378\n",
      "Epoch 162/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0496 - val_loss: 0.1368\n",
      "Epoch 163/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0493 - val_loss: 0.1361\n",
      "Epoch 164/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0491 - val_loss: 0.1360\n",
      "Epoch 165/600\n",
      "364/364 [==============================] - 0s 127us/sample - loss: 0.0496 - val_loss: 0.1322\n",
      "Epoch 166/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0493 - val_loss: 0.1404\n",
      "Epoch 167/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0485 - val_loss: 0.1398\n",
      "Epoch 168/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0483 - val_loss: 0.1361\n",
      "Epoch 169/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0483 - val_loss: 0.1330\n",
      "Epoch 170/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0475 - val_loss: 0.1379\n",
      "Epoch 171/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0472 - val_loss: 0.1387\n",
      "Epoch 172/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0474 - val_loss: 0.1358\n",
      "Epoch 173/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0477 - val_loss: 0.1389\n",
      "Epoch 174/600\n",
      "364/364 [==============================] - 0s 126us/sample - loss: 0.0473 - val_loss: 0.1332\n",
      "Epoch 175/600\n",
      "364/364 [==============================] - 0s 125us/sample - loss: 0.0468 - val_loss: 0.1406\n",
      "Epoch 176/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0465 - val_loss: 0.1356\n",
      "Epoch 177/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0460 - val_loss: 0.1379\n",
      "Epoch 178/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0464 - val_loss: 0.1354\n",
      "Epoch 179/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0459 - val_loss: 0.1387\n",
      "Epoch 180/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0456 - val_loss: 0.1369\n",
      "Epoch 181/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0453 - val_loss: 0.1343\n",
      "Epoch 182/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0451 - val_loss: 0.1361\n",
      "Epoch 183/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0449 - val_loss: 0.1366\n",
      "Epoch 184/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0446 - val_loss: 0.1318\n",
      "Epoch 185/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0447 - val_loss: 0.1356\n",
      "Epoch 186/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0449 - val_loss: 0.1393\n",
      "Epoch 187/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0440 - val_loss: 0.1345\n",
      "Epoch 188/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0443 - val_loss: 0.1360\n",
      "Epoch 189/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.0439 - val_loss: 0.1366\n",
      "Epoch 190/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0435 - val_loss: 0.1360\n",
      "Epoch 191/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0435 - val_loss: 0.1357\n",
      "Epoch 192/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0433 - val_loss: 0.1350\n",
      "Epoch 193/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0432 - val_loss: 0.1322\n",
      "Epoch 194/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0430 - val_loss: 0.1367\n",
      "Epoch 195/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0435 - val_loss: 0.1327\n",
      "Epoch 196/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0428 - val_loss: 0.1378\n",
      "Epoch 197/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0443 - val_loss: 0.1330\n",
      "Epoch 198/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0427 - val_loss: 0.1429\n",
      "Epoch 199/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0425 - val_loss: 0.1364\n",
      "Epoch 200/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0417 - val_loss: 0.1361\n",
      "Epoch 201/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0423 - val_loss: 0.1384\n",
      "Epoch 202/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0416 - val_loss: 0.1361\n",
      "Epoch 203/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0421 - val_loss: 0.1314\n",
      "Epoch 204/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0416 - val_loss: 0.1374\n",
      "Epoch 205/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0414 - val_loss: 0.1346\n",
      "Epoch 206/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0408 - val_loss: 0.1370\n",
      "Epoch 207/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0410 - val_loss: 0.1350\n",
      "Epoch 208/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0412 - val_loss: 0.1399\n",
      "Epoch 209/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0406 - val_loss: 0.1331\n",
      "Epoch 210/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0411 - val_loss: 0.1325\n",
      "Epoch 211/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0405 - val_loss: 0.1387\n",
      "Epoch 212/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0415 - val_loss: 0.1412\n",
      "Epoch 213/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0425 - val_loss: 0.1327\n",
      "Epoch 214/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0397 - val_loss: 0.1378\n",
      "Epoch 215/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0401 - val_loss: 0.1396\n",
      "Epoch 216/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0402 - val_loss: 0.1327\n",
      "Epoch 217/600\n",
      "364/364 [==============================] - 0s 124us/sample - loss: 0.0412 - val_loss: 0.1418\n",
      "Epoch 218/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.0396 - val_loss: 0.1333\n",
      "Epoch 219/600\n",
      "364/364 [==============================] - 0s 119us/sample - loss: 0.0394 - val_loss: 0.1355\n",
      "Epoch 220/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0389 - val_loss: 0.1348\n",
      "Epoch 221/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0388 - val_loss: 0.1344\n",
      "Epoch 222/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0387 - val_loss: 0.1363\n",
      "Epoch 223/600\n",
      "364/364 [==============================] - 0s 131us/sample - loss: 0.0383 - val_loss: 0.1374\n",
      "Epoch 224/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0387 - val_loss: 0.1379\n",
      "Epoch 225/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0382 - val_loss: 0.1361\n",
      "Epoch 226/600\n",
      "364/364 [==============================] - 0s 129us/sample - loss: 0.0388 - val_loss: 0.1336\n",
      "Epoch 227/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0380 - val_loss: 0.1385\n",
      "Epoch 228/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.0381 - val_loss: 0.1364\n",
      "Epoch 00228: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc719fb388>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tiny_es.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_val, y_val), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model_tiny_es_df = pd.DataFrame(model_tiny_es.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc71f33548>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_model_tiny_es_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## medium size neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_med_es = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model_med_es.add(Dense(30, activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "model_med_es.add(Dense(15, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model_med_es.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_med_es.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/600\n",
      "364/364 [==============================] - 1s 3ms/sample - loss: 0.6859 - val_loss: 0.6739\n",
      "Epoch 2/600\n",
      "364/364 [==============================] - 0s 122us/sample - loss: 0.6640 - val_loss: 0.6531\n",
      "Epoch 3/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.6411 - val_loss: 0.6307\n",
      "Epoch 4/600\n",
      "364/364 [==============================] - 0s 121us/sample - loss: 0.6180 - val_loss: 0.6062\n",
      "Epoch 5/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.5897 - val_loss: 0.5779\n",
      "Epoch 6/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.5581 - val_loss: 0.5477\n",
      "Epoch 7/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.5238 - val_loss: 0.5184\n",
      "Epoch 8/600\n",
      "364/364 [==============================] - 0s 173us/sample - loss: 0.4880 - val_loss: 0.4855\n",
      "Epoch 9/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.4518 - val_loss: 0.4538\n",
      "Epoch 10/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.4149 - val_loss: 0.4218\n",
      "Epoch 11/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.3800 - val_loss: 0.3921\n",
      "Epoch 12/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.3454 - val_loss: 0.3611\n",
      "Epoch 13/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.3117 - val_loss: 0.3356\n",
      "Epoch 14/600\n",
      "364/364 [==============================] - 0s 162us/sample - loss: 0.2830 - val_loss: 0.3106\n",
      "Epoch 15/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.2575 - val_loss: 0.2930\n",
      "Epoch 16/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.2376 - val_loss: 0.2735\n",
      "Epoch 17/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.2192 - val_loss: 0.2626\n",
      "Epoch 18/600\n",
      "364/364 [==============================] - 0s 166us/sample - loss: 0.2022 - val_loss: 0.2497\n",
      "Epoch 19/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1908 - val_loss: 0.2409\n",
      "Epoch 20/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.1821 - val_loss: 0.2279\n",
      "Epoch 21/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.1671 - val_loss: 0.2193\n",
      "Epoch 22/600\n",
      "364/364 [==============================] - 0s 163us/sample - loss: 0.1615 - val_loss: 0.2154\n",
      "Epoch 23/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1527 - val_loss: 0.2092\n",
      "Epoch 24/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.1455 - val_loss: 0.2036\n",
      "Epoch 25/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.1370 - val_loss: 0.1977\n",
      "Epoch 26/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.1320 - val_loss: 0.1907\n",
      "Epoch 27/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.1257 - val_loss: 0.1924\n",
      "Epoch 28/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.1235 - val_loss: 0.1793\n",
      "Epoch 29/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.1200 - val_loss: 0.1792\n",
      "Epoch 30/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.1214 - val_loss: 0.1772\n",
      "Epoch 31/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.1093 - val_loss: 0.1705\n",
      "Epoch 32/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1120 - val_loss: 0.1754\n",
      "Epoch 33/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.1052 - val_loss: 0.1645\n",
      "Epoch 34/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0966 - val_loss: 0.1765\n",
      "Epoch 35/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0959 - val_loss: 0.1634\n",
      "Epoch 36/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0926 - val_loss: 0.1584\n",
      "Epoch 37/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0910 - val_loss: 0.1647\n",
      "Epoch 38/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0881 - val_loss: 0.1567\n",
      "Epoch 39/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0847 - val_loss: 0.1596\n",
      "Epoch 40/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0866 - val_loss: 0.1557\n",
      "Epoch 41/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0793 - val_loss: 0.1485\n",
      "Epoch 42/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0779 - val_loss: 0.1525\n",
      "Epoch 43/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0808 - val_loss: 0.1450\n",
      "Epoch 44/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0758 - val_loss: 0.1451\n",
      "Epoch 45/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0759 - val_loss: 0.1512\n",
      "Epoch 46/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.0694 - val_loss: 0.1395\n",
      "Epoch 47/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0694 - val_loss: 0.1484\n",
      "Epoch 48/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0684 - val_loss: 0.1420\n",
      "Epoch 49/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0679 - val_loss: 0.1469\n",
      "Epoch 50/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.0658 - val_loss: 0.1388\n",
      "Epoch 51/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0632 - val_loss: 0.1413\n",
      "Epoch 52/600\n",
      "364/364 [==============================] - 0s 134us/sample - loss: 0.0615 - val_loss: 0.1391\n",
      "Epoch 53/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0604 - val_loss: 0.1415\n",
      "Epoch 54/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.0611 - val_loss: 0.1430\n",
      "Epoch 55/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0594 - val_loss: 0.1376\n",
      "Epoch 56/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0572 - val_loss: 0.1369\n",
      "Epoch 57/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0560 - val_loss: 0.1396\n",
      "Epoch 58/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0558 - val_loss: 0.1389\n",
      "Epoch 59/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0551 - val_loss: 0.1338\n",
      "Epoch 60/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0546 - val_loss: 0.1362\n",
      "Epoch 61/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0527 - val_loss: 0.1363\n",
      "Epoch 62/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0516 - val_loss: 0.1343\n",
      "Epoch 63/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0530 - val_loss: 0.1349\n",
      "Epoch 64/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0514 - val_loss: 0.1398\n",
      "Epoch 65/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0566 - val_loss: 0.1318\n",
      "Epoch 66/600\n",
      "364/364 [==============================] - 0s 123us/sample - loss: 0.0478 - val_loss: 0.1395\n",
      "Epoch 67/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0479 - val_loss: 0.1318\n",
      "Epoch 68/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0470 - val_loss: 0.1319\n",
      "Epoch 69/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0476 - val_loss: 0.1361\n",
      "Epoch 70/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0477 - val_loss: 0.1286\n",
      "Epoch 71/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0481 - val_loss: 0.1352\n",
      "Epoch 72/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0472 - val_loss: 0.1314\n",
      "Epoch 73/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0446 - val_loss: 0.1327\n",
      "Epoch 74/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0430 - val_loss: 0.1358\n",
      "Epoch 75/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0440 - val_loss: 0.1357\n",
      "Epoch 76/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0429 - val_loss: 0.1321\n",
      "Epoch 77/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.0420 - val_loss: 0.1349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0408 - val_loss: 0.1313\n",
      "Epoch 79/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0413 - val_loss: 0.1317\n",
      "Epoch 80/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0408 - val_loss: 0.1360\n",
      "Epoch 81/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.0433 - val_loss: 0.1328\n",
      "Epoch 82/600\n",
      "364/364 [==============================] - 0s 130us/sample - loss: 0.0422 - val_loss: 0.1320\n",
      "Epoch 83/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0397 - val_loss: 0.1361\n",
      "Epoch 84/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0378 - val_loss: 0.1322\n",
      "Epoch 85/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0380 - val_loss: 0.1351\n",
      "Epoch 86/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0378 - val_loss: 0.1325\n",
      "Epoch 87/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0379 - val_loss: 0.1330\n",
      "Epoch 88/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0381 - val_loss: 0.1355\n",
      "Epoch 89/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.0382 - val_loss: 0.1323\n",
      "Epoch 90/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0377 - val_loss: 0.1339\n",
      "Epoch 91/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.0355 - val_loss: 0.1359\n",
      "Epoch 92/600\n",
      "364/364 [==============================] - 0s 144us/sample - loss: 0.0360 - val_loss: 0.1356\n",
      "Epoch 93/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0354 - val_loss: 0.1345\n",
      "Epoch 94/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0344 - val_loss: 0.1385\n",
      "Epoch 95/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0360 - val_loss: 0.1362\n",
      "Epoch 00095: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc74205388>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_med_es.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_val, y_val), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model_med_es_df = pd.DataFrame(model_med_es.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc75be1588>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_model_med_es_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_med_es_dropout = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model_med_es_dropout.add(Dense(30, activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "model_med_es_dropout.add(Dropout(0.2))\n",
    "model_med_es_dropout.add(Dense(15, activation='relu'))\n",
    "model_med_es_dropout.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model_med_es_dropout.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_med_es_dropout.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 364 samples, validate on 91 samples\n",
      "Epoch 1/600\n",
      "364/364 [==============================] - 1s 3ms/sample - loss: 0.6839 - val_loss: 0.6719\n",
      "Epoch 2/600\n",
      "364/364 [==============================] - 0s 132us/sample - loss: 0.6666 - val_loss: 0.6505\n",
      "Epoch 3/600\n",
      "364/364 [==============================] - 0s 139us/sample - loss: 0.6446 - val_loss: 0.6275\n",
      "Epoch 4/600\n",
      "364/364 [==============================] - 0s 174us/sample - loss: 0.6227 - val_loss: 0.5894\n",
      "Epoch 5/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.5817 - val_loss: 0.5434\n",
      "Epoch 6/600\n",
      "364/364 [==============================] - 0s 165us/sample - loss: 0.5377 - val_loss: 0.5031\n",
      "Epoch 7/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.4947 - val_loss: 0.4686\n",
      "Epoch 8/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.4456 - val_loss: 0.4277\n",
      "Epoch 9/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.4369 - val_loss: 0.3960\n",
      "Epoch 10/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.4249 - val_loss: 0.3664\n",
      "Epoch 11/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.3653 - val_loss: 0.3431\n",
      "Epoch 12/600\n",
      "364/364 [==============================] - 0s 168us/sample - loss: 0.3400 - val_loss: 0.3260\n",
      "Epoch 13/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.3358 - val_loss: 0.3062\n",
      "Epoch 14/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.3079 - val_loss: 0.2946\n",
      "Epoch 15/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.2856 - val_loss: 0.2759\n",
      "Epoch 16/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.2652 - val_loss: 0.2668\n",
      "Epoch 17/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.2516 - val_loss: 0.2642\n",
      "Epoch 18/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.2481 - val_loss: 0.2517\n",
      "Epoch 19/600\n",
      "364/364 [==============================] - 0s 166us/sample - loss: 0.2433 - val_loss: 0.2439\n",
      "Epoch 20/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.2277 - val_loss: 0.2379\n",
      "Epoch 21/600\n",
      "364/364 [==============================] - 0s 180us/sample - loss: 0.2170 - val_loss: 0.2384\n",
      "Epoch 22/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.2172 - val_loss: 0.2287\n",
      "Epoch 23/600\n",
      "364/364 [==============================] - 0s 175us/sample - loss: 0.1982 - val_loss: 0.2222\n",
      "Epoch 24/600\n",
      "364/364 [==============================] - 0s 172us/sample - loss: 0.1896 - val_loss: 0.2315\n",
      "Epoch 25/600\n",
      "364/364 [==============================] - 0s 167us/sample - loss: 0.1869 - val_loss: 0.2151\n",
      "Epoch 26/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.1908 - val_loss: 0.2097\n",
      "Epoch 27/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.1682 - val_loss: 0.2113\n",
      "Epoch 28/600\n",
      "364/364 [==============================] - 0s 163us/sample - loss: 0.1741 - val_loss: 0.2031\n",
      "Epoch 29/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.1798 - val_loss: 0.1967\n",
      "Epoch 30/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1546 - val_loss: 0.1940\n",
      "Epoch 31/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.1789 - val_loss: 0.1999\n",
      "Epoch 32/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.1504 - val_loss: 0.1899\n",
      "Epoch 33/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.1533 - val_loss: 0.1859\n",
      "Epoch 34/600\n",
      "364/364 [==============================] - 0s 161us/sample - loss: 0.1523 - val_loss: 0.1811\n",
      "Epoch 35/600\n",
      "364/364 [==============================] - 0s 135us/sample - loss: 0.1489 - val_loss: 0.1757\n",
      "Epoch 36/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.1560 - val_loss: 0.1819\n",
      "Epoch 37/600\n",
      "364/364 [==============================] - 0s 172us/sample - loss: 0.1508 - val_loss: 0.1718\n",
      "Epoch 38/600\n",
      "364/364 [==============================] - 0s 161us/sample - loss: 0.1370 - val_loss: 0.1702\n",
      "Epoch 39/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.1368 - val_loss: 0.1767\n",
      "Epoch 40/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.1324 - val_loss: 0.1677\n",
      "Epoch 41/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.1288 - val_loss: 0.1794\n",
      "Epoch 42/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.1038 - val_loss: 0.1628\n",
      "Epoch 43/600\n",
      "364/364 [==============================] - 0s 159us/sample - loss: 0.1041 - val_loss: 0.1602\n",
      "Epoch 44/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.1268 - val_loss: 0.1835\n",
      "Epoch 45/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.1165 - val_loss: 0.1588\n",
      "Epoch 46/600\n",
      "364/364 [==============================] - 0s 137us/sample - loss: 0.1128 - val_loss: 0.1532\n",
      "Epoch 47/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.1174 - val_loss: 0.1693\n",
      "Epoch 48/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.1134 - val_loss: 0.1580\n",
      "Epoch 49/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.1148 - val_loss: 0.1523\n",
      "Epoch 50/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.1025 - val_loss: 0.1440\n",
      "Epoch 51/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0967 - val_loss: 0.1390\n",
      "Epoch 52/600\n",
      "364/364 [==============================] - 0s 168us/sample - loss: 0.0954 - val_loss: 0.1487\n",
      "Epoch 53/600\n",
      "364/364 [==============================] - 0s 157us/sample - loss: 0.1030 - val_loss: 0.1507\n",
      "Epoch 54/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0901 - val_loss: 0.1508\n",
      "Epoch 55/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.1089 - val_loss: 0.1465\n",
      "Epoch 56/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0966 - val_loss: 0.1366\n",
      "Epoch 57/600\n",
      "364/364 [==============================] - 0s 161us/sample - loss: 0.0730 - val_loss: 0.1440\n",
      "Epoch 58/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0746 - val_loss: 0.1393\n",
      "Epoch 59/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0927 - val_loss: 0.1427\n",
      "Epoch 60/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0805 - val_loss: 0.1392\n",
      "Epoch 61/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0857 - val_loss: 0.1342\n",
      "Epoch 62/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0900 - val_loss: 0.1423\n",
      "Epoch 63/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0725 - val_loss: 0.1415\n",
      "Epoch 64/600\n",
      "364/364 [==============================] - 0s 155us/sample - loss: 0.0729 - val_loss: 0.1315\n",
      "Epoch 65/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0762 - val_loss: 0.1422\n",
      "Epoch 66/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0678 - val_loss: 0.1393\n",
      "Epoch 67/600\n",
      "364/364 [==============================] - 0s 163us/sample - loss: 0.0749 - val_loss: 0.1286\n",
      "Epoch 68/600\n",
      "364/364 [==============================] - 0s 149us/sample - loss: 0.0739 - val_loss: 0.1374\n",
      "Epoch 69/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0738 - val_loss: 0.1320\n",
      "Epoch 70/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.0661 - val_loss: 0.1302\n",
      "Epoch 71/600\n",
      "364/364 [==============================] - 0s 151us/sample - loss: 0.0596 - val_loss: 0.1331\n",
      "Epoch 72/600\n",
      "364/364 [==============================] - 0s 143us/sample - loss: 0.0755 - val_loss: 0.1237\n",
      "Epoch 73/600\n",
      "364/364 [==============================] - 0s 164us/sample - loss: 0.0635 - val_loss: 0.1289\n",
      "Epoch 74/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0598 - val_loss: 0.1304\n",
      "Epoch 75/600\n",
      "364/364 [==============================] - 0s 170us/sample - loss: 0.0697 - val_loss: 0.1279\n",
      "Epoch 76/600\n",
      "364/364 [==============================] - 0s 165us/sample - loss: 0.0660 - val_loss: 0.1188\n",
      "Epoch 77/600\n",
      "364/364 [==============================] - 0s 147us/sample - loss: 0.0788 - val_loss: 0.1344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "364/364 [==============================] - 0s 156us/sample - loss: 0.0735 - val_loss: 0.1356\n",
      "Epoch 79/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0727 - val_loss: 0.1191\n",
      "Epoch 80/600\n",
      "364/364 [==============================] - 0s 198us/sample - loss: 0.0806 - val_loss: 0.1282\n",
      "Epoch 81/600\n",
      "364/364 [==============================] - 0s 128us/sample - loss: 0.0761 - val_loss: 0.1168\n",
      "Epoch 82/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0632 - val_loss: 0.1337\n",
      "Epoch 83/600\n",
      "364/364 [==============================] - 0s 152us/sample - loss: 0.0565 - val_loss: 0.1209\n",
      "Epoch 84/600\n",
      "364/364 [==============================] - 0s 150us/sample - loss: 0.0564 - val_loss: 0.1200\n",
      "Epoch 85/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0720 - val_loss: 0.1325\n",
      "Epoch 86/600\n",
      "364/364 [==============================] - 0s 153us/sample - loss: 0.0526 - val_loss: 0.1270\n",
      "Epoch 87/600\n",
      "364/364 [==============================] - 0s 140us/sample - loss: 0.0483 - val_loss: 0.1252\n",
      "Epoch 88/600\n",
      "364/364 [==============================] - 0s 145us/sample - loss: 0.0652 - val_loss: 0.1310\n",
      "Epoch 89/600\n",
      "364/364 [==============================] - 0s 146us/sample - loss: 0.0608 - val_loss: 0.1319\n",
      "Epoch 90/600\n",
      "364/364 [==============================] - 0s 182us/sample - loss: 0.0598 - val_loss: 0.1205\n",
      "Epoch 91/600\n",
      "364/364 [==============================] - 0s 158us/sample - loss: 0.0461 - val_loss: 0.1373\n",
      "Epoch 92/600\n",
      "364/364 [==============================] - 0s 162us/sample - loss: 0.0573 - val_loss: 0.1405\n",
      "Epoch 93/600\n",
      "364/364 [==============================] - 0s 133us/sample - loss: 0.0645 - val_loss: 0.1207\n",
      "Epoch 94/600\n",
      "364/364 [==============================] - 0s 160us/sample - loss: 0.0544 - val_loss: 0.1331\n",
      "Epoch 95/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0510 - val_loss: 0.1306\n",
      "Epoch 96/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0493 - val_loss: 0.1294\n",
      "Epoch 97/600\n",
      "364/364 [==============================] - 0s 136us/sample - loss: 0.0551 - val_loss: 0.1225\n",
      "Epoch 98/600\n",
      "364/364 [==============================] - 0s 141us/sample - loss: 0.0511 - val_loss: 0.1221\n",
      "Epoch 99/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0538 - val_loss: 0.1232\n",
      "Epoch 100/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0489 - val_loss: 0.1225\n",
      "Epoch 101/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0552 - val_loss: 0.1202\n",
      "Epoch 102/600\n",
      "364/364 [==============================] - 0s 142us/sample - loss: 0.0591 - val_loss: 0.1292\n",
      "Epoch 103/600\n",
      "364/364 [==============================] - 0s 148us/sample - loss: 0.0462 - val_loss: 0.1211\n",
      "Epoch 104/600\n",
      "364/364 [==============================] - 0s 162us/sample - loss: 0.0486 - val_loss: 0.1202\n",
      "Epoch 105/600\n",
      "364/364 [==============================] - 0s 154us/sample - loss: 0.0574 - val_loss: 0.1316\n",
      "Epoch 106/600\n",
      "364/364 [==============================] - 0s 138us/sample - loss: 0.0541 - val_loss: 0.1232\n",
      "Epoch 00106: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc75e562c8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_med_es_dropout.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_val, y_val), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_model_med_es_dropout_df = pd.DataFrame(model_med_es_dropout.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc7421d708>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_model_med_es_dropout_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiny_df = model_tiny.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tiny_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        43\n",
      "           1       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_tiny_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  1]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred_tiny_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model_med_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_med_es_df = model_med_es.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        43\n",
      "           1       0.99      0.97      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_med_es_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  1]\n",
      " [ 2 69]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred_med_es_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  model_med_es_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_med_es_dropout_df = model_med_es_dropout.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        43\n",
      "           1       0.97      0.94      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.95      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_med_es_dropout_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  2]\n",
      " [ 4 67]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred_med_es_dropout_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
